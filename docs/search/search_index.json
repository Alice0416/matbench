{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#leaderboard","title":"Leaderboard","text":"<p>Matbench is an automated leaderboard for benchmarking state of the art ML algorithms predicting a diverse range of solid materials' properties. It is hosted and maintained by the Materials Project. </p> <p></p> Materials Properties Materials Discovery Task Submissions <code>180</code> <code>9</code> Algorithms <code>28</code> <code>9</code> Benchmark Task Suite <code>1</code> <code>1</code>"},{"location":"#leaderboard-property-general-purpose-algorithms-on-matbench_v01","title":"Leaderboard-Property: General Purpose Algorithms on <code>matbench_v0.1</code>","text":"<p>Find more information about this benchmark on the benchmark info page</p> Task name Samples Algorithm Verified MAE (unit) or ROCAUC Notes matbench_steels 312 MODNet (v0.1.12) 87.7627 (MPa) matbench_jdft2d 636 MODNet (v0.1.12) 33.1918 (meV/atom) matbench_phonons 1,265 MegNet (kgcnn v2.1.0) 28.7606 (cm^-1) structure required matbench_expt_gap 4,604 MODNet (v0.1.12) 0.3327 (eV) matbench_dielectric 4,764 MODNet (v0.1.12) 0.2711 (unitless) matbench_expt_is_metal 4,921 AMMExpress v2020 0.9209 matbench_glass 5,680 MODNet (v0.1.12) 0.9603 matbench_log_gvrh 10,987 coNGN 0.0670 (log10(GPa)) structure required matbench_log_kvrh 10,987 coNGN 0.0491 (log10(GPa)) structure required matbench_perovskites 18,928 coGN 0.0269 (eV/unit cell) structure required matbench_mp_gap 106,113 coGN 0.1559 (eV) structure required matbench_mp_is_metal 106,113 CGCNN v2019 0.9520 structure required matbench_mp_e_form 132,752 coGN 0.0170 (eV/atom) structure required <p>Scaled errors for regressions on this leaderboard plot are assessed as the ratio of mean absolute error to mean absolute deviation:</p> <p>$$ \\text{Scaled Error} = \\frac{\\text{MAE}}{\\text{MAD}} = \\frac{\\sum_i^N | y_i - y_i^{pred} |}{\\sum_i^N | y_i - \\bar{y} | } $$</p> <p>While, scaled errors for classifications are assessed as:</p> <p>$$ \\text{Scaled Error} = \\frac{1 - \\text{ROCAUC}}{0.5} $$</p>"},{"location":"#leaderboard-discovery-general-purpose-algorithms-on-matbench_discovery-010","title":"Leaderboard-Discovery: General Purpose Algorithms on <code>matbench_discovery 0.1.0</code>","text":"<p>Matbench Discovery is an interactive leaderboard and associated PyPI package which together make it easy to benchmark ML energy models on a task designed to closely simulate a high-throughput discovery campaign for new stable inorganic crystals. Matbench-discovery compares ML structure-relaxation methods on the WBM dataset for ranking ~250k generated structures according to predicted hull stability (42k stable). Matbench Discovery is developed by Janosh Riebesell.</p> model F1 DAF Precision TPR TNR Accuracy MAE RMSE R\u00b2 CHGNet 0.59 3.06 0.52 0.67 0.87 0.84 0.07 0.11 0.61 M3GNet 0.58 2.66 0.45 0.79 0.80 0.80 0.07 0.12 0.59 MEGNet 0.52 2.70 0.46 0.59 0.86 0.81 0.13 0.20 -0.27 CGCNN 0.52 2.62 0.45 0.60 0.85 0.81 0.14 0.23 -0.61 CGCNN+P 0.51 2.38 0.41 0.69 0.79 0.78 0.11 0.18 0.02 Wrenformer 0.48 2.13 0.36 0.71 0.74 0.74 0.10 0.18 -0.04 BOWSR + MEGNet 0.44 1.90 0.32 0.74 0.67 0.68 0.11 0.16 0.15 Voronoi RF 0.34 1.51 0.26 0.52 0.69 0.66 0.14 0.21 -0.32 dummy 0.19 1.01 0.17 0.23 0.77 0.68 0.12 0.18 0.00"},{"location":"#overview","title":"Overview","text":"<p>Matbench is an ImageNet for materials science; a curated set of 13 supervised, pre-cleaned, ready-to-use ML tasks for benchmarking and fair comparison. The tasks span a wide domain of inorganic materials science applications including electronic, thermodynamic, mechanical, and thermal properties among crystals, 2D materials, disordered metals, and more.  </p> <p>The Matbench python package provides everything needed to use Matbench with your ML algorithm in ~10 lines of code or less. The web pages and repository online contain full result files, citations, methodologies, and code for the algorithms shown.</p> <p></p>"},{"location":"#what-can-matbench-offer","title":"What can Matbench offer?","text":""},{"location":"#this-website","title":"This website","text":"<ul> <li>Leaderboard of results for state-of-the-art materials ML algorithms on standardized test problems</li> <li>Interactively explore and download the tasks on MPContribs-ML, a platform hosted by The Materials Project. See Benchmark Info for links to each dataset.</li> <li>Each and every result is backed by a peer-reviewed publication and/or a jupyter notebook (similar to Papers With Code) - i.e., how were these results were obtained?</li> <li>Glossary of all algorithms' results on the Matbench problems</li> </ul>"},{"location":"#the-matbench-python-package","title":"The Matbench Python package","text":"<ul> <li>Probe ML algorithms strengths and weaknesses across a wide range of materials property prediction tasks</li> <li>Run a full benchmark in ~10 lines of code</li> <li>Submit results as a PR to the Matbench repo to compare with other algorithms and appear on the leaderboard</li> <li>Benchmark both general purpose ML models as well as algorithms specialized for particular domains</li> </ul>"},{"location":"#summary-of-matbenchs-tasks","title":"Summary of Matbench's Tasks","text":"<p>Matbench's 13 tasks can be broken down into various categories; it includes both the small - less than 10,000 samples - datasets that characterize experimental materials data as well as larger datasets from computer modelling methods like density functional theory (DFT).</p> <p></p> <p>Each task in Matbench consists of a three things:</p> <ol> <li>A set of inputs: crystal structures or chemical compositions.</li> <li>A set of outputs: target properties, such as formation energy.</li> <li>A test procedure: a way to get a score for your algorithm</li> </ol> <p>The Matbench Python package provides functions for getting the first two (packaged together for each task as a dataset) as well as running  the test procedure. See the How to use documentation page to get started.</p>"},{"location":"#citing-matbench","title":"Citing Matbench","text":"<p>You can find details and results on the benchmark in our paper Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm.  Please consider citing this paper if you use Matbench v0.1 for benchmarking, comparison, or prototyping.</p> <p>You can cite Matbench using this reference:</p> <pre><code>Dunn, A., Wang, Q., Ganose, A., Dopp, D., Jain, A. \nBenchmarking Materials Property Prediction Methods: \nThe Matbench Test Set and Automatminer Reference Algorithm. \nnpj Computational Materials 6, 138 (2020). \nhttps://doi.org/10.1038/s41524-020-00406-3\n</code></pre>"},{"location":"Benchmark%20Info/matbench_v0.1/","title":"Benchmark info for <code>matbench_v0.1</code>","text":"<p>The <code>matbench_v0.1</code> benchmark contains 13 tasks:</p> Task name Task type/input Target column (unit) Samples MAD (regression) or Fraction True (classification) Links Submissions <code>matbench_steels</code> regression/composition <code>yield strength</code> (MPa) 312 229.3743 download, interactive 11 <code>matbench_jdft2d</code> regression/structure <code>exfoliation_en</code> (meV/atom) 636 67.2020 download, interactive 16 <code>matbench_phonons</code> regression/structure <code>last phdos peak</code> (cm^-1) 1,265 323.7870 download, interactive 16 <code>matbench_expt_gap</code> regression/composition <code>gap expt</code> (eV) 4,604 1.1432 download, interactive 12 <code>matbench_dielectric</code> regression/structure <code>n</code> (unitless) 4,764 0.8085 download, interactive 16 <code>matbench_expt_is_metal</code> classification/composition <code>is_metal</code> 4,921 0.4981 download, interactive 7 <code>matbench_glass</code> classification/composition <code>gfa</code> 5,680 0.7104 download, interactive 7 <code>matbench_log_gvrh</code> regression/structure <code>log10(G_VRH)</code> (log10(GPa)) 10,987 0.2931 download, interactive 16 <code>matbench_log_kvrh</code> regression/structure <code>log10(K_VRH)</code> (log10(GPa)) 10,987 0.2897 download, interactive 16 <code>matbench_perovskites</code> regression/structure <code>e_form</code> (eV/unit cell) 18,928 0.5660 download, interactive 16 <code>matbench_mp_gap</code> regression/structure <code>gap pbe</code> (eV) 106,113 1.3271 download, interactive 16 <code>matbench_mp_is_metal</code> classification/structure <code>is_metal</code> 106,113 0.4349 download, interactive 13 <code>matbench_mp_e_form</code> regression/structure <code>e_form</code> (eV/atom) 132,752 1.0059 download, interactive 18"},{"location":"Benchmark%20Info/notes/","title":"Notes on Benchmarking","text":""},{"location":"Benchmark%20Info/notes/#general-purpose-vs-task-specific-algorithms","title":"General-purpose vs Task-specific algorithms","text":"<p>\"General purpose\" algorithms are treated differently from task-specific algorithms in Matbench for the purposes of ranking.</p> <p>We make this distinction because some algorithms can be trained and used - in theory - for predicting any property of a material as long as they are trained on sufficient data. Others are specialized for particular domains and need a separate comparison for fair analysis.</p>"},{"location":"Benchmark%20Info/notes/#general-purpose-algorithms","title":"General purpose algorithms","text":"<p>General purpose algorithms are valid for all the tasks in a benchmark using the same human-chosen configuration. Beyond defining a single configuration before beginning a benchmark, a human should not be hand-tuning or informing the algorithm about architecture, parameters, or hyperparameters. However, general purpose algorithms can automatically determine hyperparameters and parameters as part of their fitting processes in each fold.</p> <p>We include algorithms as \"general purpose\" to include on the general purpose leaderboard if any one of the following criteria is met for Matbench v0.1:</p> <ul> <li>All 13 tasks are recorded, OR...</li> <li>All 10 regression tasks are recorded, OR...</li> <li>All 9 structure tasks are recorded. If only the 9 structure tasks are recorded, the algorithm is marked with \"requires structure\".</li> </ul> <p>General purpose algorithms' results will appear on both the General Purpose Leaderboard as well as the Task-specific leaderboards.</p>"},{"location":"Benchmark%20Info/notes/#task-specific-algorithms","title":"Task specific algorithms","text":"<p>Task-specific algorithms can fit on any subset of tasks; for example, a single task. Task-specific algorithms may be valid or specialized only for a subset of the tasks in the benchmark.  </p> <p>For example, if you have a model which was specifically created for predicting bulk metallic glasses, you may submit a benchmark containing only results for the <code>matbench_glass</code> dataset. </p> <p>Task-specific results will only appear on the Task-specific leaderboards, not on the General Purpose Leaderboard. </p>"},{"location":"Benchmark%20Info/notes/#why-mae","title":"Why MAE?","text":"<p>Mean absolute error was chosen as the ranking metric for regression because:</p> <ol> <li>The meaning of MAE is the most easily inferred</li> <li>Dataset targets which should be analyzed according to relative error (such as bulk moduli) have their target transformed to order-of-magnitude form (e.g., log10).</li> <li>MAE are valid for all target values, unlike mean absolute percentage errors, which are invalid for 0-valued targets.</li> </ol> <p>That being said, other error metrics are also informative beyond what MAE can offer. Therefore, Matbench offers multiple error metrics to help assess generalization error.</p>"},{"location":"Benchmark%20Info/notes/#mean-absolute-percentage-error-mape-scores","title":"Mean absolute percentage error (<code>mape*</code>) scores","text":"<p>Mean absolute percentage error is only valid on sets of data without any true values of zero. Also, small true values can result in very large MAPE for samples with even very small predicted error. A threshold of 1e-5 is applied to mask samples with true absolute values smaller than this from the MAPE calculation. The reported MAPE is the decimal (not percentage) among these masked samples; i.e.,  a MAPE of 11% corresponds to <code>mape*=0.11</code>, and a MAPE of 11,000% corresponds to <code>mape*=110</code>.</p> <p>Please use the given MAPE scores with a grain of salt, as they are not complete for the reason given above.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/","title":"matbench_v0.1: AutoML-Mat","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#algorithm-description","title":"Algorithm description:","text":"<p>This algorithm is a modification of the 'AutoML Benchmark' framework from the publication Conrad2022AutoMLBench. It combines 4 AutoML tools and selects the most performant one. For this purpose, the AutoML tools are each run in a container to solve the problems of the different dependencies. This was simplified for this benchmark, so Docker is not needed. The best framework for the task was selected by hand, so only one AutoML tool is needed. Further information on the implementation can be found in the publication. More details on the used AutoML tool autosklearn can be found in Feurer2015Neur</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#notes","title":"Notes:","text":"<p>Autosklearn (sklearn&gt;=0.24) and Matbench(sklearn&gt;=1.0) have mutually exclusive dependencies for sklearn. In order to run the script, an environment according to the 'requirements' must be created. Installation instructions for autosklearn can be found at https://automl.github.io/auto-sklearn/master/installation.html#installation. Matbench cannot be installed via pip, but must be added via git clone. Link to GitHub from the AutoML Benchmark: https://github.com/mm-tud/automl-materials .</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>['@article{Conrad2022AutoMLBench, author  = {Conrad, Felix and M{\"a}lzer, '\n 'Mauritz and Schwarzenberger, Michael and Wiemer, Hajo and Ihlenfeldt, '\n 'Steffen}, title   = {Benchmarking AutoML for regression tasks on small '\n 'tabular data in materials design}, journal = {Scientific Reports}, year    = '\n '{2022}, month   = {Nov}, day     = {11}, volume  = {12}, issn    = '\n '{2045-2322}, doi     = {10.1038/s41598-022-23327-1}, url     = '\n '{https://doi.org/10.1038/s41598-022-23327-1}}',\n '@inproceedings{feurer-neurips15a, title     = {Efficient and Robust '\n 'Automated Machine Learning}, author    = {Feurer, Matthias and Klein, Aaron '\n 'and Eggensperger, Katharina and Springenberg, Jost and Blum, Manuel and '\n 'Hutter, Frank}, booktitle = {Advances in Neural Information Processing '\n 'Systems 28 (2015)}, pages     = {2962--2970}, year      = {2015}}']\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#user-metadata","title":"User metadata:","text":"<pre><code>{}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#metadata","title":"Metadata:","text":"tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['gxx_linux-64==12.2.0',\n            'gcc_linux-64==12.2.0',\n            'swig==4.1.0',\n            'auto-sklearn==0.15.0',\n            'numpy==1.23.4',\n            'pandas==1.5.1',\n            'monty==2022.4.26',\n            'matminer==0.8.0',\n            'jupyter==1.0.0']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#matbench_steels","title":"<code>matbench_steels</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 97.1669 139.5237 0.0643 463.0130 fold_1 70.6172 97.1152 0.0521 399.3569 fold_2 83.3158 114.2351 0.0586 369.3930 fold_3 83.7402 106.0132 0.0600 270.0560 fold_4 76.6812 113.4013 0.0592 377.1294"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 82.3043 97.1669 70.6172 8.8565 rmse 114.0577 139.5237 97.1152 14.1474 mape* 0.0588 0.0643 0.0521 0.0039 max_error 375.7897 463.0130 270.0560 62.2666"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Auto-sklearn/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/","title":"matbench_v0.1: Ax(10/90)+CrabNet v1.2.7","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#algorithm-description","title":"Algorithm description:","text":"<p>Use Ax Bayesian adaptive design to simultaneously optimize 23 hyperparameters of CrabNet. 100 sequential design iterations were used, and parameters were chosen based on a combination of intuition and algorithm/data constraints (e.g. elemental featurizers which were missing elements contained in the dataset were removed). The first 10 iterations (for more direct comparison with SAASBO) were based on SOBOL sampling to create a rough initial model, while the remaining 90 iterations were Bayesian adaptive design iterations. For the inner loops (where hyperparameter optimization is performed), the average MAE across each of the five inner folds was used as Ax's objective to minimize. The best parameter set was then trained on all the inner fold data and used to predict on the test set (unknown during hyperparameter optimization). This is nested cross-validation, and is computationally expensive.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#notes","title":"Notes:","text":"<p>A Jupyter notebook is provided which contains additional details about the run of the algorithm. If you decide to run this yourself, because it can take several days to run, be sure to set the <code>dummy</code> variable to True and run an initial test that it runs free of errors.</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>['@article{Wang2021crabnet,  author = {Wang, Anthony Yu-Tung and Kauwe, Steven '\n 'K. and Murdock, Ryan J. and Sparks, Taylor D.},  year = {2021},  title = '\n '{Compositionally restricted attention-based network for materials property '\n 'predictions},  pages = {77},  volume = {7},  number = {1},  doi = '\n '{10.1038/s41524-021-00545-1},  publisher = {{Nature Publishing Group}},  '\n 'shortjournal = {npj Comput. Mater.},  journal = {npj Computational '\n 'Materials}',\n '@article{wang_kauwe_murdock_sparks_2021, place={Cambridge}, '\n 'title={Compositionally-Restricted Attention-Based Network for Materials '\n 'Property Prediction}, DOI={10.26434/chemrxiv.11869026.v3}, '\n 'journal={ChemRxiv}, publisher={Cambridge Open Engage}, author={Wang, Anthony '\n 'and Kauwe, Steven and Murdock, Ryan and Sparks, Taylor}, year={2021}} This '\n 'content is a preprint and has not been peer-reviewed.']\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#user-metadata","title":"User metadata:","text":"<pre><code>{'algorithm_version': '1.2.7'}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#metadata","title":"Metadata:","text":"tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': [['ax_platform==0.2.3',\n             'crabnet==1.2.7',\n             'scikit_learn',\n             'matbench==0.5',\n             'matplotlib==3.5.0',\n             'pandas==1.3.5',\n             'ax-platform==0.2.3',\n             'pyro-ppl==1.8.0',\n             'plotly==5.5.0',\n             'submitit==1.4.1',\n             'cloudpickle==2.0.0']]}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#matbench_expt_gap","title":"<code>matbench_expt_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.3457 0.7883 0.3564 6.7229 fold_1 0.3668 0.8431 0.3281 6.4005 fold_2 0.3931 1.0137 0.4027 11.1003 fold_3 0.3721 0.8858 0.4132 9.3770 fold_4 0.3381 0.8085 0.4338 7.2568"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.3632 0.3931 0.3381 0.0196 rmse 0.8679 1.0137 0.7883 0.0801 mape* 0.3868 0.4338 0.3281 0.0388 max_error 8.1715 11.1003 6.4005 1.7946"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_10_90_CrabNet_v1.2.7/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{'N': 4, 'alpha': 0.48871585125853706, 'batch_size': 106, 'betas': [0.8316306312719108, 0.8958260465822976], 'bias': False, 'criterion': 'RobustL2', 'd_model': 860, 'dim_feedforward': 1411, 'dropout':...</code> fold_1 <code>{'N': 3, 'alpha': 0.6316979414711735, 'batch_size': 70, 'betas': [0.7728603241989385, 0.9438804169876437], 'bias': False, 'criterion': 'RobustL2', 'd_model': 940, 'dim_feedforward': 1702, 'dropout': 0...</code> fold_2 <code>{'N': 4, 'alpha': 0.5969894183232147, 'batch_size': 84, 'betas': [0.7123950881835376, 0.8704530737662193], 'bias': False, 'criterion': 'RobustL2', 'd_model': 726, 'dim_feedforward': 1024, 'dropout': 4...</code> fold_3 <code>{'N': 3, 'alpha': 0.6335838688405715, 'batch_size': 100, 'betas': [0.815471216688928, 0.9330437529491037], 'bias': False, 'criterion': 'RobustL2', 'd_model': 784, 'dim_feedforward': 1080, 'dropout': 0...</code> fold_4 <code>{'N': 3, 'alpha': 0.6381644715564362, 'batch_size': 103, 'betas': [0.8304237621083581, 0.90535025277763], 'bias': False, 'criterion': 'RobustL2', 'd_model': 784, 'dim_feedforward': 1487, 'dropout': 0....</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/","title":"matbench_v0.1: Ax+CrabNet v1.2.1","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#algorithm-description","title":"Algorithm description:","text":"<p>Use Ax Bayesian adaptive design to simultaneously optimize 23 hyperparameters of CrabNet. 100 sequential design iterations were used, and parameters were chosen based on a combination of intuition and algorithm/data constraints (e.g. elemental featurizers which were missing elements contained in the dataset were removed). The first 46 iterations (23*2 parameters) were based on SOBOL sampling to create a rough initial model, while the remaining 56 iterations were Bayesian adaptive design iterations. For the inner loops (where hyperparameter optimization is performed), the average MAE across each of the five inner folds was used as Ax's objective to minimize. The best parameter set was then trained on all the inner fold data and used to predict on the test set (unknown during hyperparameter optimization). This is nested cross-validation, and is computationally expensive.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#notes","title":"Notes:","text":"<p>A Jupyter notebook is provided which contains additional details about the run of the algorithm. If you decide to run this yourself, because it can take several days to run, be sure to set the <code>dummy</code> variable to True and run an initial test that it runs free of errors.</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>['@article{Wang2021crabnet,  author = {Wang, Anthony Yu-Tung and Kauwe, Steven '\n 'K. and Murdock, Ryan J. and Sparks, Taylor D.},  year = {2021},  title = '\n '{Compositionally restricted attention-based network for materials property '\n 'predictions},  pages = {77},  volume = {7},  number = {1},  doi = '\n '{10.1038/s41524-021-00545-1},  publisher = {{Nature Publishing Group}},  '\n 'shortjournal = {npj Comput. Mater.},  journal = {npj Computational '\n 'Materials}',\n '@article{wang_kauwe_murdock_sparks_2021, place={Cambridge}, '\n 'title={Compositionally-Restricted Attention-Based Network for Materials '\n 'Property Prediction}, DOI={10.26434/chemrxiv.11869026.v3}, '\n 'journal={ChemRxiv}, publisher={Cambridge Open Engage}, author={Wang, Anthony '\n 'and Kauwe, Steven and Murdock, Ryan and Sparks, Taylor}, year={2021}} This '\n 'content is a preprint and has not been peer-reviewed.']\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#user-metadata","title":"User metadata:","text":"<pre><code>{'algorithm_version': '1.2.1'}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#metadata","title":"Metadata:","text":"tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': [['ax_platform==0.2.3',\n             'crabnet==1.2.1',\n             'scikit_learn==1.0.2',\n             'matbench==0.5',\n             'kaleido==0.2.1']]}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#matbench_expt_gap","title":"<code>matbench_expt_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.3465 0.8037 0.3899 5.5211 fold_1 0.4029 0.9289 0.3584 7.2696 fold_2 0.3599 0.9700 0.3834 11.0998 fold_3 0.3324 0.7836 0.3411 5.8159 fold_4 0.3412 0.8500 0.4276 7.2613"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.3566 0.4029 0.3324 0.0248 rmse 0.8673 0.9700 0.7836 0.0717 mape* 0.3801 0.4276 0.3411 0.0295 max_error 7.3935 11.0998 5.5211 1.9882"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_CrabNet_v1.2.1/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{'N': 4, 'alpha': 0.8790919451473411, 'batch_size': 69, 'betas': [0.5216069223062726, 0.7117768790338862], 'bias': True, 'criterion': 'RobustL1', 'd_model': 860, 'dim_feedforward': 3498, 'dropout': 0....</code> fold_1 <code>{'N': 5, 'alpha': 0.7990423841817611, 'batch_size': 165, 'betas': [0.6461252540288698, 0.7283172840513323], 'bias': False, 'criterion': 'RobustL1', 'd_model': 516, 'dim_feedforward': 2663, 'dropout': ...</code> fold_2 <code>{'N': 3, 'alpha': 0.8041617902337612, 'batch_size': 63, 'betas': [0.711095287462972, 0.9476000614084613], 'bias': False, 'criterion': 'RobustL1', 'd_model': 660, 'dim_feedforward': 3469, 'dropout': 0....</code> fold_3 <code>{'N': 3, 'alpha': 1.0, 'batch_size': 241, 'betas': [0.5591583071453617, 0.5830227398533708], 'bias': True, 'criterion': 'RobustL1', 'd_model': 940, 'dim_feedforward': 1981, 'dropout': 0.00347905979314...</code> fold_4 <code>{'N': 6, 'alpha': 0.7344910928263977, 'batch_size': 125, 'betas': [0.5574111505617741, 0.9346732886315889], 'bias': False, 'criterion': 'RobustL1', 'd_model': 288, 'dim_feedforward': 1393, 'dropout': ...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/","title":"matbench_v0.1: Ax/SAASBO CrabNet v1.2.7","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#algorithm-description","title":"Algorithm description:","text":"<p>Recently, SAASBO has been demonstrated to be a highly effect high-dimensional Bayesian optimization scheme. Here, we use Ax/SAASBO Bayesian adaptive design to simultaneously optimize 23 hyperparameters of CrabNet. <code>100</code> sequential design iterations were used, and parameters were chosen based on a combination of intuition and algorithm/data constraints (e.g. elemental featurizers which were missing elements contained in the dataset were removed). The first <code>10</code> iterations were based on SOBOL sampling to create a rough initial model, while the remaining <code>90</code> iterations were SAASBO Bayesian adaptive design iterations. For the innerloops (where hyperparameter optimization is performed), the average MAE across each of the five inner folds was used as Ax's objective to minimize. The best parameter set was then trained on all the inner fold data and used to predict on the test set (unknown during hyperparameter optimization). This is nested cross-validation (CV), and is computationally expensive. See automatminer: running a benchmark for more information on nested CV.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#notes","title":"Notes:","text":"<p>A Jupyter notebook is provided which contains additional details about the run of the algorithm. If you decide to run this yourself, because it can take several days to run, be sure to set the <code>dummy</code> variable to True and run an initial test to ensure it runs free of errors.</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>['@article{Wang2021crabnet,  author = {Wang, Anthony Yu-Tung and Kauwe, Steven '\n 'K. and Murdock, Ryan J. and Sparks, Taylor D.},  year = {2021},  title = '\n '{Compositionally restricted attention-based network for materials property '\n 'predictions},  pages = {77},  volume = {7},  number = {1},  doi = '\n '{10.1038/s41524-021-00545-1},  publisher = {{Nature Publishing Group}},  '\n 'shortjournal = {npj Comput. Mater.},  journal = {npj Computational '\n 'Materials}',\n '@article{erikssonHighDimensionalBayesianOptimization2021,             title '\n '= {High-{{Dimensional Bayesian Optimization}} with {{Sparse Axis-Aligned '\n 'Subspaces}}}, author = {Eriksson, David and Jankowiak, Martin},             '\n 'year = {2021}, month = jun, journal = {arXiv:2103.00349 [cs, stat]}, eprint '\n '= {2103.00349}, eprinttype = {arxiv}, primaryclass = {cs, stat}, '\n 'archiveprefix = {arXiv}, langid = {english}, keywords = {Computer Science - '\n 'Machine Learning,Statistics - Machine Learning}}']\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#user-metadata","title":"User metadata:","text":"<pre><code>{'algorithm_version': '1.2.7'}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#metadata","title":"Metadata:","text":"tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': [['matplotlib==3.5.0',\n             'pandas==1.3.5',\n             'ax-platform==0.2.3',\n             'pyro-ppl==1.8.0',\n             'plotly==5.5.0',\n             'crabnet==1.2.5',\n             'scikit-learn==1.0.2',\n             'submitit==1.4.1',\n             'matbench==0.5',\n             'cloudpickle==2.0.0']]}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#matbench_expt_gap","title":"<code>matbench_expt_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.3214 0.7561 0.3429 5.7689 fold_1 0.3385 0.7832 0.2888 6.3999 fold_2 0.3383 0.9170 0.3705 11.1001 fold_3 0.3327 0.8318 0.3375 6.3998 fold_4 0.3239 0.7733 0.4494 6.2801"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.3310 0.3385 0.3214 0.0071 rmse 0.8123 0.9170 0.7561 0.0581 mape* 0.3578 0.4494 0.2888 0.0528 max_error 7.1897 11.1001 5.7689 1.9690"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Ax_SAASBO_CrabNet_v1.2.7/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{'N': 2, 'alpha': 0.9999998976773382, 'batch_size': 32, 'betas': [0.516639075322522, 0.5264563063760717], 'bias': True, 'criterion': 'RobustL1', 'd_model': 890, 'dim_feedforward': 4096, 'dropout': 0.0...</code> fold_1 <code>{'N': 3, 'alpha': 0.8019048022306048, 'batch_size': 32, 'betas': [0.5000000000000002, 0.5000000000000008], 'bias': False, 'criterion': 'RobustL1', 'd_model': 690, 'dim_feedforward': 1179, 'dropout': 1...</code> fold_2 <code>{'N': 4, 'alpha': 0.6659722577118914, 'batch_size': 32, 'betas': [0.5000000000015171, 0.5000000000018112], 'bias': False, 'criterion': 'RobustL1', 'd_model': 1024, 'dim_feedforward': 1903, 'dropout': ...</code> fold_3 <code>{'N': 5, 'alpha': 0.6209436008996955, 'batch_size': 104, 'betas': [0.7642325868682494, 0.7978278147950777], 'bias': False, 'criterion': 'RobustL1', 'd_model': 1024, 'dim_feedforward': 2322, 'dropout':...</code> fold_4 <code>{'N': 2, 'alpha': 0.9402737238860547, 'batch_size': 32, 'betas': [0.5212575617080646, 0.9998999993348248], 'bias': False, 'criterion': 'RobustL1', 'd_model': 1024, 'dim_feedforward': 2074, 'dropout': ...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/","title":"matbench_v0.1: CrabNet","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#algorithm-description","title":"Algorithm description:","text":"<p>Compositionally restricted attention-based network for materials property predictions. See github page for more information: https://github.com/anthony-wang/CrabNet.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#notes","title":"Notes:","text":"<p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>('@article{Wang2021crabnet,\\n'\n ' author = {Wang, Anthony Yu-Tung and Kauwe, Steven K. and Murdock, Ryan J. '\n 'and Sparks, Taylor D.},\\n'\n ' year = {2021},\\n'\n ' title = {Compositionally restricted attention-based network for materials '\n 'property predictions},\\n'\n ' pages = {77},\\n'\n ' volume = {7},\\n'\n ' number = {1},\\n'\n ' doi = {10.1038/s41524-021-00545-1},\\n'\n ' publisher = {{Nature Publishing Group}},\\n'\n ' shortjournal = {npj Comput. Mater.},\\n'\n ' journal = {npj Computational Materials}\\n'\n ' }')\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#user-metadata","title":"User metadata:","text":"<pre><code>{}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#metadata","title":"Metadata:","text":"tasks recorded 10/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2713 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#software-requirements","title":"Software Requirements","text":"<pre><code>'See GitHub page for CrabNet, CrabNet version: be89e92.'\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_dielectric","title":"<code>matbench_dielectric</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2147 0.6794 0.0733 14.7263 fold_1 0.3048 1.1243 0.0989 19.2249 fold_2 0.4376 2.9443 0.0925 59.1583 fold_3 0.3402 2.3061 0.0797 53.8845 fold_4 0.3195 1.5900 0.0942 27.8634"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.3234 0.4376 0.2147 0.0714 rmse 1.7288 2.9443 0.6794 0.8120 mape* 0.0877 0.0989 0.0733 0.0096 max_error 34.9715 59.1583 14.7263 18.1717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_expt_gap","title":"<code>matbench_expt_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores_1","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.3476 0.8404 0.3974 6.6728 fold_1 0.3434 0.8214 0.2866 6.3943 fold_2 0.3473 0.8680 0.3421 9.1598 fold_3 0.3329 0.8518 0.3553 9.8002 fold_4 0.3602 0.8702 0.4349 7.6012"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats_1","title":"Fold score stats","text":"metric mean max min std mae 0.3463 0.3602 0.3329 0.0088 rmse 0.8504 0.8702 0.8214 0.0181 mape* 0.3633 0.4349 0.2866 0.0504 max_error 7.9256 9.8002 6.3943 1.3459"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters_1","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_jdft2d","title":"<code>matbench_jdft2d</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores_2","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 36.0753 71.1404 24.8117 394.7442 fold_1 45.8800 107.0134 0.3347 669.9718 fold_2 67.1110 192.8415 0.6296 1039.2952 fold_3 31.6798 65.1904 0.2653 319.1235 fold_4 47.3058 163.8581 0.5401 1532.0118"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats_2","title":"Fold score stats","text":"metric mean max min std mae 45.6104 67.1110 31.6798 12.2491 rmse 120.0088 192.8415 65.1904 50.5756 mape* 5.3163 24.8117 0.2653 9.7486 max_error 791.0293 1532.0118 319.1235 448.3487"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters_2","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_log_gvrh","title":"<code>matbench_log_gvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores_3","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0994 0.1538 0.0787 1.4432 fold_1 0.0994 0.1648 0.0794 2.4220 fold_2 0.1020 0.1594 0.0813 1.0792 fold_3 0.1034 0.1607 0.0783 1.0056 fold_4 0.1031 0.1633 0.0810 1.5313"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats_3","title":"Fold score stats","text":"metric mean max min std mae 0.1014 0.1034 0.0994 0.0017 rmse 0.1604 0.1648 0.1538 0.0038 mape* 0.0797 0.0813 0.0783 0.0012 max_error 1.4963 2.4220 1.0056 0.5051"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters_3","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_log_kvrh","title":"<code>matbench_log_kvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores_4","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0748 0.1449 0.0509 1.6732 fold_1 0.0780 0.1549 0.0525 1.6914 fold_2 0.0698 0.1344 0.0463 1.3116 fold_3 0.0793 0.1508 0.0571 1.0620 fold_4 0.0773 0.1506 0.0532 1.8430"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats_4","title":"Fold score stats","text":"metric mean max min std mae 0.0758 0.0793 0.0698 0.0034 rmse 0.1471 0.1549 0.1344 0.0071 mape* 0.0520 0.0571 0.0463 0.0035 max_error 1.5162 1.8430 1.0620 0.2864"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters_4","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_perovskites","title":"<code>matbench_perovskites</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores_5","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.4080 0.5445 0.4861 2.3726 fold_1 0.4160 0.5515 0.5261 2.1724 fold_2 0.4034 0.5363 0.4858 2.0999 fold_3 0.4096 0.5428 0.5270 2.2336 fold_4 0.3953 0.5310 0.4611 2.2192"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats_5","title":"Fold score stats","text":"metric mean max min std mae 0.4065 0.4160 0.3953 0.0069 rmse 0.5412 0.5515 0.5310 0.0070 mape* 0.4972 0.5270 0.4611 0.0256 max_error 2.2195 2.3726 2.0999 0.0896"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters_5","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_phonons","title":"<code>matbench_phonons</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores_6","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 60.8044 155.2771 0.0881 1452.7562 fold_1 58.1439 143.0602 0.0915 1207.7800 fold_2 60.2413 165.1000 0.0869 1445.4633 fold_3 47.7603 114.5270 0.0895 894.9224 fold_4 48.6072 113.9230 0.0871 1124.2209"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats_6","title":"Fold score stats","text":"metric mean max min std mae 55.1114 60.8044 47.7603 5.7317 rmse 138.3775 165.1000 113.9230 20.9212 mape* 0.0886 0.0915 0.0869 0.0017 max_error 1225.0285 1452.7562 894.9224 209.7051"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters_6","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_steels","title":"<code>matbench_steels</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores_7","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 116.2240 176.5695 0.0774 576.3912 fold_1 88.0920 117.7789 0.0632 387.1094 fold_2 108.1233 153.4745 0.0717 485.5283 fold_3 137.4903 192.2622 0.0932 549.5977 fold_4 86.6503 124.9355 0.0654 386.2023"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats_7","title":"Fold score stats","text":"metric mean max min std mae 107.3160 137.4903 86.6503 18.9057 rmse 153.0041 192.2622 117.7789 28.7243 mape* 0.0742 0.0932 0.0632 0.0107 max_error 476.9658 576.3912 386.2023 79.4309"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters_7","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_mp_gap","title":"<code>matbench_mp_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores_8","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2653 0.5814 5.4032 6.8675 fold_1 0.2613 0.5811 2.9969 7.9829 fold_2 0.2648 0.5903 5.3833 7.7856 fold_3 0.2658 0.5954 10.1488 7.9675 fold_4 0.2704 0.6006 5.8835 6.8672"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats_8","title":"Fold score stats","text":"metric mean max min std mae 0.2655 0.2704 0.2613 0.0029 rmse 0.5898 0.6006 0.5811 0.0077 mape* 5.9631 10.1488 2.9969 2.3227 max_error 7.4941 7.9829 6.8672 0.5165"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters_8","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#matbench_mp_e_form","title":"<code>matbench_mp_e_form</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-scores_9","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0853 0.2492 0.5075 4.2164 fold_1 0.0857 0.2613 0.4542 6.3774 fold_2 0.0879 0.2587 0.4088 4.0334 fold_3 0.0854 0.2499 0.5596 6.2383 fold_4 0.0865 0.2532 0.4764 3.9335"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-score-stats_9","title":"Fold score stats","text":"metric mean max min std mae 0.0862 0.0879 0.0853 0.0010 rmse 0.2544 0.2613 0.2492 0.0048 mape* 0.4813 0.5596 0.4088 0.0507 max_error 4.9598 6.3774 3.9335 1.1053"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet/#fold-parameters_9","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/","title":"matbench_v0.1: CrabNet v1.2.1","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#algorithm-description","title":"Algorithm description:","text":"<p>Fit CrabNet with default hyperparameters to serve as a baseline for Ax+CrabNet v1.2.1.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#notes","title":"Notes:","text":"<p>A Jupyter notebook is provided which contains additional details about the run of the algorithm.</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>['@article{Wang2021crabnet,  author = {Wang, Anthony Yu-Tung and Kauwe, Steven '\n 'K. and Murdock, Ryan J. and Sparks, Taylor D.},  year = {2021},  title = '\n '{Compositionally restricted attention-based network for materials property '\n 'predictions},  pages = {77},  volume = {7},  number = {1},  doi = '\n '{10.1038/s41524-021-00545-1},  publisher = {{Nature Publishing Group}},  '\n 'shortjournal = {npj Comput. Mater.},  journal = {npj Computational '\n 'Materials}',\n '@article{wang_kauwe_murdock_sparks_2021, place={Cambridge}, '\n 'title={Compositionally-Restricted Attention-Based Network for Materials '\n 'Property Prediction}, DOI={10.26434/chemrxiv.11869026.v3}, '\n 'journal={ChemRxiv}, publisher={Cambridge Open Engage}, author={Wang, Anthony '\n 'and Kauwe, Steven and Murdock, Ryan and Sparks, Taylor}, year={2021}} This '\n 'content is a preprint and has not been peer-reviewed.']\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#user-metadata","title":"User metadata:","text":"<pre><code>{'algorithm_version': '1.2.1'}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#metadata","title":"Metadata:","text":"tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': [['crabnet==1.2.1', 'scikit_learn==1.0.2', 'matbench==0.5']]}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#matbench_expt_gap","title":"<code>matbench_expt_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.3489 0.8079 0.4441 5.6781 fold_1 0.3674 0.8399 0.3349 7.0404 fold_2 0.4106 1.0092 0.4539 10.2572 fold_3 0.3677 0.8437 0.4181 6.1608 fold_4 0.3839 0.9019 0.4944 7.4912"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.3757 0.4106 0.3489 0.0207 rmse 0.8805 1.0092 0.8079 0.0711 mape* 0.4291 0.4944 0.3349 0.0531 max_error 7.3256 10.2572 5.6781 1.5984"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_CrabNet_v1.2.1/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{'N': 3, 'adam': False, 'alpha': 0.5, 'base_lr': 0.0001, 'betas': [0.9, 0.999], 'bias': False, 'criterion': None, 'd_model': 512, 'dim_feedforward': 2048, 'dropout': 0.1, 'elem_prop': 'mat2vec', 'emb_...</code> fold_1 <code>{'N': 3, 'adam': False, 'alpha': 0.5, 'base_lr': 0.0001, 'betas': [0.9, 0.999], 'bias': False, 'criterion': None, 'd_model': 512, 'dim_feedforward': 2048, 'dropout': 0.1, 'elem_prop': 'mat2vec', 'emb_...</code> fold_2 <code>{'N': 3, 'adam': False, 'alpha': 0.5, 'base_lr': 0.0001, 'betas': [0.9, 0.999], 'bias': False, 'criterion': None, 'd_model': 512, 'dim_feedforward': 2048, 'dropout': 0.1, 'elem_prop': 'mat2vec', 'emb_...</code> fold_3 <code>{'N': 3, 'adam': False, 'alpha': 0.5, 'base_lr': 0.0001, 'betas': [0.9, 0.999], 'bias': False, 'criterion': None, 'd_model': 512, 'dim_feedforward': 2048, 'dropout': 0.1, 'elem_prop': 'mat2vec', 'emb_...</code> fold_4 <code>{'N': 3, 'adam': False, 'alpha': 0.5, 'base_lr': 0.0001, 'betas': [0.9, 0.999], 'bias': False, 'criterion': None, 'd_model': 512, 'dim_feedforward': 2048, 'dropout': 0.1, 'elem_prop': 'mat2vec', 'emb_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/","title":"matbench_v0.1: DeeperGATGNN","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#algorithm-description","title":"Algorithm description:","text":"<p>Scalable deeper graph neural networks for high-performance materials property prediction (https://www.cell.com/patterns/pdfExtended/S2666-3899(22)00076-9). We propose a scalable global graph attention neural network model DeeperGATGNN with differentiable group normalization (DGN) and skip connections for high-performance materials property prediction. Our model not only achieved state-of-the art results on benchmark dataset, but also is the most scalable one in terms of graph convolution layers, which allows us to train very deep networks (e.g., &gt;30 layers) without significant performance degradation. Source code link: https://github.com/usccolumbia/deeperGATGNN</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#notes","title":"Notes:","text":"<p>Check your PyTorch and CUDA versions for installing appropriate version of torch-scatter, torch-sparse, torch-cluster, torch-spline-conv, and torch-geometric. Our code can be run on multiple GPUs. If you face any issues, create a new issue in our github repository or email me at omee.sadman@gmail.com</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>('@article{omee2022scalable,\\n'\n ' title={Scalable deeper graph neural networks for high-performance materials '\n 'property prediction},\\n'\n ' author={Omee, Sadman Sadeed and Louis, Steph-Yves and Fu, Nihang and Wei, '\n 'Lai and Dey, Sourin and Dong, Rongzhi and Li, Qinyang and Hu, Jianjun},\\n'\n ' journal={Patterns},\\n'\n ' year={2022},\\n'\n ' publisher={Elsevier}\\n'\n '}')\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#user-metadata","title":"User metadata:","text":"<pre><code>{}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#metadata","title":"Metadata:","text":"tasks recorded 8/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['torch==1.10.0+cu113',\n            'torch-scatter==2.0.9',\n            'torch-sparse==0.6.13',\n            'torch-spline-conv==1.2.1',\n            'torch-cluster==1.6.0',\n            'torch-geometric==2.0.4',\n            'pymatgen==2023.3.23',\n            'ase==3.22.1',\n            'dscribe==1.2.2',\n            'hyperopt==0.2.5',\n            'joblib==1.2.0',\n            'matplotlib==3.7.1',\n            'numpy==1.21.0',\n            'pickle5==0.0.11',\n            'ray==1.11.0',\n            'scikit-learn==1.2.2',\n            'scipy==1.10.1',\n            'tensorboardX==2.6']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#matbench_dielectric","title":"<code>matbench_dielectric</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2203 0.6949 0.0780 14.5437 fold_1 0.2732 1.0361 0.0893 18.9965 fold_2 0.4473 2.9482 0.1005 58.7139 fold_3 0.3267 2.0680 0.0762 43.2260 fold_4 0.4097 2.1864 0.1378 34.6313"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.3355 0.4473 0.2203 0.0839 rmse 1.7867 2.9482 0.6949 0.8177 mape* 0.0964 0.1378 0.0762 0.0225 max_error 34.0223 58.7139 14.5437 16.1242"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#matbench_jdft2d","title":"<code>matbench_jdft2d</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-scores_1","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 31.2373 54.7965 39.3128 201.5965 fold_1 43.4485 101.0501 0.3128 505.6367 fold_2 66.2654 164.7194 0.7606 885.5912 fold_3 39.1329 90.9378 0.3762 502.8997 fold_4 47.2216 155.5921 0.6308 1468.3439"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-score-stats_1","title":"Fold score stats","text":"metric mean max min std mae 45.4611 66.2654 31.2373 11.6819 rmse 113.4192 164.7194 54.7965 41.2439 mape* 8.2786 39.3128 0.3128 15.5180 max_error 712.8136 1468.3439 201.5965 435.6621"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-parameters_1","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#matbench_log_gvrh","title":"<code>matbench_log_gvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-scores_2","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0890 0.1342 0.0697 1.0543 fold_1 0.0916 0.1451 0.0732 1.4002 fold_2 0.0865 0.1326 0.0690 0.9744 fold_3 0.0939 0.1436 0.0729 0.9796 fold_4 0.0902 0.1408 0.0724 1.0748"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-score-stats_2","title":"Fold score stats","text":"metric mean max min std mae 0.0903 0.0939 0.0865 0.0025 rmse 0.1393 0.1451 0.1326 0.0050 mape* 0.0714 0.0732 0.0690 0.0017 max_error 1.0967 1.4002 0.9744 0.1569"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-parameters_2","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#matbench_log_kvrh","title":"<code>matbench_log_kvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-scores_3","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0678 0.1335 0.0446 1.7755 fold_1 0.0688 0.1320 0.0454 1.5375 fold_2 0.0665 0.1264 0.0442 1.1731 fold_3 0.0752 0.1374 0.0532 0.9629 fold_4 0.0707 0.1327 0.0476 1.3972"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-score-stats_3","title":"Fold score stats","text":"metric mean max min std mae 0.0698 0.0752 0.0665 0.0030 rmse 0.1324 0.1374 0.1264 0.0035 mape* 0.0470 0.0532 0.0442 0.0033 max_error 1.3692 1.7755 0.9629 0.2820"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-parameters_3","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#matbench_mp_e_form","title":"<code>matbench_mp_e_form</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-scores_4","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0348 0.0803 0.4272 3.0043 fold_1 0.0304 0.0765 0.2247 2.8463 fold_2 0.0374 0.0769 0.2690 3.4390 fold_3 0.0326 0.0727 0.2908 2.1084 fold_4 0.0346 0.0734 0.2950 1.9758"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-score-stats_4","title":"Fold score stats","text":"metric mean max min std mae 0.0340 0.0374 0.0304 0.0023 rmse 0.0759 0.0803 0.0727 0.0027 mape* 0.3013 0.4272 0.2247 0.0677 max_error 2.6748 3.4390 1.9758 0.5534"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-parameters_4","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#matbench_mp_gap","title":"<code>matbench_mp_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-scores_5","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.1765 0.4271 1.6708 6.8089 fold_1 0.1666 0.4181 2.1018 7.3731 fold_2 0.1734 0.4180 4.6320 7.3691 fold_3 0.1650 0.4090 5.9843 6.7121 fold_4 0.1655 0.4153 2.9621 7.4794"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-score-stats_5","title":"Fold score stats","text":"metric mean max min std mae 0.1694 0.1765 0.1650 0.0047 rmse 0.4175 0.4271 0.4090 0.0058 mape* 3.4702 5.9843 1.6708 1.6149 max_error 7.1485 7.4794 6.7121 0.3207"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-parameters_5","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#matbench_perovskites","title":"<code>matbench_perovskites</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-scores_6","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0280 0.0569 0.0272 0.8604 fold_1 0.0306 0.0628 0.0305 1.0267 fold_2 0.0274 0.0521 0.0267 0.8454 fold_3 0.0290 0.0536 0.0283 0.7928 fold_4 0.0291 0.0583 0.0254 0.9152"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-score-stats_6","title":"Fold score stats","text":"metric mean max min std mae 0.0288 0.0306 0.0274 0.0011 rmse 0.0568 0.0628 0.0521 0.0038 mape* 0.0276 0.0305 0.0254 0.0017 max_error 0.8881 1.0267 0.7928 0.0795"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-parameters_6","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#matbench_phonons","title":"<code>matbench_phonons</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-scores_7","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 34.9378 94.4311 0.0567 1134.0565 fold_1 31.8727 66.0292 0.0532 583.8024 fold_2 32.4509 75.4627 0.0555 708.0555 fold_3 34.7909 91.8744 0.0620 1111.3660 fold_4 31.5530 66.4401 0.0554 522.2902"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-score-stats_7","title":"Fold score stats","text":"metric mean max min std mae 33.1211 34.9378 31.5530 1.4530 rmse 78.8475 94.4311 66.0292 12.1841 mape* 0.0566 0.0620 0.0532 0.0029 max_error 811.9141 1134.0565 522.2902 260.8259"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DeeperGATGNN/#fold-parameters_7","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/","title":"matbench_v0.1: DimeNet++ (kgcnn v2.1.0)","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#algorithm-description","title":"Algorithm description:","text":"<p>Fast and Uncertainty-Aware Directional Message Passing for Non-Equilibrium Molecules. Adapted implementation of <code>kgcnn</code>. Original code from https://github.com/gasteigerjo/dimenet. Settings are almost similar compared to original work for QM9. We had to reduce the batch size to 16 and the maximum number of edges or neighbours to 17 due to memory issues (in addition to 5A cutoff). For angles, multi-edges and correct images are taken into account. We added a standard scaler for regression. No additional features were introduced but geometry and atom type. Training was carried out on A100-SXM with 41 GB of memory.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#notes","title":"Notes:","text":"<p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>['@inproceedings{gasteiger_dimenet_2020,\\n'\n 'title = {Directional Message Passing for Molecular Graphs},\\n'\n 'author = {Gasteiger, Johannes and Gro{\\\\ss}, Janek and G{\\\\\"u}nnemann, '\n 'Stephan},\\n'\n 'booktitle={International Conference on Learning Representations (ICLR)},\\n'\n 'year = {2020} }',\n '@inproceedings{gasteiger_dimenetpp_2020,\\n'\n 'title = {Fast and Uncertainty-Aware Directional Message Passing for '\n 'Non-Equilibrium Molecules},\\n'\n 'author = {Gasteiger, Johannes and Giri, Shankari and Margraf, Johannes T. '\n 'and G{\\\\\"u}nnemann, Stephan},\\n'\n 'booktitle={Machine Learning for Molecules Workshop, NeurIPS},\\n'\n 'year = {2020} }']\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#user-metadata","title":"User metadata:","text":"<pre><code>{}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#metadata","title":"Metadata:","text":"tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['scikit-learn==0.24.1',\n            'numpy==1.20.1',\n            'matbench==0.1.0',\n            'tensorflow==2.9.0',\n            'kgcnn==2.1.0',\n            'pymatgen==2022.9.8',\n            'pyxtal==0.5.2',\n            'networkx',\n            'pandas',\n            'tensorflow-addons']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_dielectric","title":"<code>matbench_dielectric</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2831 1.7549 0.0981 34.6909 fold_1 0.3120 1.2357 0.1049 19.2668 fold_2 0.4431 3.0083 0.0998 58.5416 fold_3 0.3043 2.1882 0.0641 49.1359 fold_4 0.3576 1.7811 0.1137 28.5201"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.3400 0.4431 0.2831 0.0570 rmse 1.9936 3.0083 1.2357 0.5906 mape* 0.0961 0.1137 0.0641 0.0169 max_error 38.0311 58.5416 19.2668 14.1259"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_1 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_2 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_3 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_4 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_jdft2d","title":"<code>matbench_jdft2d</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-scores_1","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 37.6448 59.7893 26.8152 240.0727 fold_1 52.4543 107.0413 0.4509 624.3835 fold_2 68.4016 187.3249 0.6867 1008.1589 fold_3 35.3625 57.1472 0.3687 292.5341 fold_4 51.2584 163.3720 0.6936 1515.0046"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-score-stats_1","title":"Fold score stats","text":"metric mean max min std mae 49.0243 68.4016 35.3625 11.9027 rmse 114.9349 187.3249 57.1472 52.9702 mape* 5.8030 26.8152 0.3687 10.5069 max_error 736.0308 1515.0046 240.0727 476.6514"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-parameters_1","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_1 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_2 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_3 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_4 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_log_gvrh","title":"<code>matbench_log_gvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-scores_2","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0786 0.1276 0.0615 1.5533 fold_1 0.0804 0.1304 0.0659 1.5549 fold_2 0.0781 0.1220 0.0625 1.1013 fold_3 0.0785 0.1195 0.0614 0.9208 fold_4 0.0806 0.1281 0.0635 1.5558"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-score-stats_2","title":"Fold score stats","text":"metric mean max min std mae 0.0792 0.0806 0.0781 0.0011 rmse 0.1255 0.1304 0.1195 0.0041 mape* 0.0630 0.0659 0.0614 0.0016 max_error 1.3372 1.5558 0.9208 0.2723"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-parameters_2","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_1 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_2 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_3 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_4 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_log_kvrh","title":"<code>matbench_log_kvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-scores_3","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0547 0.1189 0.0396 1.7063 fold_1 0.0574 0.1174 0.0399 1.5804 fold_2 0.0530 0.1001 0.0349 1.0732 fold_3 0.0618 0.1202 0.0453 1.1725 fold_4 0.0593 0.1178 0.0409 1.4483"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-score-stats_3","title":"Fold score stats","text":"metric mean max min std mae 0.0572 0.0618 0.0530 0.0032 rmse 0.1149 0.1202 0.1001 0.0074 mape* 0.0401 0.0453 0.0349 0.0033 max_error 1.3961 1.7063 1.0732 0.2397"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-parameters_3","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_1 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_2 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_3 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_4 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_mp_e_form","title":"<code>matbench_mp_e_form</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-scores_4","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0235 0.0725 0.2865 3.2321 fold_1 0.0236 0.0717 0.1561 2.4344 fold_2 0.0234 0.0640 0.1688 1.4689 fold_3 0.0241 0.0739 0.2090 3.6006 fold_4 0.0229 0.0655 0.2567 2.3014"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-score-stats_4","title":"Fold score stats","text":"metric mean max min std mae 0.0235 0.0241 0.0229 0.0004 rmse 0.0695 0.0739 0.0640 0.0040 mape* 0.2154 0.2865 0.1561 0.0500 max_error 2.6075 3.6006 1.4689 0.7478"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-parameters_4","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_1 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_2 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_3 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_4 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_mp_gap","title":"<code>matbench_mp_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-scores_5","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.1976 0.4493 2.7455 6.5509 fold_1 0.2011 0.4799 2.1119 14.0169 fold_2 0.1991 0.4789 4.5244 7.5415 fold_3 0.1904 0.4673 4.9372 9.0348 fold_4 0.2083 0.4846 4.8806 7.6471"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-score-stats_5","title":"Fold score stats","text":"metric mean max min std mae 0.1993 0.2083 0.1904 0.0058 rmse 0.4720 0.4846 0.4493 0.0127 mape* 3.8399 4.9372 2.1119 1.1781 max_error 8.9582 14.0169 6.5509 2.6502"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-parameters_5","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_1 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_2 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_3 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_4 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_mp_is_metal","title":"<code>matbench_mp_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-scores_6","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9111 0.9089 0.8972 0.9089 fold_1 0.9063 0.9038 0.8915 0.9038 fold_2 0.9022 0.8998 0.8869 0.8998 fold_3 0.9062 0.9043 0.8919 0.9043 fold_4 0.9014 0.8989 0.8858 0.8989"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-score-stats_6","title":"Fold score stats","text":"metric mean max min std accuracy 0.9054 0.9111 0.9014 0.0035 balanced_accuracy 0.9032 0.9089 0.8989 0.0036 f1 0.8907 0.8972 0.8858 0.0041 rocauc 0.9032 0.9089 0.8989 0.0036"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-parameters_6","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_1 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_2 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_3 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_4 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_perovskites","title":"<code>matbench_perovskites</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-scores_7","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0391 0.0668 0.0390 0.8217 fold_1 0.0385 0.0689 0.0379 0.9676 fold_2 0.0370 0.0605 0.0378 0.7633 fold_3 0.0362 0.0612 0.0344 0.8475 fold_4 0.0372 0.0637 0.0346 0.9014"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-score-stats_7","title":"Fold score stats","text":"metric mean max min std mae 0.0376 0.0391 0.0362 0.0011 rmse 0.0642 0.0689 0.0605 0.0032 mape* 0.0367 0.0390 0.0344 0.0019 max_error 0.8603 0.9676 0.7633 0.0697"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-parameters_7","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_1 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_2 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_3 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_4 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#matbench_phonons","title":"<code>matbench_phonons</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-scores_8","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 39.9212 93.3040 0.0663 883.7585 fold_1 35.3137 60.9662 0.0756 413.8156 fold_2 37.1448 77.1708 0.0730 604.9076 fold_3 40.0427 94.8770 0.0752 1012.6802 fold_4 34.8869 75.2053 0.0768 607.9076"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-score-stats_8","title":"Fold score stats","text":"metric mean max min std mae 37.4619 40.0427 34.8869 2.1934 rmse 80.3047 94.8770 60.9662 12.5789 mape* 0.0734 0.0768 0.0663 0.0037 max_error 704.6139 1012.6802 413.8156 214.8743"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_DimeNetPP_kgcnn_v2.1.0/#fold-parameters_8","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_1 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_2 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_3 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code> fold_4 <code>{'data': {'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0, 'max_neighbours': 17}}, {'map_list': {'method': 'set_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/","title":"matbench_v0.1: Finder_v1.2 composition-only version","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#algorithm-description","title":"Algorithm description:","text":"<p>Formula graph self-attention network for representation-domain independent materials discovery (Finder). Formula graph is a general representation of crystal structure and chemical composition for graph neural networks (GNNs). Finder GNN can therefore be used for materials property prediction with or without crystal structure. Please see the related publication (https://onlinelibrary.wiley.com/doi/full/10.1002/advs.202200164) and the github repository for more details (https://github.com/ihalage/Finder).</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#notes","title":"Notes:","text":"<p>An example python script with instructions to evaluate Finder algorithm on matbench suite is provided.</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>('@article{Ihalage_2022_Adv_Sci, author = {Ihalage, Achintha and Hao, Yang}, '\n 'title = {Formula Graph Self-Attention Network for Representation-Domain '\n 'Independent Materials Discovery}, journal = {Advanced Science}, volume = '\n '{9}, number = {18}, pages = {2200164}, keywords = {attention, '\n 'epsilon-near-zero, graph-network, machine-learning, materials-informatics}, '\n 'doi = {https://doi.org/10.1002/advs.202200164}, url = '\n '{https://onlinelibrary.wiley.com/doi/abs/10.1002/advs.202200164}, eprint = '\n '{https://onlinelibrary.wiley.com/doi/pdf/10.1002/advs.202200164}, year = '\n '{2022}}')\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#user-metadata","title":"User metadata:","text":"<pre><code>{}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#metadata","title":"Metadata:","text":"tasks recorded 8/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': [['spektral==1.1.0',\n             'tensorflow==2.9.1',\n             'pymatgen==2022.7.19',\n             'matminer==0.7.8',\n             'numpy==1.23.1',\n             'pandas==1.4.3',\n             'matplotlib==3.5.2',\n             'scikit-learn==1.1.1',\n             'scipy==1.8.1',\n             'sparse==0.13.0',\n             'protobuf==3.19.4']]}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#matbench_dielectric","title":"<code>matbench_dielectric</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2020 0.6838 0.0727 14.8287 fold_1 0.2675 1.0293 0.0874 19.0338 fold_2 0.4347 2.9821 0.0970 59.0528 fold_3 0.3222 2.1621 0.0775 46.3432 fold_4 0.3754 1.7371 0.1209 27.8804"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.3204 0.4347 0.2020 0.0811 rmse 1.7189 2.9821 0.6838 0.8172 mape* 0.0911 0.1209 0.0727 0.0171 max_error 33.4278 59.0528 14.8287 16.7770"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#matbench_jdft2d","title":"<code>matbench_jdft2d</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-scores_1","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 37.3620 72.8756 24.6383 356.9083 fold_1 45.0031 109.9971 0.3200 696.8793 fold_2 63.3670 175.1722 0.6752 914.8421 fold_3 34.3768 68.2091 0.3643 385.8836 fold_4 59.6980 178.1554 0.7090 1582.3598"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-score-stats_1","title":"Fold score stats","text":"metric mean max min std mae 47.9614 63.3670 34.3768 11.6680 rmse 120.8819 178.1554 68.2091 47.8021 mape* 5.3414 24.6383 0.3200 9.6497 max_error 787.3746 1582.3598 356.9083 447.8694"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-parameters_1","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#matbench_log_gvrh","title":"<code>matbench_log_gvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-scores_2","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0982 0.1516 0.0754 1.1378 fold_1 0.0984 0.1643 0.0787 2.3854 fold_2 0.0986 0.1548 0.0771 1.0763 fold_3 0.0996 0.1520 0.0759 0.9424 fold_4 0.1029 0.1631 0.0805 1.2900"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-score-stats_2","title":"Fold score stats","text":"metric mean max min std mae 0.0996 0.1029 0.0982 0.0018 rmse 0.1572 0.1643 0.1516 0.0055 mape* 0.0775 0.0805 0.0754 0.0019 max_error 1.3664 2.3854 0.9424 0.5216"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-parameters_2","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#matbench_log_kvrh","title":"<code>matbench_log_kvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-scores_3","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0745 0.1425 0.0485 1.5642 fold_1 0.0756 0.1554 0.0496 2.3863 fold_2 0.0737 0.1420 0.0485 1.3227 fold_3 0.0806 0.1500 0.0556 0.9465 fold_4 0.0778 0.1555 0.0531 1.6076"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-score-stats_3","title":"Fold score stats","text":"metric mean max min std mae 0.0764 0.0806 0.0737 0.0025 rmse 0.1491 0.1555 0.1420 0.0059 mape* 0.0511 0.0556 0.0485 0.0028 max_error 1.5655 2.3863 0.9465 0.4728"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-parameters_3","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#matbench_mp_e_form","title":"<code>matbench_mp_e_form</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-scores_4","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0838 0.2512 0.6783 4.2840 fold_1 0.0826 0.2569 0.4626 6.3948 fold_2 0.0843 0.2537 0.4024 4.1659 fold_3 0.0830 0.2485 0.5036 5.4366 fold_4 0.0858 0.2583 0.8146 3.8705"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-score-stats_4","title":"Fold score stats","text":"metric mean max min std mae 0.0839 0.0858 0.0826 0.0011 rmse 0.2537 0.2583 0.2485 0.0036 mape* 0.5723 0.8146 0.4024 0.1520 max_error 4.8304 6.3948 3.8705 0.9462"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-parameters_4","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#matbench_mp_gap","title":"<code>matbench_mp_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-scores_5","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2291 0.4816 3.3802 5.8312 fold_1 0.2350 0.4943 2.3466 7.6477 fold_2 0.2326 0.4808 4.1827 7.8152 fold_3 0.2265 0.4720 6.1036 5.4306 fold_4 0.2306 0.4900 4.8680 5.5791"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-score-stats_5","title":"Fold score stats","text":"metric mean max min std mae 0.2308 0.2350 0.2265 0.0029 rmse 0.4837 0.4943 0.4720 0.0078 mape* 4.1762 6.1036 2.3466 1.2786 max_error 6.4608 7.8152 5.4306 1.0467"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-parameters_5","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#matbench_perovskites","title":"<code>matbench_perovskites</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-scores_6","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.6366 0.8655 0.7413 3.4641 fold_1 0.6773 0.9258 0.8507 3.5402 fold_2 0.6399 0.8800 0.7475 3.3632 fold_3 0.6415 0.8821 0.8200 3.5053 fold_4 0.6294 0.8620 0.7008 3.5391"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-score-stats_6","title":"Fold score stats","text":"metric mean max min std mae 0.6450 0.6773 0.6294 0.0167 rmse 0.8831 0.9258 0.8620 0.0227 mape* 0.7721 0.8507 0.7008 0.0550 max_error 3.4824 3.5402 3.3632 0.0658"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-parameters_6","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#matbench_phonons","title":"<code>matbench_phonons</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-scores_7","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 50.6994 106.3352 0.0791 891.8557 fold_1 43.3725 90.7974 0.0823 1051.2485 fold_2 47.9669 103.6501 0.0802 706.1363 fold_3 41.0528 77.7973 0.0907 533.1135 fold_4 49.7836 95.6768 0.0916 644.7436"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-score-stats_7","title":"Fold score stats","text":"metric mean max min std mae 46.5751 50.6994 41.0528 3.7415 rmse 94.8514 106.3352 77.7973 10.1711 mape* 0.0848 0.0916 0.0791 0.0053 max_error 765.4195 1051.2485 533.1135 184.2431"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_composition/#fold-parameters_7","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/","title":"matbench_v0.1: Finder_v1.2 structure-based version","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#algorithm-description","title":"Algorithm description:","text":"<p>Formula graph self-attention network for representation-domain independent materials discovery (Finder). Formula graph is a general representation of crystal structure and chemical composition for graph neural networks (GNNs). Finder GNN can therefore be used for materials property prediction with or without crystal structure. Please see the related publication (https://onlinelibrary.wiley.com/doi/full/10.1002/advs.202200164) and the github repository for more details (https://github.com/ihalage/Finder).</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#notes","title":"Notes:","text":"<p>An example python script with instructions to evaluate Finder algorithm on matbench suite is provided.</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>('@article{Ihalage_2022_Adv_Sci, author = {Ihalage, Achintha and Hao, Yang}, '\n 'title = {Formula Graph Self-Attention Network for Representation-Domain '\n 'Independent Materials Discovery}, journal = {Advanced Science}, volume = '\n '{9}, number = {18}, pages = {2200164}, keywords = {attention, '\n 'epsilon-near-zero, graph-network, machine-learning, materials-informatics}, '\n 'doi = {https://doi.org/10.1002/advs.202200164}, url = '\n '{https://onlinelibrary.wiley.com/doi/abs/10.1002/advs.202200164}, eprint = '\n '{https://onlinelibrary.wiley.com/doi/pdf/10.1002/advs.202200164}, year = '\n '{2022}}')\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#user-metadata","title":"User metadata:","text":"<pre><code>{}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#metadata","title":"Metadata:","text":"tasks recorded 8/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': [['spektral==1.1.0',\n             'tensorflow==2.9.1',\n             'pymatgen==2022.7.19',\n             'matminer==0.7.8',\n             'numpy==1.23.1',\n             'pandas==1.4.3',\n             'matplotlib==3.5.2',\n             'scikit-learn==1.1.1',\n             'scipy==1.8.1',\n             'sparse==0.13.0',\n             'protobuf==3.19.4']]}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#matbench_dielectric","title":"<code>matbench_dielectric</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2068 0.7005 0.0727 14.8493 fold_1 0.2879 1.0938 0.0903 20.5043 fold_2 0.4186 2.9374 0.0885 59.0606 fold_3 0.3187 2.1634 0.0740 48.5382 fold_4 0.3663 1.7113 0.1228 28.3808"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.3197 0.4186 0.2068 0.0717 rmse 1.7213 2.9374 0.7005 0.7887 mape* 0.0897 0.1228 0.0727 0.0181 max_error 34.2666 59.0606 14.8493 16.8493"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#matbench_jdft2d","title":"<code>matbench_jdft2d</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-scores_1","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 30.4010 59.8060 24.0386 307.2029 fold_1 48.3155 112.6815 0.3680 673.9473 fold_2 64.6416 177.1717 0.7375 916.1028 fold_3 38.6522 86.1866 0.3161 568.6914 fold_4 48.6590 164.6126 0.5689 1581.4571"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-score-stats_1","title":"Fold score stats","text":"metric mean max min std mae 46.1339 64.6416 30.4010 11.4644 rmse 120.0917 177.1717 59.8060 44.8978 mape* 5.2058 24.0386 0.3161 9.4176 max_error 809.4803 1581.4571 307.2029 432.6540"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-parameters_1","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#matbench_log_gvrh","title":"<code>matbench_log_gvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-scores_2","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0881 0.1346 0.0702 0.9501 fold_1 0.0915 0.1478 0.0740 1.4842 fold_2 0.0897 0.1392 0.0712 0.9853 fold_3 0.0931 0.1415 0.0731 0.9482 fold_4 0.0925 0.1428 0.0729 0.9433"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-score-stats_2","title":"Fold score stats","text":"metric mean max min std mae 0.0910 0.0931 0.0881 0.0018 rmse 0.1412 0.1478 0.1346 0.0043 mape* 0.0723 0.0740 0.0702 0.0014 max_error 1.0622 1.4842 0.9433 0.2115"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-parameters_2","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#matbench_log_kvrh","title":"<code>matbench_log_kvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-scores_3","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0671 0.1270 0.0447 1.5412 fold_1 0.0707 0.1402 0.0469 1.6242 fold_2 0.0640 0.1223 0.0429 1.1117 fold_3 0.0743 0.1353 0.0532 0.9727 fold_4 0.0703 0.1344 0.0474 1.3475"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-score-stats_3","title":"Fold score stats","text":"metric mean max min std mae 0.0693 0.0743 0.0640 0.0035 rmse 0.1318 0.1402 0.1223 0.0064 mape* 0.0470 0.0532 0.0429 0.0035 max_error 1.3194 1.6242 0.9727 0.2475"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-parameters_3","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#matbench_mp_e_form","title":"<code>matbench_mp_e_form</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-scores_4","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0343 0.1006 0.3993 5.3738 fold_1 0.0332 0.0949 0.2940 4.9769 fold_2 0.0338 0.0882 0.2527 2.2726 fold_3 0.0366 0.2927 0.2853 45.1834 fold_4 0.0338 0.0892 0.3819 2.0420"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-score-stats_4","title":"Fold score stats","text":"metric mean max min std mae 0.0343 0.0366 0.0332 0.0012 rmse 0.1331 0.2927 0.0882 0.0799 mape* 0.3226 0.3993 0.2527 0.0574 max_error 11.9698 45.1834 2.0420 16.6622"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-parameters_4","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#matbench_mp_gap","title":"<code>matbench_mp_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-scores_5","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2182 0.4971 2.6076 6.3889 fold_1 0.2213 0.5032 2.9288 7.2332 fold_2 0.2177 0.4878 4.3448 7.6676 fold_3 0.2194 0.5090 7.5606 7.5448 fold_4 0.2198 0.4975 4.4658 6.5257"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-score-stats_5","title":"Fold score stats","text":"metric mean max min std mae 0.2193 0.2213 0.2177 0.0012 rmse 0.4989 0.5090 0.4878 0.0071 mape* 4.3815 7.5606 2.6076 1.7534 max_error 7.0720 7.6676 6.3889 0.5233"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-parameters_5","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#matbench_perovskites","title":"<code>matbench_perovskites</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-scores_6","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0330 0.0635 0.0328 0.8298 fold_1 0.0337 0.0670 0.0344 0.8875 fold_2 0.0313 0.0551 0.0311 0.8150 fold_3 0.0314 0.0565 0.0294 0.7990 fold_4 0.0305 0.0549 0.0280 0.8683"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-score-stats_6","title":"Fold score stats","text":"metric mean max min std mae 0.0320 0.0337 0.0305 0.0012 rmse 0.0594 0.0670 0.0549 0.0050 mape* 0.0311 0.0344 0.0280 0.0023 max_error 0.8399 0.8875 0.7990 0.0331"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-parameters_6","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#matbench_phonons","title":"<code>matbench_phonons</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-scores_7","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 58.5674 156.9785 0.0794 1706.8711 fold_1 43.6763 85.9967 0.0814 882.3383 fold_2 47.4812 109.3605 0.0810 850.8088 fold_3 55.2361 153.8394 0.0946 1506.3175 fold_4 48.7417 114.2167 0.0847 978.8324"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-score-stats_7","title":"Fold score stats","text":"metric mean max min std mae 50.7406 58.5674 43.6763 5.4036 rmse 124.0783 156.9785 85.9967 27.3211 mape* 0.0842 0.0946 0.0794 0.0055 max_error 1185.0336 1706.8711 850.8088 352.5301"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_Finder_v1.2_structure/#fold-parameters_7","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/","title":"matbench_v0.1: GN-OA v1","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#algorithm-description","title":"Algorithm description:","text":"<p>Crystal structure prediction by combining graph network and optimization algorithm, GN-OA v1.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#notes","title":"Notes:","text":"<p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>('@article{cheng_crystal_2022,\\n'\n '  doi = {10.1038/s41467-022-29241-4},\\n'\n '  url = {https://www.nature.com/articles/s41467-022-29241-4},\\n'\n '  year = {2022},\\n'\n '  month = mar,\\n'\n '  publisher = {Nature Publishing Group},\\n'\n '  volume = {13},\\n'\n '  number = {1},\\n'\n '  pages={1492},\\n'\n '  author = {Guanjian Cheng and Xin-Gao Gong and Wan-Jian Yin},\\n'\n '  title = {Crystal structure prediction by combining graph network and '\n 'optimization algorithm},\\n'\n '  journal = {Nature Communications}\\n'\n '}')\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#user-metadata","title":"User metadata:","text":"<pre><code>{}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#metadata","title":"Metadata:","text":"tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['pymatgen==2020.8.3',\n            'tensorflow==2.3.0',\n            'megnet==1.1.8',\n            'megnet==1.1.8',\n            'hyperopt==0.2.4',\n            'sko==0.6.1',\n            'matbench==0.1.0']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#matbench_mp_e_form","title":"<code>matbench_mp_e_form</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0245 0.0626 12.5887 2.1366 fold_1 0.0245 0.0616 7.9466 1.9405 fold_2 0.0249 0.0648 9.2633 2.4150 fold_3 0.0249 0.0632 11.8882 2.1705 fold_4 0.0250 0.0658 12.1946 1.7974"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.0248 0.0250 0.0245 0.0002 rmse 0.0636 0.0658 0.0616 0.0015 mape* 10.7763 12.5887 7.9466 1.8346 max_error 2.0920 2.4150 1.7974 0.2108"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_GN-OA/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/","title":"matbench_v0.1: MegNet (kgcnn v2.1.0)","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#algorithm-description","title":"Algorithm description:","text":"<p>Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals. Adapted implementation of <code>kgcnn</code>. Original code from https://github.com/materialsvirtuallab/megnet. Settings are similar compared to original work: A model depth of 3 and units for MegNet block of [64,32,32], a Set2Set encoder for node and edge embeddings, feed-forward blocks of units [64, 32], softplus activation and gauss distance expansion with cutoff of 5A and 25 bins with 0.4 sigma. We used a larger input embedding vector [64] of atom species and added the charge as input graph attributes. We trained with MAE loss and a linear learning rate scheduler from 5e-4 to 5e-6 over 1000 epochs using Adam. We added a standard scaler for regression. Training was carried out on A100-SXM with 41 GB of memory. Hyperparameter were not optimized but just copied over from training on  QM9/QM7 datasets.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#notes","title":"Notes:","text":"<p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>['@article{doi:10.1021/acs.chemmater.9b01294, author = {Chen, Chi and Ye, '\n 'Weike and Zuo, Yunxing and Zheng, Chen and Ong, Shyue Ping}, title = {Graph '\n 'Networks as a Universal Machine Learning Framework for Molecules and '\n 'Crystals}, journal = {Chemistry of Materials}, volume = {31}, number = {9}, '\n 'pages = {3564-3572}, year = {2019}, doi = {10.1021/acs.chemmater.9b01294}, '\n 'URL = {https://doi.org/10.1021/acs.chemmater.9b01294}, eprint = '\n '{https://doi.org/10.1021/acs.chemmater.9b01294}}']\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#user-metadata","title":"User metadata:","text":"<pre><code>{}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#metadata","title":"Metadata:","text":"tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['scikit-learn==0.24.1',\n            'numpy==1.20.1',\n            'matbench==0.1.0',\n            'tensorflow==2.9.0',\n            'kgcnn==2.1.0',\n            'pymatgen==2022.9.8',\n            'pyxtal==0.5.2',\n            'networkx',\n            'pandas',\n            'tensorflow-addons']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_dielectric","title":"<code>matbench_dielectric</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2385 1.0393 0.0767 20.5088 fold_1 0.2872 1.2163 0.0936 20.4615 fold_2 0.4444 3.0835 0.0973 59.3095 fold_3 0.3254 2.2884 0.0714 52.2159 fold_4 0.3998 2.3078 0.1274 47.8845"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.3391 0.4444 0.2385 0.0745 rmse 1.9871 3.0835 1.0393 0.7600 mape* 0.0933 0.1274 0.0714 0.0197 max_error 40.0760 59.3095 20.4615 16.4066"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_1 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_2 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_3 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_4 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_jdft2d","title":"<code>matbench_jdft2d</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-scores_1","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 50.6822 91.2961 15.5595 511.9383 fold_1 54.6317 115.4827 0.3805 518.5855 fold_2 67.3932 184.2895 0.6927 1064.3459 fold_3 34.6872 73.0294 0.3497 407.8362 fold_4 63.4653 182.5356 0.8128 1561.5756"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-score-stats_1","title":"Fold score stats","text":"metric mean max min std mae 54.1719 67.3932 34.6872 11.4299 rmse 129.3267 184.2895 73.0294 46.1724 mape* 3.5591 15.5595 0.3497 6.0029 max_error 812.8563 1561.5756 407.8362 439.3213"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-parameters_1","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_1 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_2 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_3 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_4 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_log_gvrh","title":"<code>matbench_log_gvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-scores_2","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0848 0.1350 0.0659 1.5533 fold_1 0.0883 0.1396 0.0699 1.5549 fold_2 0.0867 0.1313 0.0690 0.8507 fold_3 0.0883 0.1342 0.0681 0.9500 fold_4 0.0876 0.1387 0.0681 1.5558"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-score-stats_2","title":"Fold score stats","text":"metric mean max min std mae 0.0871 0.0883 0.0848 0.0013 rmse 0.1358 0.1396 0.1313 0.0030 mape* 0.0682 0.0699 0.0659 0.0013 max_error 1.2929 1.5558 0.8507 0.3221"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-parameters_2","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_1 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_2 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_3 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_4 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_log_kvrh","title":"<code>matbench_log_kvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-scores_3","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0648 0.1286 0.0452 1.6193 fold_1 0.0673 0.1365 0.0454 1.8705 fold_2 0.0633 0.1172 0.0410 1.2643 fold_3 0.0730 0.1337 0.0517 1.2378 fold_4 0.0657 0.1275 0.0451 1.4056"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-score-stats_3","title":"Fold score stats","text":"metric mean max min std mae 0.0668 0.0730 0.0633 0.0034 rmse 0.1287 0.1365 0.1172 0.0066 mape* 0.0457 0.0517 0.0410 0.0034 max_error 1.4795 1.8705 1.2378 0.2377"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-parameters_3","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_1 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_2 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_3 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_4 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_mp_e_form","title":"<code>matbench_mp_e_form</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-scores_4","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0248 0.0711 0.3029 3.4758 fold_1 0.0250 0.0707 0.1600 2.2742 fold_2 0.0253 0.0679 0.1952 2.3452 fold_3 0.0257 0.0742 0.2225 3.6006 fold_4 0.0251 0.0668 0.2638 2.2808"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-score-stats_4","title":"Fold score stats","text":"metric mean max min std mae 0.0252 0.0257 0.0248 0.0003 rmse 0.0701 0.0742 0.0668 0.0026 mape* 0.2289 0.3029 0.1600 0.0502 max_error 2.7953 3.6006 2.2742 0.6083"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-parameters_4","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_1 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_2 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_3 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_4 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_mp_gap","title":"<code>matbench_mp_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-scores_5","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.1845 0.4415 2.4896 6.8774 fold_1 0.1970 0.4744 2.0477 7.0580 fold_2 0.2039 0.5019 4.1405 6.9070 fold_3 0.1817 0.4501 6.2172 7.8821 fold_4 0.1999 0.4895 5.3344 7.0037"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-score-stats_5","title":"Fold score stats","text":"metric mean max min std mae 0.1934 0.2039 0.1817 0.0087 rmse 0.4715 0.5019 0.4415 0.0229 mape* 4.0459 6.2172 2.0477 1.5999 max_error 7.1457 7.8821 6.8774 0.3739"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-parameters_5","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_1 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_2 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_3 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_4 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_mp_is_metal","title":"<code>matbench_mp_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-scores_6","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9072 0.9048 0.8926 0.9048 fold_1 0.9039 0.9013 0.8886 0.9013 fold_2 0.9063 0.9035 0.8912 0.9035 fold_3 0.9032 0.9008 0.8880 0.9008 fold_4 0.9029 0.9002 0.8873 0.9002"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-score-stats_6","title":"Fold score stats","text":"metric mean max min std accuracy 0.9047 0.9072 0.9029 0.0017 balanced_accuracy 0.9021 0.9048 0.9002 0.0018 f1 0.8895 0.8926 0.8873 0.0020 rocauc 0.9021 0.9048 0.9002 0.0018"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-parameters_6","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_1 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_2 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_3 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_4 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_perovskites","title":"<code>matbench_perovskites</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-scores_7","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0355 0.0653 0.0366 0.8320 fold_1 0.0374 0.0722 0.0372 1.0236 fold_2 0.0335 0.0554 0.0341 0.7220 fold_3 0.0363 0.0646 0.0357 0.7184 fold_4 0.0331 0.0602 0.0293 0.8357"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-score-stats_7","title":"Fold score stats","text":"metric mean max min std mae 0.0352 0.0374 0.0331 0.0016 rmse 0.0635 0.0722 0.0554 0.0056 mape* 0.0346 0.0372 0.0293 0.0029 max_error 0.8263 1.0236 0.7184 0.1110"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-parameters_7","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_1 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_2 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_3 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_4 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#matbench_phonons","title":"<code>matbench_phonons</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-scores_8","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 31.6159 63.3487 0.0560 724.7676 fold_1 31.0426 61.1066 0.0590 589.2758 fold_2 25.2700 55.0800 0.0513 489.6110 fold_3 29.7114 64.6030 0.0611 774.1321 fold_4 26.1630 43.2011 0.0529 208.9928"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-score-stats_8","title":"Fold score stats","text":"metric mean max min std mae 28.7606 31.6159 25.2700 2.5767 rmse 57.4679 64.6030 43.2011 7.8483 mape* 0.0561 0.0611 0.0513 0.0036 max_error 557.3559 774.1321 208.9928 200.9894"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_MegNet_kgcnn_v2.1.0/#fold-parameters_8","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_1 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_2 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_3 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code> fold_4 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5.0}}], 'module_name': 'kgcnn.data.crysta...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/","title":"matbench_v0.1: RF-Regex Steels","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#algorithm-description","title":"Algorithm description:","text":"<p>The RF algorithm from sklearn is used.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#notes","title":"Notes:","text":"<p>No special considerations required. Key is to convert the composition string properly into a table</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>''\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#user-metadata","title":"User metadata:","text":"<pre><code>{}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#metadata","title":"Metadata:","text":"tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['scikit-learn==0.24.1', 'numpy==1.20.1', 'matbench==0.1.0']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#matbench_steels","title":"<code>matbench_steels</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 97.5404 135.2950 0.0660 500.0100 fold_1 86.2789 120.2379 0.0620 422.3500 fold_2 79.5099 114.1154 0.0559 357.8433 fold_3 94.5817 128.5511 0.0678 328.0567 fold_4 95.0372 142.2333 0.0720 505.2967"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 90.5896 97.5404 79.5099 6.7138 rmse 128.0865 142.2333 114.1154 10.0906 mape* 0.0647 0.0720 0.0559 0.0054 max_error 422.7113 505.2967 328.0567 72.0596"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_RFLR/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/","title":"matbench_v0.1: SchNet (kgcnn v2.1.0)","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#algorithm-description","title":"Algorithm description:","text":"<p>A continuous-filter convolutional neural network for modeling quantum interactions - SchNet. Implementation adapted to crystals in <code>kgcnn</code>. Original code from https://github.com/atomistic-machine-learning/schnetpack .</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#notes","title":"Notes:","text":"<p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>['@article{doi:10.1063/1.5019779,author={Sch\u00fctt, K.T. and Sauceda, H. E. and '\n 'Kindermans, P.-J. and Tkatchenko, A. and M\u00fcller, K.-R.},title={SchNet - A '\n 'deep learning architecture for molecules and materials},journal={The Journal '\n 'of Chemical '\n 'Physics},volume={148},number={24},pages={241722},year={2018},doi={10.1063/1.5019779},URL={https://doi.org/10.1063/1.5019779},eprint={https://doi.org/10.1063/1.5019779}}']\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#user-metadata","title":"User metadata:","text":"<pre><code>{}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#metadata","title":"Metadata:","text":"tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['scikit-learn==0.24.1',\n            'numpy==1.20.1',\n            'matbench==0.1.0',\n            'tensorflow==2.9.0',\n            'kgcnn==2.1.0',\n            'pymatgen==2022.9.8',\n            'pyxtal==0.5.2',\n            'networkx',\n            'pandas',\n            'tensorflow-addons']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_dielectric","title":"<code>matbench_dielectric</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.1797 0.7529 0.0610 14.6940 fold_1 0.3327 1.5348 0.1185 21.6101 fold_2 0.4288 3.0209 0.0941 58.6071 fold_3 0.3228 2.2977 0.0702 51.8160 fold_4 0.3747 1.8887 0.1275 28.3467"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.3277 0.4288 0.1797 0.0829 rmse 1.8990 3.0209 0.7529 0.7568 mape* 0.0942 0.1275 0.0610 0.0260 max_error 35.0148 58.6071 14.6940 17.1812"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_1 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_2 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_3 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_4 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_jdft2d","title":"<code>matbench_jdft2d</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-scores_1","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 27.5059 53.8311 22.7853 409.8511 fold_1 49.5297 106.4853 0.4151 562.8652 fold_2 63.6005 185.0466 0.6597 1015.3435 fold_3 27.7970 54.7520 0.2490 287.0124 fold_4 44.8856 154.9782 0.6035 1524.9143"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-score-stats_1","title":"Fold score stats","text":"metric mean max min std mae 42.6637 63.6005 27.5059 13.7201 rmse 111.0187 185.0466 53.8311 52.6678 mape* 4.9425 22.7853 0.2490 8.9226 max_error 759.9973 1524.9143 287.0124 455.0775"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-parameters_1","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_1 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_2 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_3 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_4 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_log_gvrh","title":"<code>matbench_log_gvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-scores_2","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0769 0.1203 0.0615 0.9939 fold_1 0.0825 0.1313 0.0675 1.1584 fold_2 0.0772 0.1246 0.0624 0.9158 fold_3 0.0804 0.1261 0.0644 0.9228 fold_4 0.0812 0.1276 0.0641 0.7567"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-score-stats_2","title":"Fold score stats","text":"metric mean max min std mae 0.0796 0.0825 0.0769 0.0022 rmse 0.1260 0.1313 0.1203 0.0036 mape* 0.0640 0.0675 0.0615 0.0021 max_error 0.9495 1.1584 0.7567 0.1301"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-parameters_2","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_1 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_2 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_3 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_4 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_log_kvrh","title":"<code>matbench_log_kvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-scores_3","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0577 0.1137 0.0387 1.7542 fold_1 0.0568 0.1159 0.0395 1.4185 fold_2 0.0575 0.1069 0.0387 1.0520 fold_3 0.0628 0.1183 0.0452 1.2305 fold_4 0.0601 0.1167 0.0404 1.4135"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-score-stats_3","title":"Fold score stats","text":"metric mean max min std mae 0.0590 0.0628 0.0568 0.0022 rmse 0.1143 0.1183 0.1069 0.0040 mape* 0.0405 0.0452 0.0387 0.0024 max_error 1.3737 1.7542 1.0520 0.2334"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-parameters_3","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_1 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_2 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_3 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_4 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_mp_e_form","title":"<code>matbench_mp_e_form</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-scores_4","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0223 0.0581 0.2173 2.9568 fold_1 0.0212 0.0506 0.1738 2.0016 fold_2 0.0219 0.0523 0.1543 2.9990 fold_3 0.0221 0.0539 0.1662 1.9801 fold_4 0.0216 0.0495 0.2167 1.4672"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-score-stats_4","title":"Fold score stats","text":"metric mean max min std mae 0.0218 0.0223 0.0212 0.0004 rmse 0.0529 0.0581 0.0495 0.0030 mape* 0.1856 0.2173 0.1543 0.0263 max_error 2.2809 2.9990 1.4672 0.6005"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-parameters_4","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_1 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_2 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_3 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_4 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_mp_gap","title":"<code>matbench_mp_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-scores_5","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2316 0.5058 2.4606 7.3981 fold_1 0.2313 0.5064 2.2767 9.1171 fold_2 0.2360 0.5152 3.7636 7.1947 fold_3 0.2366 0.5278 5.7306 7.6585 fold_4 0.2405 0.5308 5.0042 7.4353"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-score-stats_5","title":"Fold score stats","text":"metric mean max min std mae 0.2352 0.2405 0.2313 0.0034 rmse 0.5172 0.5308 0.5058 0.0105 mape* 3.8472 5.7306 2.2767 1.3625 max_error 7.7607 9.1171 7.1947 0.6940"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-parameters_5","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_1 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_2 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_3 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_4 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_mp_is_metal","title":"<code>matbench_mp_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-scores_6","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.8930 0.8902 0.8759 0.8902 fold_1 0.8909 0.8890 0.8745 0.8890 fold_2 0.8914 0.8888 0.8744 0.8888 fold_3 0.8946 0.8929 0.8790 0.8929 fold_4 0.8952 0.8928 0.8788 0.8928"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-score-stats_6","title":"Fold score stats","text":"metric mean max min std accuracy 0.8930 0.8952 0.8909 0.0017 balanced_accuracy 0.8907 0.8929 0.8888 0.0018 f1 0.8765 0.8790 0.8744 0.0020 rocauc 0.8907 0.8929 0.8888 0.0018"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-parameters_6","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_1 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_2 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_3 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_4 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_perovskites","title":"<code>matbench_perovskites</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-scores_7","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0348 0.0624 0.0336 0.8552 fold_1 0.0346 0.0645 0.0356 0.8765 fold_2 0.0336 0.0559 0.0348 0.6017 fold_3 0.0340 0.0584 0.0326 0.6391 fold_4 0.0338 0.0585 0.0318 0.8929"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-score-stats_7","title":"Fold score stats","text":"metric mean max min std mae 0.0342 0.0348 0.0336 0.0005 rmse 0.0599 0.0645 0.0559 0.0031 mape* 0.0337 0.0356 0.0318 0.0014 max_error 0.7731 0.8929 0.6017 0.1258"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-parameters_7","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_1 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_2 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_3 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_4 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#matbench_phonons","title":"<code>matbench_phonons</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-scores_8","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 39.8691 89.5683 0.0746 1034.3312 fold_1 41.1306 83.3891 0.0865 827.0298 fold_2 40.1591 86.2715 0.0767 731.4202 fold_3 38.1467 63.9434 0.0950 355.3882 fold_4 35.5125 61.4670 0.0795 607.1646"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-score-stats_8","title":"Fold score stats","text":"metric mean max min std mae 38.9636 41.1306 35.5125 1.9760 rmse 76.9279 89.5683 61.4670 11.8023 mape* 0.0825 0.0950 0.0746 0.0074 max_error 711.0668 1034.3312 355.3882 226.1258"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_SchNet_kgcnn_v2.1.0/#fold-parameters_8","title":"Fold parameters","text":"fold params dict fold_0 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_1 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_2 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_3 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code> fold_4 <code>{'data': {'data_unit': '', 'dataset': {'class_name': 'CrystalDataset', 'config': {}, 'methods': [{'map_list': {'method': 'set_range_periodic', 'max_distance': 5}}], 'module_name': 'kgcnn.data.crystal'...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_TPOT/","title":"matbench_v0.1: TPOT-Mat","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_TPOT/#algorithm-description","title":"Algorithm description:","text":"<p>This algorithm was generated by a TPOTRegressor (formulating the search as an optimisation process) run on the matbench-steel data</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_TPOT/#notes","title":"Notes:","text":"<p>None</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_TPOT/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>['@inproceedings{OlsonGECCO2016, author = {Olson, Randal S. and Bartley, '\n 'Nathan and Urbanowicz, Ryan J. and Moore, Jason H.},title = {Evaluation of a '\n 'Tree-based Pipeline Optimization Tool for Automating Data Science}, '\n 'booktitle = {Proceedings of the Genetic and Evolutionary Computation '\n \"Conference 2016}, series = {GECCO '16},year = {2016},isbn = \"\n '{978-1-4503-4206-3},location = {Denver, Colorado, USA},pages = '\n '{485--492},numpages = {8},url = '\n '{http://doi.acm.org/10.1145/2908812.2908918},doi = '\n '{10.1145/2908812.2908918},acmid = {2908918},publisher = {ACM},address = {New '\n 'York, NY, USA},']\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_TPOT/#user-metadata","title":"User metadata:","text":"<pre><code>{}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_TPOT/#metadata","title":"Metadata:","text":"tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_TPOT/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['numpy==1.23.5',\n            'pandas==1.5.1',\n            'jupyter==1.0.0',\n            'tpot==0.11.7',\n            'scikit-learn==1.2.2',\n            'matbench',\n            'joblib']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_TPOT/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_TPOT/#matbench_steels","title":"<code>matbench_steels</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_TPOT/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 105.6363 155.8008 0.0694 522.6191 fold_1 66.3154 90.4633 0.0478 373.0512 fold_2 78.2786 107.1225 0.0554 384.7484 fold_3 77.9677 102.4338 0.0576 279.6365 fold_4 71.5361 121.0169 0.0554 478.0417"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_TPOT/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 79.9468 105.6363 66.3154 13.5883 rmse 115.3675 155.8008 90.4633 22.4600 mape* 0.0571 0.0694 0.0478 0.0070 max_error 407.6194 522.6191 279.6365 85.1844"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_TPOT/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/","title":"matbench_v0.1: ALIGNN","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#algorithm-description","title":"Algorithm description:","text":"<p>The Atomistic Line Graph Neural Network (https://doi.org/10.1038/s41524-021-00650-1) introduces a new graph convolution layer that explicitly models both two and three body interactions in atomistic systems. This is achieved by composing two edge-gated graph convolution layers, the first applied to the atomistic line graph L(g) (representing triplet interactions) and the second applied to the atomistic bond graph g (representing pair interactions). The atomistic graph g consists of a node for each atom i (with atom/node representations hi), and one edge for each atom pair within a cutoff radius (with bond/pair representations eij). The atomistic line graph L(g) represents relationships between atom triplets: it has nodes corresponding to bonds (sharing representations eij with those in g) and edges corresponding to bond angles (with angle/triplet representations tijk).The line graph convolution updates the triplet representations and the pair representations; the direct graph convolution further updates the pair representations and the atom representations.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#notes","title":"Notes:","text":"<p>None</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>('@article{choudhary2021atomistic,title={Atomistic Line Graph Neural Network '\n 'for improved materials property predictions},author={Choudhary, Kamal and '\n 'DeCost, Brian},journal={npj Computational '\n 'Materials},volume={7},number={1},pages={1--8},year={2021},publisher={Nature '\n 'Publishing Group}}')\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#user-metadata","title":"User metadata:","text":"<pre><code>{'algorithm': 'ALIGNN'}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#metadata","title":"Metadata:","text":"tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['absl-py==1.0.0',\n            'alignn==2021.12.27',\n            'astunparse==1.6.3',\n            'attrs==21.3.0',\n            'black==21.12b0',\n            'cachetools==4.2.4',\n            'certifi==2021.10.8',\n            'charset-normalizer==2.0.9',\n            'click==8.0.3',\n            'cloudpickle==2.0.0',\n            'cycler==0.11.0',\n            'decorator==5.1.0',\n            'dgl==0.6.1',\n            'dgl-cu111==0.6.1',\n            'dm-tree==0.1.6',\n            'flake8==4.0.1',\n            'flatbuffers==2.0',\n            'fonttools==4.28.5',\n            'future==0.18.2',\n            'gast==0.4.0',\n            'google-auth==2.3.3',\n            'google-auth-oauthlib==0.4.6',\n            'google-pasta==0.2.0',\n            'grpcio==1.43.0',\n            'h5py==3.6.0',\n            'idna==3.3',\n            'importlib-metadata==4.10.0',\n            'importlib-resources==5.4.0',\n            'jarvis-tools==2021.12.16',\n            'joblib==1.1.0',\n            'jsonschema==4.3.2',\n            'julia==0.5.6',\n            'keras==2.7.0',\n            'Keras-Preprocessing==1.1.2',\n            'kiwisolver==1.3.2',\n            'libclang==12.0.0',\n            'Markdown==3.3.6',\n            'matbench==0.5',\n            'matminer==0.6.5',\n            'matplotlib==3.5.1',\n            'mccabe==0.6.1',\n            'modnet==0.1.11',\n            'monty==2021.8.17',\n            'mpmath==1.2.1',\n            'mypy-extensions==0.4.3',\n            'networkx==2.6.3',\n            'numpy==1.21.5',\n            'oauthlib==3.1.1',\n            'opt-einsum==3.3.0',\n            'packaging==21.3',\n            'palettable==3.3.0',\n            'pandas==1.3.5',\n            'pathspec==0.9.0',\n            'Pillow==8.4.0',\n            'Pint==0.18',\n            'platformdirs==2.4.0',\n            'plotly==5.5.0',\n            'protobuf==3.19.1',\n            'pyasn1==0.4.8',\n            'pyasn1-modules==0.2.8',\n            'pycodestyle==2.8.0',\n            'pydantic==1.8.2',\n            'pydocstyle==6.1.1',\n            'pyflakes==2.4.0',\n            'pymatgen==2020.8.13',\n            'pymongo==4.0.1',\n            'pyparsing==2.4.7',\n            'pyrsistent==0.18.0',\n            'python-dateutil==2.8.2',\n            'pytorch-ignite==0.4.7',\n            'pytz==2021.3',\n            'requests==2.26.0',\n            'requests-oauthlib==1.3.0',\n            'rsa==4.8',\n            'ruamel.yaml==0.17.19',\n            'ruamel.yaml.clib==0.2.6',\n            'scikit-learn==0.23.2',\n            'scipy==1.7.3',\n            'six==1.16.0',\n            'snowballstemmer==2.2.0',\n            'spglib==1.16.3',\n            'sympy==1.9',\n            'tabulate==0.8.9',\n            'tenacity==8.0.1',\n            'tensorboard==2.7.0',\n            'tensorboard-data-server==0.6.1',\n            'tensorboard-plugin-wit==1.8.0',\n            'tensorflow==2.7.0',\n            'tensorflow-estimator==2.7.0',\n            'tensorflow-io-gcs-filesystem==0.23.1',\n            'tensorflow-probability==0.15.0',\n            'termcolor==1.1.0',\n            'threadpoolctl==3.0.0',\n            'tomli==1.2.3',\n            'toolz==0.11.2',\n            'torch==1.10.1',\n            'tqdm==4.62.3',\n            'typing_extensions==4.0.1',\n            'uncertainties==3.1.6',\n            'urllib3==1.26.7',\n            'Werkzeug==2.0.2',\n            'wrapt==1.13.3',\n            'xmltodict==0.12.0',\n            'zipp==3.6.0']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_dielectric","title":"<code>matbench_dielectric</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.1974 0.6847 0.0700 13.6699 fold_1 0.3552 1.4949 0.1212 23.3832 fold_2 0.4551 3.1409 0.1035 58.7285 fold_3 0.3164 2.2413 0.0725 51.3719 fold_4 0.4005 2.2637 0.1258 36.5440"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.3449 0.4551 0.1974 0.0871 rmse 1.9651 3.1409 0.6847 0.8257 mape* 0.0986 0.1258 0.0700 0.0236 max_error 36.7395 58.7285 13.6699 16.7825"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_1 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_2 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_3 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_4 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_jdft2d","title":"<code>matbench_jdft2d</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-scores_1","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 37.0106 85.2042 23.4970 649.7056 fold_1 45.3752 121.0872 0.4163 767.6072 fold_2 58.3624 172.0326 0.6282 973.0735 fold_3 31.9625 55.3213 0.3025 275.8517 fold_4 44.4110 153.4614 0.5874 1519.7424"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-score-stats_1","title":"Fold score stats","text":"metric mean max min std mae 43.4244 58.3624 31.9625 8.9491 rmse 117.4213 172.0326 55.3213 42.8697 mape* 5.0863 23.4970 0.3025 9.2061 max_error 837.1961 1519.7424 275.8517 409.7401"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-parameters_1","title":"Fold parameters","text":"fold params dict fold_0 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_1 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_2 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_3 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_4 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_log_gvrh","title":"<code>matbench_log_gvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-scores_2","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0709 0.1093 0.0560 0.9401 fold_1 0.0725 0.1167 0.0587 1.1324 fold_2 0.0712 0.1122 0.0566 0.7799 fold_3 0.0710 0.1102 0.0558 0.8718 fold_4 0.0719 0.1133 0.0563 0.7814"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-score-stats_2","title":"Fold score stats","text":"metric mean max min std mae 0.0715 0.0725 0.0709 0.0006 rmse 0.1123 0.1167 0.1093 0.0026 mape* 0.0567 0.0587 0.0558 0.0011 max_error 0.9011 1.1324 0.7799 0.1303"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-parameters_2","title":"Fold parameters","text":"fold params dict fold_0 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_1 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_2 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_3 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_4 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_log_kvrh","title":"<code>matbench_log_kvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-scores_3","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0552 0.1062 0.0361 1.6438 fold_1 0.0572 0.1158 0.0375 1.3470 fold_2 0.0531 0.1017 0.0351 1.1254 fold_3 0.0615 0.1187 0.0442 1.1145 fold_4 0.0569 0.1105 0.0379 1.3937"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-score-stats_3","title":"Fold score stats","text":"metric mean max min std mae 0.0568 0.0615 0.0531 0.0028 rmse 0.1106 0.1187 0.1017 0.0062 mape* 0.0382 0.0442 0.0351 0.0032 max_error 1.3249 1.6438 1.1145 0.1955"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-parameters_3","title":"Fold parameters","text":"fold params dict fold_0 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_1 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_2 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_3 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_4 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_mp_e_form","title":"<code>matbench_mp_e_form</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-scores_4","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0218 0.0647 0.1437 3.5487 fold_1 0.0220 0.0534 0.1299 2.9160 fold_2 0.0209 0.0494 0.1434 2.1189 fold_3 0.0219 0.0546 0.1762 1.6654 fold_4 0.0210 0.0499 0.2528 1.4116"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-score-stats_4","title":"Fold score stats","text":"metric mean max min std mae 0.0215 0.0220 0.0209 0.0005 rmse 0.0544 0.0647 0.0494 0.0055 mape* 0.1692 0.2528 0.1299 0.0445 max_error 2.3321 3.5487 1.4116 0.7948"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-parameters_4","title":"Fold parameters","text":"fold params dict fold_0 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_1 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_2 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_3 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_4 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_mp_gap","title":"<code>matbench_mp_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-scores_5","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.1860 0.4624 2.3206 6.6263 fold_1 0.1852 0.4622 2.5314 7.4756 fold_2 0.1901 0.4729 4.2501 6.2931 fold_3 0.1812 0.4497 5.1591 6.9986 fold_4 0.1880 0.4703 4.8122 6.4513"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-score-stats_5","title":"Fold score stats","text":"metric mean max min std mae 0.1861 0.1901 0.1812 0.0030 rmse 0.4635 0.4729 0.4497 0.0081 mape* 3.8147 5.1591 2.3206 1.1723 max_error 6.7690 7.4756 6.2931 0.4242"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-parameters_5","title":"Fold parameters","text":"fold params dict fold_0 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_1 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_2 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_3 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_4 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_mp_is_metal","title":"<code>matbench_mp_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-scores_6","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9173 0.9156 0.9047 0.9156 fold_1 0.9135 0.9117 0.9003 0.9117 fold_2 0.9146 0.9125 0.9013 0.9125 fold_3 0.9135 0.9117 0.9003 0.9117 fold_4 0.9147 0.9123 0.9012 0.9123"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-score-stats_6","title":"Fold score stats","text":"metric mean max min std accuracy 0.9147 0.9173 0.9135 0.0014 balanced_accuracy 0.9128 0.9156 0.9117 0.0015 f1 0.9015 0.9047 0.9003 0.0016 rocauc 0.9128 0.9156 0.9117 0.0015"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-parameters_6","title":"Fold parameters","text":"fold params dict fold_0 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_1 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_2 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_3 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_4 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_perovskites","title":"<code>matbench_perovskites</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-scores_7","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0293 0.0577 0.0292 0.8306 fold_1 0.0301 0.0622 0.0291 0.9028 fold_2 0.0276 0.0509 0.0274 0.8358 fold_3 0.0286 0.0532 0.0276 0.7984 fold_4 0.0282 0.0558 0.0253 0.8666"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-score-stats_7","title":"Fold score stats","text":"metric mean max min std mae 0.0288 0.0301 0.0276 0.0009 rmse 0.0559 0.0622 0.0509 0.0039 mape* 0.0277 0.0292 0.0253 0.0014 max_error 0.8468 0.9028 0.7984 0.0354"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-parameters_7","title":"Fold parameters","text":"fold params dict fold_0 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_1 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_2 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_3 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_4 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#matbench_phonons","title":"<code>matbench_phonons</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-scores_8","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 33.4099 57.5251 0.0623 394.6285 fold_1 28.0306 44.1719 0.0571 277.0146 fold_2 29.4772 53.9163 0.0575 300.2450 fold_3 29.4931 62.0127 0.0571 615.3466 fold_4 27.2814 49.8790 0.0521 528.2511"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-score-stats_8","title":"Fold score stats","text":"metric mean max min std mae 29.5385 33.4099 27.2814 2.1148 rmse 53.5010 62.0127 44.1719 6.1476 mape* 0.0572 0.0623 0.0521 0.0032 max_error 423.0972 615.3466 277.0146 130.5836"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_alignn/#fold-parameters_8","title":"Fold parameters","text":"fold params dict fold_0 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_1 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_2 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_3 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code> fold_4 <code>{'atom_features': 'cgcnn', 'batch_size': 2, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': 'user_data', 'epochs': 3, 'filename': 'sample', 'id_tag': 'jid', 'keep_data_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/","title":"matbench_v0.1: AMMExpress v2020","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#algorithm-description","title":"Algorithm description:","text":"<p>Automatminer express v1.03.20200727. Based on automatic featurization, tree-based feature reduction, and genetic-algorithm based AutoML with the TPOT package.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#notes","title":"Notes:","text":"<p>All data was generated using the same config (express, default). The automatminer version requirement specifies the versions of many dependent packages, such as matminer, which are required for the algorithm to work in your virtualenv.</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>('@article{Dunn2020,\\n'\n '  doi = {10.1038/s41524-020-00406-3},\\n'\n '  url = {https://doi.org/10.1038/s41524-020-00406-3},\\n'\n '  year = {2020},\\n'\n '  month = sep,\\n'\n '  publisher = {Springer Science and Business Media {LLC}},\\n'\n '  volume = {6},\\n'\n '  number = {1},\\n'\n '  author = {Alexander Dunn and Qi Wang and Alex Ganose and Daniel Dopp and '\n 'Anubhav Jain},\\n'\n '  title = {Benchmarking materials property prediction methods: the Matbench '\n 'test set and Automatminer reference algorithm},\\n'\n '  journal = {npj Computational Materials}\\n'\n '}')\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#user-metadata","title":"User metadata:","text":"<pre><code>{'autofeaturizer_kwargs': {'n_jobs': 10, 'preset': 'express'},\n 'cleaner_kwargs': {'feature_na_method': 'drop',\n                    'max_na_frac': 0.1,\n                    'na_method_fit': 'mean',\n                    'na_method_transform': 'mean'},\n 'learner_kwargs': {'max_eval_time_mins': 20,\n                    'max_time_mins': 1440,\n                    'memory': 'auto',\n                    'n_jobs': 10,\n                    'population_size': 200},\n 'learner_name': 'TPOTAdaptor',\n 'reducer_kwargs': {'reducers': ['corr', 'tree'],\n                    'tree_importance_percentile': 0.99}}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#metadata","title":"Metadata:","text":"tasks recorded 13/13 complete? \u2713 composition complete? \u2713 structure complete? \u2713 regression complete? \u2713 classification complete? \u2713"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['automatminer==1.0.3.20200727', 'matbench==0.1.0']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_dielectric","title":"<code>matbench_dielectric</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2188 0.6855 0.0760 14.6654 fold_1 0.2844 1.0764 0.0899 19.6283 fold_2 0.4257 2.9472 0.0889 59.0112 fold_3 0.3198 2.2782 0.0720 53.5196 fold_4 0.3264 1.6137 0.0987 28.1601"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.3150 0.4257 0.2188 0.0672 rmse 1.7202 2.9472 0.6855 0.8140 mape* 0.0851 0.0987 0.0720 0.0098 max_error 34.9969 59.0112 14.6654 17.9782"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.006, score_func=&lt;function f_regression at 0x2aaaef1a0840&gt;))', '(robustscaler, RobustScaler(copy=true, quantile_range=(25.0, 75.0), with_centering=true...</code> fold_1 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(zerocount, ZeroCount())', '(gradientboostingregressor, GradientBoostingRegressor(alpha=0.75, criterion=friedman_mse, in...</code> fold_2 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.001))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(gradientboostingregressor, GradientBoostingRegressor(al...</code> fold_3 <code>{'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.023, score_func=&lt;function f_regression at 0x2aaaef19f950&gt;))', '(standardscaler, StandardScaler(copy=true, with_mean=true, with_std=true))', '(gradient...</code> fold_4 <code>{'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.034, score_func=&lt;function f_regression at 0x2aaaf35a08c8&gt;))', '(zerocount, ZeroCount())', '(gradientboostingregressor, GradientBoostingRegressor(alpha...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_expt_gap","title":"<code>matbench_expt_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_1","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.3998 0.9435 0.3372 8.0111 fold_1 0.4061 0.9354 0.3085 8.6887 fold_2 0.4538 1.0955 0.3916 12.7533 fold_3 0.4061 1.0273 0.3019 12.6296 fold_4 0.4150 0.9573 0.4503 6.0779"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_1","title":"Fold score stats","text":"metric mean max min std mae 0.4161 0.4538 0.3998 0.0194 rmse 0.9918 1.0955 0.9354 0.0612 mape* 0.3579 0.4503 0.3019 0.0560 max_error 9.6321 12.7533 6.0779 2.6411"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_1","title":"Fold parameters","text":"fold params dict fold_0 <code>{'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.035, score_func=&lt;function f_regression at 0x2aaaf35a18c8&gt;))', '(standardscaler, StandardScaler(copy=true, with_mean=true, with_std=true))', '(gradient...</code> fold_1 <code>{'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.046, score_func=&lt;function f_regression at 0x2aaaef19f8c8&gt;))', '(onehotencoder, OneHotEncoder(categorical_features=[false, false, false, false, false, ...</code> fold_2 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0005))', '(robustscaler, RobustScaler(copy=true, quantile_range=(25.0, 75.0), with_centering=true,\\n             with_scaling=true...</code> fold_3 <code>{'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=85,\\n                 score_func=&lt;function f_regression at 0x2aaaf39a38c8&gt;))', '(onehotencoder, OneHotEncoder(categorical_features=[f...</code> fold_4 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0005))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(randomforestregressor, RandomForestRegressor(bootstrap=false, criterion=mse,...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_expt_is_metal","title":"<code>matbench_expt_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_2","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9218 0.9218 0.9205 0.9218 fold_1 0.9157 0.9156 0.9145 0.9156 fold_2 0.9207 0.9207 0.9193 0.9207 fold_3 0.9228 0.9228 0.9223 0.9228 fold_4 0.9238 0.9238 0.9235 0.9238"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_2","title":"Fold score stats","text":"metric mean max min std accuracy 0.9210 0.9238 0.9157 0.0028 balanced_accuracy 0.9209 0.9238 0.9156 0.0028 f1 0.9200 0.9235 0.9145 0.0031 rocauc 0.9209 0.9238 0.9156 0.0028"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_2","title":"Fold parameters","text":"fold params dict fold_0 <code>{'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.009000000000000001,\\n          score_func=&lt;function f_classif at 0x2aaaf35a16a8&gt;))', '(onehotencoder, OneHotEncoder(categorical_features=[false, false...</code> fold_1 <code>{'best_pipeline': ['(rfe, RFE(estimator=ExtraTreesClassifier(bootstrap=false, class_weight=null,\\n                                   criterion=gini, max_depth=null,\\n                                  ...</code> fold_2 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.001))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(gradientboostingclassifier, GradientBoostingClassifier(criterion=friedman_mse...</code> fold_3 <code>{'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.03, score_func=&lt;function f_classif at 0x2aaaf35a0730&gt;))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(gradientboostingclassifier, GradientBoostingCla...</code> fold_4 <code>{'best_pipeline': ['(rfe, RFE(estimator=ExtraTreesClassifier(bootstrap=false, class_weight=null,\\n                                   criterion=entropy, max_depth=null,\\n                               ...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_glass","title":"<code>matbench_glass</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_3","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.8283 0.8441 0.8697 0.8441 fold_1 0.8125 0.8383 0.8548 0.8383 fold_2 0.8574 0.8546 0.8956 0.8546 fold_3 0.9173 0.8742 0.9437 0.8742 fold_4 0.9375 0.8921 0.9579 0.8921"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_3","title":"Fold score stats","text":"metric mean max min std accuracy 0.8706 0.9375 0.8125 0.0490 balanced_accuracy 0.8607 0.8921 0.8383 0.0199 f1 0.9043 0.9579 0.8548 0.0404 rocauc 0.8607 0.8921 0.8383 0.0199"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_3","title":"Fold parameters","text":"fold params dict fold_0 <code>{'best_pipeline': ['(selectfrommodel, SelectFromModel(estimator=ExtraTreesClassifier(bootstrap=false,\\n                                               class_weight=null,\\n                              ...</code> fold_1 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(standardscaler, StandardScaler(copy=true, with_mean=true, with_std=true))', '(extratreesclassifier, ExtraTreesClassifie...</code> fold_2 <code>{'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=74,\\n                 score_func=&lt;function f_classif at 0x2aaaf35a0730&gt;))', '(onehotencoder, OneHotEncoder(categorical_features=[fals...</code> fold_3 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(standardscaler, StandardScaler(copy=true, with_mean=true, with_std=true))', '(gradientboostingclassifier, GradientBoost...</code> fold_4 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(standardscaler, StandardScaler(copy=true, with_mean=true, with_std=true))', '(gradientboostingclassifier, GradientBoost...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_jdft2d","title":"<code>matbench_jdft2d</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_4","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 29.5070 57.7719 18.9726 362.2752 fold_1 44.3036 98.1137 0.3191 551.7742 fold_2 54.4690 164.0162 0.5117 847.0618 fold_3 28.0759 55.8345 0.2371 316.2185 fold_4 42.8931 156.9938 0.5429 1552.9102"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_4","title":"Fold score stats","text":"metric mean max min std mae 39.8497 54.4690 28.0759 9.8835 rmse 106.5460 164.0162 55.8345 46.6251 mape* 4.1167 18.9726 0.2371 7.4289 max_error 726.0480 1552.9102 316.2185 453.6535"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_4","title":"Fold parameters","text":"fold params dict fold_0 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(gradientboostingregressor, GradientBoostingRegressor(alph...</code> fold_1 <code>{'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=40,\\n                 score_func=&lt;function f_regression at 0x2aaaf35a08c8&gt;))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(gradientb...</code> fold_2 <code>{'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=62,\\n                 score_func=&lt;function f_regression at 0x2aaaf35a08c8&gt;))', '(onehotencoder, OneHotEncoder(categorical_features=[f...</code> fold_3 <code>{'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=82,\\n                 score_func=&lt;function f_regression at 0x2aab561f6620&gt;))', '(robustscaler, RobustScaler(copy=true, quantile_range...</code> fold_4 <code>{'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=62,\\n                 score_func=&lt;function f_regression at 0x2aaaf35a08c8&gt;))', '(zerocount, ZeroCount())', '(gradientboostingregresso...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_log_gvrh","title":"<code>matbench_log_gvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_5","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0891 0.1270 0.0692 1.1580 fold_1 0.0852 0.1261 0.0666 1.0887 fold_2 0.0849 0.1261 0.0668 0.9631 fold_3 0.0884 0.1279 0.0670 0.8959 fold_4 0.0894 0.1313 0.0690 0.9810"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_5","title":"Fold score stats","text":"metric mean max min std mae 0.0874 0.0894 0.0849 0.0020 rmse 0.1277 0.1313 0.1261 0.0019 mape* 0.0677 0.0692 0.0666 0.0012 max_error 1.0173 1.1580 0.8959 0.0937"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_5","title":"Fold parameters","text":"fold params dict fold_0 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.2))', '(zerocount, ZeroCount())', '(gradientboostingregressor, GradientBoostingRegressor(alpha=0.99, criterion=friedman_mse, init=...</code> fold_1 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.01))', '(robustscaler, RobustScaler(copy=true, quantile_range=(25.0, 75.0), with_centering=true,\\n             with_scaling=true))...</code> fold_2 <code>{'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.01, score_func=&lt;function f_regression at 0x2aaaef19e8c8&gt;))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(randomforestregressor,...</code> fold_3 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(standardscaler, StandardScaler(copy=true, with_mean=true, with_std=true))', '(gradientboostingregressor, GradientBoosti...</code> fold_4 <code>{'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=96,\\n                 score_func=&lt;function f_regression at 0x2aaaf35a08c8&gt;))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(extratree...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_log_kvrh","title":"<code>matbench_log_kvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_6","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0639 0.1179 0.0417 1.4823 fold_1 0.0659 0.1231 0.0432 1.2686 fold_2 0.0627 0.1115 0.0411 1.1316 fold_3 0.0668 0.1217 0.0464 1.1890 fold_4 0.0640 0.1172 0.0417 1.4335"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_6","title":"Fold score stats","text":"metric mean max min std mae 0.0647 0.0668 0.0627 0.0015 rmse 0.1183 0.1231 0.1115 0.0041 mape* 0.0428 0.0464 0.0411 0.0019 max_error 1.3010 1.4823 1.1316 0.1362"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_6","title":"Fold parameters","text":"fold params dict fold_0 <code>{'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.032, score_func=&lt;function f_regression at 0x2aaaf35a2840&gt;))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(extratreesregressor, ...</code> fold_1 <code>{'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.029, score_func=&lt;function f_regression at 0x2aaaf35a08c8&gt;))', '(zerocount, ZeroCount())', '(gradientboostingregressor, GradientBoostingRegressor(alpha...</code> fold_2 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.2))', '(onehotencoder, OneHotEncoder(categorical_features=[false, false, false, false, false, false,\\n                            ...</code> fold_3 <code>{'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.016, score_func=&lt;function f_regression at 0x2aaaf79a28c8&gt;))', '(onehotencoder, OneHotEncoder(categorical_features=[false, false, false, false, false, ...</code> fold_4 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(extratreesregressor, ExtraTreesRegressor(bootstrap=fal...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_mp_e_form","title":"<code>matbench_mp_e_form</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_7","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.1586 0.2508 1.0829 4.0713 fold_1 0.2026 0.2955 0.9253 5.8108 fold_2 0.1473 0.2256 0.7722 2.7696 fold_3 0.2080 0.3062 1.3958 5.5190 fold_4 0.1467 0.2226 0.8028 3.3888"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_7","title":"Fold score stats","text":"metric mean max min std mae 0.1726 0.2080 0.1467 0.0270 rmse 0.2602 0.3062 0.2226 0.0348 mape* 0.9958 1.3958 0.7722 0.2280 max_error 4.3119 5.8108 2.7696 1.1826"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_7","title":"Fold parameters","text":"fold params dict fold_0 <code>{'best_pipeline': ['(gradientboostingregressor, GradientBoostingRegressor(alpha=0.75, criterion=friedman_mse, init=null,\\n             learning_rate=0.5, loss=huber, max_depth=5,\\n             max_fea...</code> fold_1 <code>{'best_pipeline': ['(polynomialfeatures, PolynomialFeatures(degree=2, include_bias=false, interaction_only=false))', '(pca, PCA(copy=true, iterated_power=3, n_components=null, random_state=null,\\n  sv...</code> fold_2 <code>{'best_pipeline': ['(stackingestimator, StackingEstimator(estimator=GradientBoostingRegressor(alpha=0.9, criterion=friedman_mse, init=null,\\n             learning_rate=0.5, loss=huber, max_depth=4,\\n ...</code> fold_3 <code>{'best_pipeline': ['(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(selectfwe, SelectFwe(alpha=0.027, score_func=&lt;function f_regression at 0x2b2eb18422f0&gt;))', '(stackingestimator, St...</code> fold_4 <code>{'best_pipeline': ['(xgbregressor, XGBRegressor(base_score=0.5, booster=gbtree, colsample_bylevel=1,\\n       colsample_bytree=1, gamma=0, learning_rate=0.5, max_delta_step=0,\\n       max_depth=5, min_...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_mp_gap","title":"<code>matbench_mp_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_8","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2799 0.5481 3.5712 5.4792 fold_1 0.2850 0.5671 3.1533 6.9105 fold_2 0.2724 0.5477 4.6097 6.2045 fold_3 0.2909 0.5710 10.0191 6.4590 fold_4 0.2837 0.5714 6.8322 5.5333"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_8","title":"Fold score stats","text":"metric mean max min std mae 0.2824 0.2909 0.2724 0.0061 rmse 0.5611 0.5714 0.5477 0.0109 mape* 5.6371 10.0191 3.1533 2.5347 max_error 6.1173 6.9105 5.4792 0.5480"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_8","title":"Fold parameters","text":"fold params dict fold_0 <code>{'best_pipeline': ['(stackingestimator-1, StackingEstimator(estimator=RandomForestRegressor(bootstrap=false, criterion=mse, max_depth=null,\\n           max_features=0.4, max_leaf_nodes=null,\\n        ...</code> fold_1 <code>{'best_pipeline': ['(stackingestimator-1, StackingEstimator(estimator=RandomForestRegressor(bootstrap=true, criterion=mse, max_depth=null,\\n           max_features=0.35000000000000003, max_leaf_nodes=...</code> fold_2 <code>{'best_pipeline': ['(stackingestimator-1, StackingEstimator(estimator=RandomForestRegressor(bootstrap=false, criterion=mse, max_depth=null,\\n           max_features=0.45, max_leaf_nodes=null,\\n       ...</code> fold_3 <code>{'best_pipeline': ['(stackingestimator-1, StackingEstimator(estimator=ExtraTreesRegressor(bootstrap=false, criterion=mse, max_depth=null,\\n          max_features=0.45, max_leaf_nodes=null,\\n          ...</code> fold_4 <code>{'best_pipeline': ['(stackingestimator-1, StackingEstimator(estimator=GradientBoostingRegressor(alpha=0.85, criterion=friedman_mse, init=null,\\n             learning_rate=0.01, loss=lad, max_depth=1,\\...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_mp_is_metal","title":"<code>matbench_mp_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_9","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9133 0.9094 0.8982 0.9094 fold_1 0.9123 0.9086 0.8972 0.9086 fold_2 0.9129 0.9089 0.8976 0.9089 fold_3 0.9146 0.9108 0.8998 0.9108 fold_4 0.9129 0.9086 0.8974 0.9086"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_9","title":"Fold score stats","text":"metric mean max min std accuracy 0.9132 0.9146 0.9123 0.0008 balanced_accuracy 0.9093 0.9108 0.9086 0.0008 f1 0.8981 0.8998 0.8972 0.0009 rocauc 0.9093 0.9108 0.9086 0.0008"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_9","title":"Fold parameters","text":"fold params dict fold_0 <code>{'best_pipeline': ['(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(randomforestclassifier, RandomForestClassifier(bootstrap=false, class_weight=null,\\n            criterion=entropy,...</code> fold_1 <code>{'best_pipeline': ['(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(randomforestclassifier, RandomForestClassifier(bootstrap=false, class_weight=null,\\n            criterion=entropy,...</code> fold_2 <code>{'best_pipeline': ['(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(randomforestclassifier, RandomForestClassifier(bootstrap=false, class_weight=null,\\n            criterion=entropy,...</code> fold_3 <code>{'best_pipeline': ['(stackingestimator, StackingEstimator(estimator=RandomForestClassifier(bootstrap=false, class_weight=null,\\n            criterion=entropy, max_depth=null, max_features=0.5,\\n      ...</code> fold_4 <code>{'best_pipeline': ['(featureunion, FeatureUnion(n_jobs=null,\\n       transformer_list=[(functiontransformer, FunctionTransformer(accept_sparse=false, check_inverse=true,\\n          func=&lt;function copy...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_perovskites","title":"<code>matbench_perovskites</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_10","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2159 0.3114 0.2077 2.7651 fold_1 0.1904 0.2857 0.1944 2.6783 fold_2 0.1962 0.2869 0.1933 2.4466 fold_3 0.1992 0.2907 0.2209 3.3116 fold_4 0.2006 0.3023 0.1886 2.4386"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_10","title":"Fold score stats","text":"metric mean max min std mae 0.2005 0.2159 0.1904 0.0085 rmse 0.2954 0.3114 0.2857 0.0099 mape* 0.2010 0.2209 0.1886 0.0118 max_error 2.7280 3.3116 2.4386 0.3186"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_10","title":"Fold parameters","text":"fold params dict fold_0 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(robustscaler, RobustScaler(copy=true, quantile_range=(25.0, 75.0), with_centering=true,\\n             with_scaling=true))'...</code> fold_1 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(zerocount, ZeroCount())', '(randomforestregressor, RandomForestRegressor(bootstrap=false, criterion=mse, max_depth=null,\\n...</code> fold_2 <code>{'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.03, score_func=&lt;function f_regression at 0x2aaaf35a08c8&gt;))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(gradientboostingregres...</code> fold_3 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(robustscaler, RobustScaler(copy=true, quantile_range=(25.0, 75.0), with_centering=true,\\n             with_scaling=true))'...</code> fold_4 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.05))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(randomforestregressor, RandomForestRegressor(bootstrap=false, criterion=mse, m...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_phonons","title":"<code>matbench_phonons</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_11","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 67.5727 146.7970 0.1079 1151.5570 fold_1 54.0755 100.2097 0.1048 890.4159 fold_2 50.9853 96.5991 0.0931 680.9361 fold_3 59.6458 127.8555 0.1142 926.0969 fold_4 48.5738 77.0626 0.0958 383.1912"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_11","title":"Fold score stats","text":"metric mean max min std mae 56.1706 67.5727 48.5738 6.7981 rmse 109.7048 146.7970 77.0626 24.6280 mape* 0.1032 0.1142 0.0931 0.0078 max_error 806.4394 1151.5570 383.1912 258.9850"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_11","title":"Fold parameters","text":"fold params dict fold_0 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.01))', '(robustscaler, RobustScaler(copy=true, quantile_range=(25.0, 75.0), with_centering=true,\\n             with_scaling=true))...</code> fold_1 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.005))', '(maxabsscaler, MaxAbsScaler(copy=true))', '(gradientboostingregressor, GradientBoostingRegressor(alpha=0.8, criterion=fri...</code> fold_2 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(extratreesregressor, ExtraTreesRegressor(bootstrap=false,...</code> fold_3 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.0001))', '(onehotencoder, OneHotEncoder(categorical_features=[false, false, false, false, false, false,\\n                         ...</code> fold_4 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.2))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(extratreesregressor, ExtraTreesRegressor(bootstrap=false,...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#matbench_steels","title":"<code>matbench_steels</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-scores_12","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 109.3058 188.8049 0.0693 1082.7703 fold_1 80.4188 109.2771 0.0569 416.3620 fold_2 83.5360 120.2935 0.0607 424.5913 fold_3 98.7186 136.5898 0.0722 473.4563 fold_4 115.4851 215.1149 0.0891 1142.9223"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-score-stats_12","title":"Fold score stats","text":"metric mean max min std mae 97.4929 115.4851 80.4188 13.7919 rmse 154.0161 215.1149 109.2771 40.9531 mape* 0.0696 0.0891 0.0569 0.0112 max_error 708.0205 1142.9223 416.3620 331.6607"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_automatminer_expressv2020/#fold-parameters_12","title":"Fold parameters","text":"fold params dict fold_0 <code>{'best_pipeline': ['(selectfrommodel, SelectFromModel(estimator=ExtraTreesRegressor(bootstrap=false, criterion=mse,\\n                                              max_depth=null,\\n                    ...</code> fold_1 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(fastica, FastICA(algorithm=parallel, fun=logcosh, fun_args=null, max_iter=200,\\n        n_components=null, random_state=nu...</code> fold_2 <code>{'best_pipeline': ['(selectpercentile, SelectPercentile(percentile=53,\\n                 score_func=&lt;function f_regression at 0x2aaaf79a38c8&gt;))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=...</code> fold_3 <code>{'best_pipeline': ['(variancethreshold, VarianceThreshold(threshold=0.1))', '(minmaxscaler, MinMaxScaler(copy=true, feature_range=(0, 1)))', '(kneighborsregressor, KNeighborsRegressor(algorithm=auto, ...</code> fold_4 <code>{'best_pipeline': ['(selectfrommodel, SelectFromModel(estimator=ExtraTreesRegressor(bootstrap=false, criterion=mse,\\n                                              max_depth=null,\\n                    ...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/","title":"matbench_v0.1: CGCNN v2019","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#algorithm-description","title":"Algorithm description:","text":"<p>Convolutional graph neural network, in it's original implementation as in https://github.com/txie-93/cgcnn. Utility modifications were made in order to run CGCNN without error across all structure tasks. Adapted from data originally taken from Dunn et. al 'Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm' (2020). Training was performed using one NVIDIA 1080Ti GPU using CUDA (accompanied by two Intel Xeon E5-2623 CPUs with 60GB RAM). Each outer NCV training set was split 75/25 for train/validation; thus the final split for each fold was 60% train, 20% validation, 20% test. Each model is trained in epochs of 128-structure batches by optimizing according to mean squared error loss (regression) or binary cross-entropy (classification). After each epoch, the validation loss is computed with the same scoring functions as the final evaluation: MAE for regression or ROC-AUC for classification (made negative so that higher loss represents worse performance). To prevent overfitting, the training is stopped early when the validation loss does not improve over a period of at least 500 epochs.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#notes","title":"Notes:","text":"<p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>['@article{Xie2018,\\n'\n '  doi = {10.1103/physrevlett.120.145301},\\n'\n '  url = {https://doi.org/10.1103/physrevlett.120.145301},\\n'\n '  year = {2018},\\n'\n '  month = apr,\\n'\n '  publisher = {American Physical Society ({APS})},\\n'\n '  volume = {120},\\n'\n '  number = {14},\\n'\n '  author = {Tian Xie and Jeffrey C. Grossman},\\n'\n '  title = {Crystal Graph Convolutional Neural Networks for an Accurate and '\n 'Interpretable Prediction of Material Properties},\\n'\n '  journal = {Physical Review Letters}\\n'\n '}',\n '@article{Dunn2020,\\n'\n '  doi = {10.1038/s41524-020-00406-3},\\n'\n '  url = {https://doi.org/10.1038/s41524-020-00406-3},\\n'\n '  year = {2020},\\n'\n '  month = sep,\\n'\n '  publisher = {Springer Science and Business Media {LLC}},\\n'\n '  volume = {6},\\n'\n '  number = {1},\\n'\n '  author = {Alexander Dunn and Qi Wang and Alex Ganose and Daniel Dopp and '\n 'Anubhav Jain},\\n'\n '  title = {Benchmarking materials property prediction methods: the Matbench '\n 'test set and Automatminer reference algorithm},\\n'\n '  journal = {npj Computational Materials}\\n'\n '}']\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#user-metadata","title":"User metadata:","text":"<pre><code>{'conv_to_fc.bias': 32,\n 'conv_to_fc.weight': 2048,\n 'convs.0.bn1.bias': 128,\n 'convs.0.bn1.num_batches_tracked': 1,\n 'convs.0.bn1.running_mean': 128,\n 'convs.0.bn1.running_var': 128,\n 'convs.0.bn1.weight': 128,\n 'convs.0.bn2.bias': 64,\n 'convs.0.bn2.num_batches_tracked': 1,\n 'convs.0.bn2.running_mean': 64,\n 'convs.0.bn2.running_var': 64,\n 'convs.0.bn2.weight': 64,\n 'convs.0.fc_full.bias': 128,\n 'convs.0.fc_full.weight': 21632,\n 'convs.1.bn1.bias': 128,\n 'convs.1.bn1.num_batches_tracked': 1,\n 'convs.1.bn1.running_mean': 128,\n 'convs.1.bn1.running_var': 128,\n 'convs.1.bn1.weight': 128,\n 'convs.1.bn2.bias': 64,\n 'convs.1.bn2.num_batches_tracked': 1,\n 'convs.1.bn2.running_mean': 64,\n 'convs.1.bn2.running_var': 64,\n 'convs.1.bn2.weight': 64,\n 'convs.1.fc_full.bias': 128,\n 'convs.1.fc_full.weight': 21632,\n 'convs.2.bn1.bias': 128,\n 'convs.2.bn1.num_batches_tracked': 1,\n 'convs.2.bn1.running_mean': 128,\n 'convs.2.bn1.running_var': 128,\n 'convs.2.bn1.weight': 128,\n 'convs.2.bn2.bias': 64,\n 'convs.2.bn2.num_batches_tracked': 1,\n 'convs.2.bn2.running_mean': 64,\n 'convs.2.bn2.running_var': 64,\n 'convs.2.bn2.weight': 64,\n 'convs.2.fc_full.bias': 128,\n 'convs.2.fc_full.weight': 21632,\n 'convs.3.bn1.bias': 128,\n 'convs.3.bn1.num_batches_tracked': 1,\n 'convs.3.bn1.running_mean': 128,\n 'convs.3.bn1.running_var': 128,\n 'convs.3.bn1.weight': 128,\n 'convs.3.bn2.bias': 64,\n 'convs.3.bn2.num_batches_tracked': 1,\n 'convs.3.bn2.running_mean': 64,\n 'convs.3.bn2.running_var': 64,\n 'convs.3.bn2.weight': 64,\n 'convs.3.fc_full.bias': 128,\n 'convs.3.fc_full.weight': 21632,\n 'embedding.bias': 64,\n 'embedding.weight': 5888,\n 'fc_out.bias': 1,\n 'fc_out.weight': 32}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#metadata","title":"Metadata:","text":"tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['https://github.com/txie-93/cgcnn',\n            'numpy==1.20.1',\n            'matbench==0.1.0']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_dielectric","title":"<code>matbench_dielectric</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.4704 0.9059 0.1949 14.6895 fold_1 0.5724 1.2825 0.2222 20.3729 fold_2 0.7301 3.0600 0.2194 58.9996 fold_3 0.6111 2.4214 0.2119 53.4782 fold_4 0.6099 1.8183 0.2348 28.6714"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.5988 0.7301 0.4704 0.0833 rmse 1.8976 3.0600 0.9059 0.7738 mape* 0.2167 0.2348 0.1949 0.0131 max_error 35.2423 58.9996 14.6895 17.7969"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_jdft2d","title":"<code>matbench_jdft2d</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-scores_1","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 34.4937 56.8278 33.7683 256.0330 fold_1 51.1167 98.1228 0.5027 407.6809 fold_2 69.4250 182.5647 0.6043 1061.5574 fold_3 42.7453 71.8811 0.4072 303.9963 fold_4 48.4396 154.4480 0.6338 1516.9120"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-score-stats_1","title":"Fold score stats","text":"metric mean max min std mae 49.2440 69.4250 34.4937 11.5865 rmse 112.7689 182.5647 56.8278 48.2169 mape* 7.1833 33.7683 0.4072 13.2927 max_error 709.2359 1516.9120 256.0330 497.3969"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-parameters_1","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_log_gvrh","title":"<code>matbench_log_gvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-scores_2","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0870 0.1270 0.0680 1.0473 fold_1 0.0899 0.1384 0.0714 1.4520 fold_2 0.0887 0.1323 0.0699 1.0024 fold_3 0.0902 0.1344 0.0705 0.9712 fold_4 0.0918 0.1362 0.0712 0.8430"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-score-stats_2","title":"Fold score stats","text":"metric mean max min std mae 0.0895 0.0918 0.0870 0.0016 rmse 0.1337 0.1384 0.1270 0.0039 mape* 0.0702 0.0714 0.0680 0.0012 max_error 1.0632 1.4520 0.8430 0.2059"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-parameters_2","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_log_kvrh","title":"<code>matbench_log_kvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-scores_3","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0702 0.1290 0.0456 1.7725 fold_1 0.0722 0.1353 0.0477 1.3813 fold_2 0.0665 0.1191 0.0423 1.1052 fold_3 0.0748 0.1341 0.0517 1.1231 fold_4 0.0724 0.1328 0.0480 1.5001"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-score-stats_3","title":"Fold score stats","text":"metric mean max min std mae 0.0712 0.0748 0.0665 0.0028 rmse 0.1301 0.1353 0.1191 0.0059 mape* 0.0471 0.0517 0.0423 0.0031 max_error 1.3765 1.7725 1.1052 0.2490"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-parameters_3","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_mp_e_form","title":"<code>matbench_mp_e_form</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-scores_4","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0340 0.0714 0.4273 3.4254 fold_1 0.0340 0.0681 0.1934 2.0786 fold_2 0.0328 0.0756 0.2075 7.7205 fold_3 0.0332 0.0623 0.2258 1.3283 fold_4 0.0346 0.0633 0.2830 1.5782"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-score-stats_4","title":"Fold score stats","text":"metric mean max min std mae 0.0337 0.0346 0.0328 0.0006 rmse 0.0682 0.0756 0.0623 0.0050 mape* 0.2674 0.4273 0.1934 0.0855 max_error 3.2262 7.7205 1.3283 2.3611"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-parameters_4","title":"Fold parameters","text":"fold params dict fold_0 <code>{'training_mae': 0.020714398227129675, 'training_n_samples': 79650, 'validation_mae': 0.03311641346102554, 'validation_n_samples': 26551}</code> fold_1 <code>{'training_mae': 0.020727165395357502, 'training_n_samples': 79650, 'validation_mae': 0.03387322865233633, 'validation_n_samples': 26551}</code> fold_2 <code>{'training_mae': 0.020593563770909047, 'training_n_samples': 79651, 'validation_mae': 0.033246301549184044, 'validation_n_samples': 26551}</code> fold_3 <code>{'training_mae': 0.020858287502723834, 'training_n_samples': 79651, 'validation_mae': 0.03272479726288639, 'validation_n_samples': 26551}</code> fold_4 <code>{'training_mae': 0.0220815778646356, 'training_n_samples': 79651, 'validation_mae': 0.03445024667244967, 'validation_n_samples': 26551}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_mp_gap","title":"<code>matbench_mp_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-scores_5","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2978 0.6753 3.5253 7.2169 fold_1 0.2939 0.6827 3.3933 13.6569 fold_2 0.2960 0.6653 5.5089 6.8339 fold_3 0.2947 0.6740 7.7018 7.7523 fold_4 0.3038 0.6884 5.7405 7.7166"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-score-stats_5","title":"Fold score stats","text":"metric mean max min std mae 0.2972 0.3038 0.2939 0.0035 rmse 0.6771 0.6884 0.6653 0.0079 mape* 5.1740 7.7018 3.3933 1.5945 max_error 8.6353 13.6569 6.8339 2.5336"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-parameters_5","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_mp_is_metal","title":"<code>matbench_mp_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-scores_6","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9590 0.9578 0.9526 0.9578 fold_1 0.9450 0.9432 0.9363 0.9432 fold_2 0.9643 0.9632 0.9588 0.9632 fold_3 0.9480 0.9463 0.9398 0.9463 fold_4 0.9510 0.9494 0.9433 0.9494"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-score-stats_6","title":"Fold score stats","text":"metric mean max min std accuracy 0.9534 0.9643 0.9450 0.0072 balanced_accuracy 0.9520 0.9632 0.9432 0.0074 f1 0.9462 0.9588 0.9363 0.0083 rocauc 0.9520 0.9632 0.9432 0.0074"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-parameters_6","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_perovskites","title":"<code>matbench_perovskites</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-scores_7","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0456 0.0753 0.0483 0.9441 fold_1 0.0462 0.0735 0.0497 0.9923 fold_2 0.0448 0.0690 0.0466 0.9840 fold_3 0.0454 0.0714 0.0482 0.7688 fold_4 0.0442 0.0718 0.0419 0.9384"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-score-stats_7","title":"Fold score stats","text":"metric mean max min std mae 0.0452 0.0462 0.0442 0.0007 rmse 0.0722 0.0753 0.0690 0.0021 mape* 0.0469 0.0497 0.0419 0.0027 max_error 0.9255 0.9923 0.7688 0.0812"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-parameters_7","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#matbench_phonons","title":"<code>matbench_phonons</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-scores_8","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 81.1553 231.3233 0.1330 2504.8743 fold_1 45.0945 79.3798 0.0995 835.2144 fold_2 54.2563 132.8543 0.1081 1667.5734 fold_3 56.5819 169.7248 0.1201 2378.4055 fold_4 51.7292 95.2267 0.1087 658.0856"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-score-stats_8","title":"Fold score stats","text":"metric mean max min std mae 57.7635 81.1553 45.0945 12.3109 rmse 141.7018 231.3233 79.3798 54.6618 mape* 0.1139 0.1330 0.0995 0.0116 max_error 1608.8306 2504.8743 658.0856 761.7071"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_cgcnnv2019/#fold-parameters_8","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/","title":"matbench_v0.1: coGN","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#algorithm-description","title":"Algorithm description:","text":"<p>Connectivity optimized Graph Network</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#notes","title":"Notes:","text":"<p>We found that there is a strong interdependency between crystal preprocessing for GNNs and GNN architectures. Our model 'coGN' was optimized with respect to both aspects.</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>('@misc{ruff2023connectivity, title={Connectivity Optimized Nested Graph '\n 'Networks for Crystal Structures}, author={Robin Ruff and Patrick Reiser and '\n 'Jan St\u00fchmer and Pascal Friederich}, year={2023}, eprint={2302.14102}, '\n 'archivePrefix={arXiv}, primaryClass={cs.LG}}')\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#user-metadata","title":"User metadata:","text":"<pre><code>{}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#metadata","title":"Metadata:","text":"tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['git+https://github.com/robinruff/graphlist@dcbf79e',\n            'kgcnn==3.0.0']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_dielectric","title":"<code>matbench_dielectric</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.1775 1.1939 0.0588 31.1751 fold_1 0.2663 1.2545 0.0928 19.5706 fold_2 0.4209 3.1241 0.0910 58.7728 fold_3 0.2986 2.3053 0.0561 50.6162 fold_4 0.3805 2.3953 0.1318 34.7823"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.3088 0.4209 0.1775 0.0859 rmse 2.0546 3.1241 1.1939 0.7353 mape* 0.0861 0.1318 0.0561 0.0276 max_error 38.9834 58.7728 19.5706 14.0173"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_1 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_2 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_3 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_4 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_jdft2d","title":"<code>matbench_jdft2d</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-scores_1","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 22.2500 37.9580 16.0047 159.0532 fold_1 37.2341 93.9861 0.3232 511.9405 fold_2 60.1682 173.0409 0.6480 886.4798 fold_3 24.3924 46.1018 0.2122 300.6775 fold_4 41.7814 154.7034 0.5589 1515.5614"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-score-stats_1","title":"Fold score stats","text":"metric mean max min std mae 37.1652 60.1682 22.2500 13.6825 rmse 101.1580 173.0409 37.9580 54.9748 mape* 3.5494 16.0047 0.2122 6.2296 max_error 674.7425 1515.5614 159.0532 486.6567"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-parameters_1","title":"Fold parameters","text":"fold params dict fold_0 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_1 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_2 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_3 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_4 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_log_gvrh","title":"<code>matbench_log_gvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-scores_2","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0681 0.1078 0.0538 0.9176 fold_1 0.0700 0.1145 0.0570 1.0842 fold_2 0.0685 0.1084 0.0544 0.9597 fold_3 0.0699 0.1110 0.0550 0.9638 fold_4 0.0679 0.1091 0.0530 0.7744"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-score-stats_2","title":"Fold score stats","text":"metric mean max min std mae 0.0689 0.0700 0.0679 0.0009 rmse 0.1102 0.1145 0.1078 0.0024 mape* 0.0547 0.0570 0.0530 0.0013 max_error 0.9399 1.0842 0.7744 0.0997"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-parameters_2","title":"Fold parameters","text":"fold params dict fold_0 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_1 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_2 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_3 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_4 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_log_kvrh","title":"<code>matbench_log_kvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-scores_3","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0521 0.1067 0.0346 1.6521 fold_1 0.0547 0.1140 0.0365 1.3120 fold_2 0.0495 0.0998 0.0334 1.1084 fold_3 0.0579 0.1142 0.0410 1.1212 fold_4 0.0536 0.1064 0.0359 1.4031"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-score-stats_3","title":"Fold score stats","text":"metric mean max min std mae 0.0535 0.0579 0.0495 0.0028 rmse 0.1082 0.1142 0.0998 0.0054 mape* 0.0363 0.0410 0.0334 0.0026 max_error 1.3194 1.6521 1.1084 0.2008"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-parameters_3","title":"Fold parameters","text":"fold params dict fold_0 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_1 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_2 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_3 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_4 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_mp_e_form","title":"<code>matbench_mp_e_form</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-scores_4","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0174 0.0597 0.2045 3.8249 fold_1 0.0167 0.0473 0.1188 2.5255 fold_2 0.0168 0.0433 0.1260 1.4799 fold_3 0.0173 0.0464 0.1515 1.2865 fold_4 0.0169 0.0448 0.1966 1.6626"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-score-stats_4","title":"Fold score stats","text":"metric mean max min std mae 0.0170 0.0174 0.0167 0.0003 rmse 0.0483 0.0597 0.0433 0.0059 mape* 0.1595 0.2045 0.1188 0.0353 max_error 2.1559 3.8249 1.2865 0.9358"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-parameters_4","title":"Fold parameters","text":"fold params dict fold_0 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_1 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_2 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_3 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_4 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_mp_gap","title":"<code>matbench_mp_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-scores_5","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.1532 0.3904 1.5736 7.3352 fold_1 0.1561 0.3928 1.9621 6.7683 fold_2 0.1570 0.4010 3.8426 7.3269 fold_3 0.1549 0.3909 5.5071 7.1401 fold_4 0.1583 0.4027 4.0927 6.8235"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-score-stats_5","title":"Fold score stats","text":"metric mean max min std mae 0.1559 0.1583 0.1532 0.0017 rmse 0.3956 0.4027 0.3904 0.0052 mape* 3.3956 5.5071 1.5736 1.4504 max_error 7.0788 7.3352 6.7683 0.2419"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-parameters_5","title":"Fold parameters","text":"fold params dict fold_0 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_1 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_2 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_3 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_4 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_mp_is_metal","title":"<code>matbench_mp_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-scores_6","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9184 0.9162 0.9055 0.9162 fold_1 0.9116 0.9092 0.8976 0.9092 fold_2 0.9138 0.9117 0.9003 0.9117 fold_3 0.9155 0.9135 0.9024 0.9135 fold_4 0.9137 0.9113 0.9000 0.9113"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-score-stats_6","title":"Fold score stats","text":"metric mean max min std accuracy 0.9146 0.9184 0.9116 0.0023 balanced_accuracy 0.9124 0.9162 0.9092 0.0023 f1 0.9012 0.9055 0.8976 0.0027 rocauc 0.9124 0.9162 0.9092 0.0023"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-parameters_6","title":"Fold parameters","text":"fold params dict fold_0 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_1 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_2 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_3 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_4 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_perovskites","title":"<code>matbench_perovskites</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-scores_7","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0273 0.0577 0.0272 0.8584 fold_1 0.0280 0.0616 0.0297 0.9449 fold_2 0.0256 0.0494 0.0254 0.8721 fold_3 0.0271 0.0538 0.0277 0.8234 fold_4 0.0266 0.0545 0.0240 0.8305"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-score-stats_7","title":"Fold score stats","text":"metric mean max min std mae 0.0269 0.0280 0.0256 0.0008 rmse 0.0554 0.0616 0.0494 0.0041 mape* 0.0268 0.0297 0.0240 0.0019 max_error 0.8659 0.9449 0.8234 0.0434"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-parameters_7","title":"Fold parameters","text":"fold params dict fold_0 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_1 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_2 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_3 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_4 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#matbench_phonons","title":"<code>matbench_phonons</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-scores_8","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 32.1211 62.9439 0.0581 622.4674 fold_1 29.1911 54.8274 0.0602 480.0777 fold_2 30.2587 55.7380 0.0661 497.7857 fold_3 30.7953 62.8746 0.0695 593.3290 fold_4 26.1921 52.1653 0.0547 530.2232"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-score-stats_8","title":"Fold score stats","text":"metric mean max min std mae 29.7117 32.1211 26.1921 1.9968 rmse 57.7099 62.9439 52.1653 4.4047 mape* 0.0617 0.0695 0.0547 0.0054 max_error 544.7766 622.4674 480.0777 54.7706"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coGN/#fold-parameters_8","title":"Fold parameters","text":"fold params dict fold_0 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_1 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_2 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_3 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code> fold_4 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': None, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_are...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/","title":"matbench_v0.1: coNGN","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#algorithm-description","title":"Algorithm description:","text":"<p>Connectivity optimized Nested Graph Network</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#notes","title":"Notes:","text":"<p>We found that there is a strong interdependency between crystal preprocessing for GNNs and GNN architectures. Our model 'coNGN' was optimized with respect to both aspects and further adds nested line graphs.</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>('@misc{ruff2023connectivity, title={Connectivity Optimized Nested Graph '\n 'Networks for Crystal Structures}, author={Robin Ruff and Patrick Reiser and '\n 'Jan St\u00fchmer and Pascal Friederich}, year={2023}, eprint={2302.14102}, '\n 'archivePrefix={arXiv}, primaryClass={cs.LG}}')\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#user-metadata","title":"User metadata:","text":"<pre><code>{}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#metadata","title":"Metadata:","text":"tasks recorded 9/13 complete? \u2717 composition complete? \u2717 structure complete? \u2713 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['git+https://github.com/robinruff/graphlist@dcbf79e',\n            'kgcnn==3.0.0']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#matbench_dielectric","title":"<code>matbench_dielectric</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.1989 0.9752 0.0733 15.1038 fold_1 0.2949 1.4516 0.1033 19.4905 fold_2 0.3904 2.9550 0.0841 58.8654 fold_3 0.2875 2.1322 0.0577 43.9192 fold_4 0.3992 2.6535 0.1217 46.3053"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.3142 0.3992 0.1989 0.0740 rmse 2.0335 2.9550 0.9752 0.7351 mape* 0.0880 0.1217 0.0577 0.0224 max_error 36.7368 58.8654 15.1038 16.7227"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_1 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_2 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_3 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_4 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#matbench_jdft2d","title":"<code>matbench_jdft2d</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-scores_1","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 23.7560 43.2821 21.8411 203.2730 fold_1 35.7004 79.6640 0.2947 439.8148 fold_2 53.9029 152.3112 0.5833 852.7897 fold_3 23.9486 50.7536 0.1900 307.8413 fold_4 43.5412 151.3720 0.5862 1496.9020"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-score-stats_1","title":"Fold score stats","text":"metric mean max min std mae 36.1698 53.9029 23.7560 11.5972 rmse 95.4766 152.3112 43.2821 47.6003 mape* 4.6990 21.8411 0.1900 8.5725 max_error 660.1242 1496.9020 203.2730 473.0052"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-parameters_1","title":"Fold parameters","text":"fold params dict fold_0 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_1 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_2 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_3 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_4 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#matbench_log_gvrh","title":"<code>matbench_log_gvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-scores_2","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0662 0.1052 0.0523 0.9334 fold_1 0.0678 0.1094 0.0541 1.1760 fold_2 0.0663 0.1082 0.0541 0.8977 fold_3 0.0674 0.1084 0.0525 0.9771 fold_4 0.0672 0.1075 0.0526 0.7083"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-score-stats_2","title":"Fold score stats","text":"metric mean max min std mae 0.0670 0.0678 0.0662 0.0006 rmse 0.1078 0.1094 0.1052 0.0014 mape* 0.0531 0.0541 0.0523 0.0008 max_error 0.9385 1.1760 0.7083 0.1501"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-parameters_2","title":"Fold parameters","text":"fold params dict fold_0 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_1 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_2 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_3 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_4 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#matbench_log_kvrh","title":"<code>matbench_log_kvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-scores_3","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0482 0.1016 0.0315 1.6329 fold_1 0.0494 0.1046 0.0337 1.3323 fold_2 0.0458 0.0979 0.0307 1.2123 fold_3 0.0536 0.1108 0.0380 0.9669 fold_4 0.0484 0.1037 0.0323 1.3584"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-score-stats_3","title":"Fold score stats","text":"metric mean max min std mae 0.0491 0.0536 0.0458 0.0026 rmse 0.1037 0.1108 0.0979 0.0042 mape* 0.0332 0.0380 0.0307 0.0026 max_error 1.3006 1.6329 0.9669 0.2163"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-parameters_3","title":"Fold parameters","text":"fold params dict fold_0 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_1 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_2 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_3 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_4 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#matbench_mp_e_form","title":"<code>matbench_mp_e_form</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-scores_4","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0181 0.0584 0.1996 3.2378 fold_1 0.0178 0.0474 0.1399 1.7003 fold_2 0.0172 0.0470 0.1301 2.0011 fold_3 0.0182 0.0506 0.1838 1.7068 fold_4 0.0179 0.0478 0.2313 1.5277"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-score-stats_4","title":"Fold score stats","text":"metric mean max min std mae 0.0178 0.0182 0.0172 0.0004 rmse 0.0502 0.0584 0.0470 0.0043 mape* 0.1769 0.2313 0.1301 0.0376 max_error 2.0347 3.2378 1.5277 0.6205"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-parameters_4","title":"Fold parameters","text":"fold params dict fold_0 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_1 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_2 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_3 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_4 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#matbench_mp_gap","title":"<code>matbench_mp_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-scores_5","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.1694 0.4187 1.5208 7.3460 fold_1 0.1658 0.4075 1.9359 6.3431 fold_2 0.1719 0.4374 4.4042 7.0906 fold_3 0.1663 0.4287 4.3879 7.9674 fold_4 0.1750 0.4434 4.1872 7.0762"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-score-stats_5","title":"Fold score stats","text":"metric mean max min std mae 0.1697 0.1750 0.1658 0.0035 rmse 0.4271 0.4434 0.4075 0.0129 mape* 3.2872 4.4042 1.5208 1.2818 max_error 7.1646 7.9674 6.3431 0.5226"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-parameters_5","title":"Fold parameters","text":"fold params dict fold_0 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_1 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_2 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_3 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_4 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#matbench_mp_is_metal","title":"<code>matbench_mp_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-scores_6","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9122 0.9096 0.8981 0.9096 fold_1 0.9141 0.9123 0.9009 0.9123 fold_2 0.9098 0.9072 0.8953 0.9072 fold_3 0.9104 0.9085 0.8966 0.9085 fold_4 0.9089 0.9069 0.8949 0.9069"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-score-stats_6","title":"Fold score stats","text":"metric mean max min std accuracy 0.9111 0.9141 0.9089 0.0019 balanced_accuracy 0.9089 0.9123 0.9069 0.0019 f1 0.8972 0.9009 0.8949 0.0022 rocauc 0.9089 0.9123 0.9069 0.0019"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-parameters_6","title":"Fold parameters","text":"fold params dict fold_0 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_1 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_2 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_3 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_4 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#matbench_perovskites","title":"<code>matbench_perovskites</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-scores_7","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0295 0.0612 0.0287 0.8405 fold_1 0.0309 0.0656 0.0316 0.9346 fold_2 0.0277 0.0554 0.0290 0.7072 fold_3 0.0283 0.0554 0.0285 0.8785 fold_4 0.0284 0.0573 0.0263 0.8348"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-score-stats_7","title":"Fold score stats","text":"metric mean max min std mae 0.0290 0.0309 0.0277 0.0011 rmse 0.0590 0.0656 0.0554 0.0039 mape* 0.0288 0.0316 0.0263 0.0017 max_error 0.8391 0.9346 0.7072 0.0750"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-parameters_7","title":"Fold parameters","text":"fold params dict fold_0 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_1 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_2 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_3 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_4 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#matbench_phonons","title":"<code>matbench_phonons</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-scores_8","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 33.0209 76.5063 0.0568 747.0843 fold_1 32.6300 69.5953 0.0570 617.0889 fold_2 26.0880 48.5695 0.0547 291.2322 fold_3 25.3229 43.7936 0.0615 335.4448 fold_4 27.3750 47.2225 0.0566 358.0064"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-score-stats_8","title":"Fold score stats","text":"metric mean max min std mae 28.8874 33.0209 25.3229 3.2840 rmse 57.1375 76.5063 43.7936 13.2674 mape* 0.0573 0.0615 0.0547 0.0023 max_error 469.7713 747.0843 291.2322 179.4526"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_coNGN/#fold-parameters_8","title":"Fold parameters","text":"fold params dict fold_0 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_1 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_2 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_3 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code> fold_4 <code>{'input_block_cfg': {'atomic_mass': True, 'atomic_radius': True, 'edge_embedding_args': {'bins_distance': 32, 'bins_voronoi_area': 32, 'distance_log_base': 1.0, 'max_distance': 8.0, 'max_voronoi_area'...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/","title":"matbench_v0.1: Darwin","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#algorithm-description","title":"Algorithm description:","text":"<p>Fine-tuning DARWIN Natural Science Large Language Model</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#notes","title":"Notes:","text":"<p>We provide prompts and call-and-return of our model. The code for evaluating the benchmarks is available at https://github.com/MasterAI-EAM/Darwin-SIT, our base model is available at https://aigreendynamics-my.sharepoint.com/:f:/g/personal/yuwei_greendynamics_com_au/EvZEghuFSZZCguWrCsbk2QMB_eYqv-BRMM4VLhcK8TT4Zw?e=9bnqWW. To train our model, it requires at least 4*A100(80G)</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>('@misc{xie2023large,\\n'\n ' title={Large Language Models as Master Key: Unlocking the Secrets of '\n 'Materials Science with GPT},\\n'\n ' author={Tong Xie and Yuwei Wan and Wei Huang and Yufei Zhou and Yixuan Liu '\n 'and Qingyuan Linghu and Shaozhou Wang and Chunyu Kit and Clara Grazian and '\n 'Wenjie Zhang and Bram Hoex},\\n'\n ' year={2023},\\n'\n ' eprint={2304.02213},\\n'\n ' archivePrefix={arXiv},\\n'\n ' primaryClass={cs.CL}')\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#user-metadata","title":"User metadata:","text":"<pre><code>{}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#metadata","title":"Metadata:","text":"tasks recorded 4/13 complete? \u2717 composition complete? \u2713 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['git+https://github.com/MasterAI-EAM/Darwin.git',\n            'matbench==0.1.0',\n            'numpy',\n            'rouge_score',\n            'fire',\n            'openai',\n            'transformers&gt;=4.28.1',\n            'torch',\n            'sentencepiece',\n            'tokenizers&gt;=0.13.3',\n            'wandb']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#matbench_expt_gap","title":"<code>matbench_expt_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2723 0.6679 0.3996 7.6000 fold_1 0.2873 0.6843 0.3629 6.4000 fold_2 0.2945 0.7388 0.4516 6.3900 fold_3 0.2836 0.7482 0.4408 6.8000 fold_4 0.2949 0.7535 0.4748 6.8000"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.2865 0.2949 0.2723 0.0083 rmse 0.7185 0.7535 0.6679 0.0354 mape* 0.4259 0.4748 0.3629 0.0398 max_error 6.7980 7.6000 6.3900 0.4400"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#matbench_expt_is_metal","title":"<code>matbench_expt_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#fold-scores_1","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9635 0.9634 0.9630 0.9634 fold_1 0.9634 0.9634 0.9633 0.9634 fold_2 0.9543 0.9543 0.9548 0.9543 fold_3 0.9624 0.9624 0.9626 0.9624 fold_4 0.9553 0.9553 0.9558 0.9553"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#fold-score-stats_1","title":"Fold score stats","text":"metric mean max min std accuracy 0.9598 0.9635 0.9543 0.0041 balanced_accuracy 0.9598 0.9634 0.9543 0.0041 f1 0.9599 0.9633 0.9548 0.0038 rocauc 0.9598 0.9634 0.9543 0.0041"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#fold-parameters_1","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#matbench_glass","title":"<code>matbench_glass</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#fold-scores_2","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.8160 0.7607 0.8733 0.7607 fold_1 0.8002 0.7450 0.8617 0.7450 fold_2 0.8169 0.7694 0.8725 0.7694 fold_3 0.8275 0.7840 0.8796 0.7840 fold_4 0.8195 0.7749 0.8740 0.7749"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#fold-score-stats_2","title":"Fold score stats","text":"metric mean max min std accuracy 0.8160 0.8275 0.8002 0.0089 balanced_accuracy 0.7668 0.7840 0.7450 0.0133 f1 0.8722 0.8796 0.8617 0.0058 rocauc 0.7668 0.7840 0.7450 0.0133"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#fold-parameters_2","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#matbench_steels","title":"<code>matbench_steels</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#fold-scores_3","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 129.1587 182.3484 0.0884 565.5000 fold_1 108.8460 144.9490 0.0799 399.7000 fold_2 122.0081 176.7949 0.0864 469.0000 fold_3 146.6677 200.0602 0.1076 577.3000 fold_4 109.7855 165.5786 0.0813 628.9000"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#fold-score-stats_3","title":"Fold score stats","text":"metric mean max min std mae 123.2932 146.6677 108.8460 13.9542 rmse 173.9462 200.0602 144.9490 18.2839 mape* 0.0887 0.1076 0.0799 0.0099 max_error 528.0800 628.9000 399.7000 82.4129"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_darwin/#fold-parameters_3","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/","title":"matbench_v0.1: Dummy","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#algorithm-description","title":"Algorithm description:","text":"<p>Dummy regressor, using strategy 'mean', and Dummy classifier, using strategy 'stratified'.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#notes","title":"Notes:","text":"<p>No notes.</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>('@article{Dunn2020,\\n'\n '  doi = {10.1038/s41524-020-00406-3},\\n'\n '  url = {https://doi.org/10.1038/s41524-020-00406-3},\\n'\n '  year = {2020},\\n'\n '  month = sep,\\n'\n '  publisher = {Springer Science and Business Media {LLC}},\\n'\n '  volume = {6},\\n'\n '  number = {1},\\n'\n '  author = {Alexander Dunn and Qi Wang and Alex Ganose and Daniel Dopp and '\n 'Anubhav Jain},\\n'\n '  title = {Benchmarking materials property prediction methods: the Matbench '\n 'test set and Automatminer reference algorithm},\\n'\n '  journal = {npj Computational Materials}\\n'\n '}')\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#user-metadata","title":"User metadata:","text":"<pre><code>{'algorithm': 'dummy',\n 'classification_strategy': 'stratified',\n 'regression_strategy': 'mean'}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#metadata","title":"Metadata:","text":"tasks recorded 13/13 complete? \u2713 composition complete? \u2713 structure complete? \u2713 regression complete? \u2713 classification complete? \u2713"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['scikit-learn==0.24.1', 'numpy==1.20.1', 'matbench==0.1.0']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_dielectric","title":"<code>matbench_dielectric</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.7026 1.0677 0.3201 14.9501 fold_1 0.7811 1.4374 0.3142 20.3552 fold_2 0.9218 3.1055 0.3155 59.6653 fold_3 0.8382 2.4438 0.3266 53.4563 fold_4 0.8004 1.8094 0.3222 28.5706"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.8088 0.9218 0.7026 0.0718 rmse 1.9728 3.1055 1.0677 0.7263 mape* 0.3197 0.3266 0.3142 0.0045 max_error 35.3995 59.6653 14.9501 17.9221"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{'constant_': [[2.4569770107667264]]}</code> fold_1 <code>{'constant_': [[2.4254682439737882]]}</code> fold_2 <code>{'constant_': [[2.397736448888908]]}</code> fold_3 <code>{'constant_': [[2.429725254851624]]}</code> fold_4 <code>{'constant_': [[2.4316628587393003]]}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_expt_gap","title":"<code>matbench_expt_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_1","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 1.0965 1.3397 0.8589 7.0119 fold_1 1.1922 1.5156 0.7802 8.3754 fold_2 1.1527 1.5268 1.0398 10.7354 fold_3 1.1445 1.4389 0.8373 9.5190 fold_4 1.1317 1.3979 1.2418 9.0085"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_1","title":"Fold score stats","text":"metric mean max min std mae 1.1435 1.1922 1.0965 0.0310 rmse 1.4438 1.5268 1.3397 0.0707 mape* 0.9516 1.2418 0.7802 0.1692 max_error 8.9300 10.7354 7.0119 1.2328"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_1","title":"Fold parameters","text":"fold params dict fold_0 <code>{'constant_': [[0.9881156665761609]]}</code> fold_1 <code>{'constant_': [[0.9545533532446375]]}</code> fold_2 <code>{'constant_': [[0.9645506380667934]]}</code> fold_3 <code>{'constant_': [[0.9810371979364648]]}</code> fold_4 <code>{'constant_': [[0.9914956568946797]]}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_expt_is_metal","title":"<code>matbench_expt_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_2","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.4701 0.4700 0.4540 0.4700 fold_1 0.5000 0.5001 0.5080 0.5001 fold_2 0.4878 0.4878 0.4878 0.4878 fold_3 0.5071 0.5072 0.5126 0.5072 fold_4 0.4970 0.4969 0.4944 0.4969"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_2","title":"Fold score stats","text":"metric mean max min std accuracy 0.4924 0.5071 0.4701 0.0128 balanced_accuracy 0.4924 0.5072 0.4700 0.0128 f1 0.4913 0.5126 0.4540 0.0207 rocauc 0.4924 0.5072 0.4700 0.0128"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_2","title":"Fold parameters","text":"fold params dict fold_0 <code>{'class_prior_': [0.5020325203252033, 0.49796747967479676]}</code> fold_1 <code>{'class_prior_': [0.5019050038100076, 0.49809499618999237]}</code> fold_2 <code>{'class_prior_': [0.5019050038100076, 0.49809499618999237]}</code> fold_3 <code>{'class_prior_': [0.5019050038100076, 0.49809499618999237]}</code> fold_4 <code>{'class_prior_': [0.5019050038100076, 0.49809499618999237]}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_glass","title":"<code>matbench_glass</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_3","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.6127 0.5212 0.7304 0.5212 fold_1 0.6083 0.5217 0.7251 0.5217 fold_2 0.5775 0.4848 0.7033 0.4848 fold_3 0.5731 0.4799 0.7001 0.4799 fold_4 0.5819 0.4951 0.7044 0.4951"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_3","title":"Fold score stats","text":"metric mean max min std accuracy 0.5907 0.6127 0.5731 0.0165 balanced_accuracy 0.5005 0.5217 0.4799 0.0178 f1 0.7127 0.7304 0.7001 0.0125 rocauc 0.5005 0.5217 0.4799 0.0178"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_3","title":"Fold parameters","text":"fold params dict fold_0 <code>{'class_prior_': [0.289612676056338, 0.710387323943662]}</code> fold_1 <code>{'class_prior_': [0.289612676056338, 0.710387323943662]}</code> fold_2 <code>{'class_prior_': [0.289612676056338, 0.710387323943662]}</code> fold_3 <code>{'class_prior_': [0.289612676056338, 0.710387323943662]}</code> fold_4 <code>{'class_prior_': [0.289612676056338, 0.710387323943662]}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_jdft2d","title":"<code>matbench_jdft2d</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_4","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 53.1447 74.1060 35.3098 509.7791 fold_1 72.8118 118.0523 0.8129 642.7424 fold_2 83.1220 192.2365 0.9798 1025.0199 fold_3 61.3174 85.6603 0.7921 468.0412 fold_4 66.0295 164.1680 1.1452 1491.7993"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_4","title":"Fold score stats","text":"metric mean max min std mae 67.2851 83.1220 53.1447 10.1832 rmse 126.8446 192.2365 74.1060 45.2193 mape* 7.8079 35.3098 0.7921 13.7515 max_error 827.4764 1491.7993 468.0412 385.9016"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_4","title":"Fold parameters","text":"fold params dict fold_0 <code>{'constant_': [[117.03965287603667]]}</code> fold_1 <code>{'constant_': [[112.91320041366653]]}</code> fold_2 <code>{'constant_': [[106.46511492350562]]}</code> fold_3 <code>{'constant_': [[114.84311227394852]]}</code> fold_4 <code>{'constant_': [[112.23899155170879]]}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_log_gvrh","title":"<code>matbench_log_gvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_5","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2943 0.3749 0.2368 1.5529 fold_1 0.2933 0.3743 0.2359 1.5544 fold_2 0.2969 0.3736 0.2353 1.5533 fold_3 0.2875 0.3646 0.2251 1.5524 fold_4 0.2937 0.3706 0.2334 1.5552"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_5","title":"Fold score stats","text":"metric mean max min std mae 0.2931 0.2969 0.2875 0.0031 rmse 0.3716 0.3749 0.3646 0.0038 mape* 0.2333 0.2368 0.2251 0.0042 max_error 1.5536 1.5552 1.5524 0.0010"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_5","title":"Fold parameters","text":"fold params dict fold_0 <code>{'constant_': [[1.5529289714161707]]}</code> fold_1 <code>{'constant_': [[1.554355173237515]]}</code> fold_2 <code>{'constant_': [[1.5532719705303168]]}</code> fold_3 <code>{'constant_': [[1.5523993668681186]]}</code> fold_4 <code>{'constant_': [[1.5552370733167413]]}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_log_kvrh","title":"<code>matbench_log_kvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_6","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2935 0.3774 0.1877 1.8800 fold_1 0.2875 0.3669 0.1858 1.8809 fold_2 0.2889 0.3634 0.1825 1.8801 fold_3 0.2833 0.3635 0.1926 1.8790 fold_4 0.2953 0.3752 0.1900 1.8822"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_6","title":"Fold score stats","text":"metric mean max min std mae 0.2897 0.2953 0.2833 0.0043 rmse 0.3693 0.3774 0.3634 0.0059 mape* 0.1877 0.1926 0.1825 0.0035 max_error 1.8804 1.8822 1.8790 0.0011"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_6","title":"Fold parameters","text":"fold params dict fold_0 <code>{'constant_': [[1.8800295900875317]]}</code> fold_1 <code>{'constant_': [[1.880914404358644]]}</code> fold_2 <code>{'constant_': [[1.8800659898099186]]}</code> fold_3 <code>{'constant_': [[1.8789962707394416]]}</code> fold_4 <code>{'constant_': [[1.8822230471663404]]}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_mp_e_form","title":"<code>matbench_mp_e_form</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_7","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 1.0063 1.1626 11.6409 3.8987 fold_1 1.0036 1.1597 7.2868 3.8782 fold_2 1.0062 1.1662 8.5651 3.9096 fold_3 1.0024 1.1597 10.9729 3.8934 fold_4 1.0111 1.1675 11.2779 3.9051"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_7","title":"Fold score stats","text":"metric mean max min std mae 1.0059 1.0111 1.0024 0.0030 rmse 1.1631 1.1675 1.1597 0.0032 mape* 9.9487 11.6409 7.2868 1.7134 max_error 3.8970 3.9096 3.8782 0.0109"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_7","title":"Fold parameters","text":"fold params dict fold_0 <code>{'constant_': [[-1.4071424641223964]]}</code> fold_1 <code>{'constant_': [[-1.4079146341783042]]}</code> fold_2 <code>{'constant_': [[-1.4100821676758766]]}</code> fold_3 <code>{'constant_': [[-1.406498235557698]]}</code> fold_4 <code>{'constant_': [[-1.4079540738106724]]}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_mp_gap","title":"<code>matbench_mp_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_8","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 1.3199 1.5863 13.8283 7.1079 fold_1 1.3224 1.5888 12.1282 8.1096 fold_2 1.3252 1.5964 14.5509 7.6322 fold_3 1.3335 1.6113 19.3774 7.4334 fold_4 1.3348 1.6118 18.0392 8.5092"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_8","title":"Fold score stats","text":"metric mean max min std mae 1.3272 1.3348 1.3199 0.0060 rmse 1.5989 1.6118 1.5863 0.0108 mape* 15.5848 19.3774 12.1282 2.7022 max_error 7.7585 8.5092 7.1079 0.4963"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_8","title":"Fold parameters","text":"fold params dict fold_0 <code>{'constant_': [[1.216204829779715]]}</code> fold_1 <code>{'constant_': [[1.2168485710920014]]}</code> fold_2 <code>{'constant_': [[1.2161007256449523]]}</code> fold_3 <code>{'constant_': [[1.2119634071927532]]}</code> fold_4 <code>{'constant_': [[1.2120157684560202]]}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_mp_is_metal","title":"<code>matbench_mp_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_9","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.5158 0.5069 0.4405 0.5069 fold_1 0.5032 0.4944 0.4277 0.4944 fold_2 0.5069 0.4986 0.4342 0.4986 fold_3 0.5119 0.5032 0.4376 0.5032 fold_4 0.5118 0.5030 0.4367 0.5030"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_9","title":"Fold score stats","text":"metric mean max min std accuracy 0.5099 0.5158 0.5032 0.0044 balanced_accuracy 0.5012 0.5069 0.4944 0.0043 f1 0.4353 0.4405 0.4277 0.0043 rocauc 0.5012 0.5069 0.4944 0.0043"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_9","title":"Fold parameters","text":"fold params dict fold_0 <code>{'class_prior_': [0.5650724466957239, 0.4349275533042761]}</code> fold_1 <code>{'class_prior_': [0.5650724466957239, 0.4349275533042761]}</code> fold_2 <code>{'class_prior_': [0.5650842266462481, 0.4349157733537519]}</code> fold_3 <code>{'class_prior_': [0.5650775700604305, 0.4349224299395696]}</code> fold_4 <code>{'class_prior_': [0.5650775700604305, 0.4349224299395696]}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_perovskites","title":"<code>matbench_perovskites</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_10","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.5672 0.7361 0.7398 3.4868 fold_1 0.5742 0.7618 0.8046 3.3123 fold_2 0.5660 0.7438 0.7674 3.6873 fold_3 0.5614 0.7342 0.7738 3.3906 fold_4 0.5612 0.7362 0.7058 3.5084"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_10","title":"Fold score stats","text":"metric mean max min std mae 0.5660 0.5742 0.5612 0.0048 rmse 0.7424 0.7618 0.7342 0.0102 mape* 0.7583 0.8046 0.7058 0.0334 max_error 3.4771 3.6873 3.3123 0.1264"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_10","title":"Fold parameters","text":"fold params dict fold_0 <code>{'constant_': [[1.4731871615374454]]}</code> fold_1 <code>{'constant_': [[1.4677308149517898]]}</code> fold_2 <code>{'constant_': [[1.4726720380398888]]}</code> fold_3 <code>{'constant_': [[1.4694433071386122]]}</code> fold_4 <code>{'constant_': [[1.4716264940896784]]}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_phonons","title":"<code>matbench_phonons</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_11","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 337.1003 542.7449 0.8225 3020.7169 fold_1 299.1209 452.2982 0.7977 2702.0312 fold_2 348.2576 545.4772 0.9223 3062.3450 fold_3 325.2402 480.9296 1.0268 3048.7920 fold_4 310.1921 439.3166 0.8936 1970.0884"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_11","title":"Fold score stats","text":"metric mean max min std mae 323.9822 348.2576 299.1209 17.7269 rmse 492.1533 545.4772 439.3166 44.5176 mape* 0.8926 1.0268 0.7977 0.0810 max_error 2760.7947 3062.3450 1970.0884 417.1581"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_11","title":"Fold parameters","text":"fold params dict fold_0 <code>{'constant_': [[571.8686083004105]]}</code> fold_1 <code>{'constant_': [[583.1997247898747]]}</code> fold_2 <code>{'constant_': [[581.3984519265839]]}</code> fold_3 <code>{'constant_': [[588.7935123141577]]}</code> fold_4 <code>{'constant_': [[581.4972239423439]]}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#matbench_steels","title":"<code>matbench_steels</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-scores_12","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 241.4591 293.7245 0.1647 941.0643 fold_1 219.3770 289.2253 0.1550 1064.2831 fold_2 225.7932 291.5410 0.1600 1084.8760 fold_3 241.2035 343.9346 0.1567 1088.0568 fold_4 220.8898 287.6803 0.1576 983.3424"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-score-stats_12","title":"Fold score stats","text":"metric mean max min std mae 229.7445 241.4591 219.3770 9.6958 rmse 301.2211 343.9346 287.6803 21.4551 mape* 0.1588 0.1647 0.1550 0.0034 max_error 1032.3245 1088.0568 941.0643 59.3579"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_dummy/#fold-parameters_12","title":"Fold parameters","text":"fold params dict fold_0 <code>{'constant_': [[1415.3357429718874]]}</code> fold_1 <code>{'constant_': [[1423.0168674698796]]}</code> fold_2 <code>{'constant_': [[1425.424]]}</code> fold_3 <code>{'constant_': [[1413.0431999999998]]}</code> fold_4 <code>{'constant_': [[1428.1575999999998]]}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/","title":"matbench_v0.1: gptchem","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#algorithm-description","title":"Algorithm description:","text":"<p>Language-interface (LIFT) fine-tuned ada GPT-3 model (without optimization of finetuning parameters or prompt)</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#notes","title":"Notes:","text":"<p>We use the high-level GPTRegressor and GPTClassifier APIs provided via our gptchem package. The code for running the benchmarks is available at https://github.com/kjappelbaum/gptchem-matbench.</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>('@article{Jablonka_2023,\\n'\n ' doi = {10.26434/chemrxiv-2023-fw8n4},\\n'\n ' url = {https:doi.org/10.26434%2Fchemrxiv-2023-fw8n4},\\n'\n ' year = 2023,\\n'\n ' month = {feb},\\n'\n '  publisher = {American Chemical Society ({ACS})},\\n'\n ' author = {Kevin Maik Jablonka and Philippe Schwaller and Andres '\n 'Ortega-Guerrero and Berend Smit},\\n'\n ' title = {Is {GPT}-3 all you need for low-data discovery in chemistry\\n'\n '}')\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#user-metadata","title":"User metadata:","text":"<pre><code>{}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#metadata","title":"Metadata:","text":"tasks recorded 4/13 complete? \u2717 composition complete? \u2713 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['git+https://github.com/kjappelbaum/gptchem.git',\n            'matbench==0.1.0']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#matbench_expt_gap","title":"<code>matbench_expt_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.4734 1.0919 0.4774 7.8000 fold_1 0.4451 1.0520 0.4390 9.3300 fold_2 0.4572 1.1435 0.4767 11.7000 fold_3 0.4585 1.0736 0.5515 10.4000 fold_4 0.4376 1.0074 0.6414 7.6000"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.4544 0.4734 0.4376 0.0123 rmse 1.0737 1.1435 1.0074 0.0449 mape* 0.5172 0.6414 0.4390 0.0720 max_error 9.3660 11.7000 7.6000 1.5549"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#matbench_expt_is_metal","title":"<code>matbench_expt_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-scores_1","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9025 0.9025 0.9012 0.9025 fold_1 0.8852 0.8851 0.8824 0.8851 fold_2 0.8994 0.8993 0.8961 0.8993 fold_3 0.8974 0.8974 0.8983 0.8974 fold_4 0.8984 0.8984 0.8984 0.8984"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-score-stats_1","title":"Fold score stats","text":"metric mean max min std accuracy 0.8966 0.9025 0.8852 0.0060 balanced_accuracy 0.8965 0.9025 0.8851 0.0060 f1 0.8953 0.9012 0.8824 0.0066 rocauc 0.8965 0.9025 0.8851 0.0060"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-parameters_1","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#matbench_glass","title":"<code>matbench_glass</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-scores_2","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.8363 0.7839 0.8874 0.7839 fold_1 0.8143 0.7684 0.8703 0.7684 fold_2 0.8204 0.7674 0.8761 0.7674 fold_3 0.8363 0.7965 0.8855 0.7965 fold_4 0.8151 0.7646 0.8718 0.7646"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-score-stats_2","title":"Fold score stats","text":"metric mean max min std accuracy 0.8245 0.8363 0.8143 0.0099 balanced_accuracy 0.7762 0.7965 0.7646 0.0122 f1 0.8782 0.8874 0.8703 0.0070 rocauc 0.7762 0.7965 0.7646 0.0122"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-parameters_2","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#matbench_steels","title":"<code>matbench_steels</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-scores_3","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 162.9667 227.5822 0.1112 650.8000 fold_1 161.0762 270.1202 0.1211 1368.2000 fold_2 137.0645 198.1973 0.0947 651.6000 fold_3 135.9887 195.8941 0.0973 720.9000 fold_4 117.9177 198.3470 0.0880 1139.3000"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-score-stats_3","title":"Fold score stats","text":"metric mean max min std mae 143.0028 162.9667 117.9177 16.9642 rmse 218.0282 270.1202 195.8941 28.5495 mape* 0.1025 0.1211 0.0880 0.0120 max_error 906.1600 1368.2000 650.8000 293.9952"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_gptchem/#fold-parameters_3","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/","title":"matbench_v0.1: Lattice-XGBoost","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#algorithm-description","title":"Algorithm description:","text":"<p>eXtreme Gradient Boosting trees (XGBoost) is applied on basic tabular data that describes the crystal lattice of each compound: lattice parameter lengths and angles, space group number, and unit cell volume. Fixed XGBoost hyperparameters were used. This serves as part of a baseline to answer the question: how much predictive performance is present in the basic details of a crystal lattice (i.e. no composition, no site information)?</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#notes","title":"Notes:","text":"<p>Designed for use on the <code>matbench_mp_e_form</code> task as an alternative perspective in a more established domain (i.e. model accuracy) to that of generative model benchmarking. This is specifically part of a series of baselines and tests related to the xtal2png (https://xtal2png.readthedocs.io/en/latest/) representation.</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>('@inproceedings{Chen:2016:XST:2939672.2939785,\\n'\n ' author = {Chen, Tianqi and Guestrin, Carlos},\\n'\n ' title = {{XGBoost}: A Scalable Tree Boosting System},\\n'\n ' booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on '\n 'Knowledge Discovery and Data Mining},\\n'\n \" series = {KDD '16},\\n\"\n ' year = {2016},\\n'\n ' isbn = {978-1-4503-4232-2},\\n'\n ' location = {San Francisco, California, USA},\\n'\n ' pages = {785--794},\\n'\n ' numpages = {10},\\n'\n ' url = {http://doi.acm.org/10.1145/2939672.2939785},\\n'\n ' doi = {10.1145/2939672.2939785},\\n'\n ' acmid = {2939785},\\n'\n ' publisher = {ACM},\\n'\n ' address = {New York, NY, USA},\\n'\n ' keywords = {large-scale machine learning}\\n'\n '}, @article{article,\\n'\n ' author = {Ong, Shyue and Richards, William and Jain, Anubhav and Hautier, '\n 'Geoffroy and Kocher, Michael and Cholia, Shreyas and Gunter, Dan and '\n 'Chevrier, Vincent and Persson, Kristin and Ceder, Gerbrand},\\n'\n ' year = {2013},\\n'\n ' month = {02},\\n'\n ' pages = {314-319},\\n'\n ' title = {Python Materials Genomics (pymatgen): A robust, open-source python '\n 'library for materials analysis},\\n'\n ' volume = {68},\\n'\n ' journal = {Computational Materials Science},\\n'\n ' doi = {10.1016/j.commatsci.2012.10.028}}')\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#user-metadata","title":"User metadata:","text":"<pre><code>{}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#metadata","title":"Metadata:","text":"tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['matbench==0.5.0',\n            'scikit-learn==1.1.1',\n            'xgboost==1.6.1',\n            'pandas==1.4.2',\n            'numpy==1.22.1 ',\n            'typing==3.10.5']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#matbench_mp_e_form","title":"<code>matbench_mp_e_form</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.7549 0.9441 8.1981 4.0717 fold_1 0.7464 0.9374 4.8884 4.2425 fold_2 0.7560 0.9454 5.8547 3.9905 fold_3 0.7465 0.9363 7.3725 4.0495 fold_4 0.7536 0.9441 8.2081 3.9335"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.7515 0.7560 0.7464 0.0042 rmse 0.9415 0.9454 0.9363 0.0038 mape* 6.9044 8.2081 4.8884 1.3235 max_error 4.0575 4.2425 3.9335 0.1043"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_lattice_xgboost/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_matformer/","title":"matbench_v0.1: Matformer","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_matformer/#algorithm-description","title":"Algorithm description:","text":"<p>Periodic Graph Transformers for Crystal Material Property Prediction. In this work, we propose a transformer architecture, known as Matformer, for periodic graph representation learning. Our Matformer is designed to be invariant to periodicity and can capture repeating patterns explicitly. In particular, Matformer encodes periodic patterns by efficient use of geometric distances between the same atoms in neighboring cells.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_matformer/#notes","title":"Notes:","text":"<p>This version has not been submitted by the original authors and has a modified training script, since the original version is not capable to train on the official matbench. All adjusted files are attached. The model and the parameters are from the original github repository (https://github.com/YKQ98/Matformer), which itself builds on the code basis of ALIGNN.</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_matformer/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>['@inproceedings{yan2022periodic,\\n'\n '  title={Periodic Graph Transformers for Crystal Material Property '\n 'Prediction},\\n'\n '  author={Keqiang Yan and Yi Liu and Yuchao Lin and Shuiwang Ji},\\n'\n '  booktitle={The 36th Annual Conference on Neural Information Processing '\n 'Systems},\\n'\n '  year={2022}\\n'\n '}',\n '@misc{yan2022periodicArXiv,\\n'\n '      title={Periodic Graph Transformers for Crystal Material Property '\n 'Prediction}, \\n'\n '      author={Keqiang Yan and Yi Liu and Yuchao Lin and Shuiwang Ji},\\n'\n '      year={2022},\\n'\n '      eprint={2209.11807},\\n'\n '      archivePrefix={arXiv},\\n'\n '      primaryClass={cs.LG}\\n'\n '}']\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_matformer/#user-metadata","title":"User metadata:","text":"<pre><code>{'algorithm': 'Matformer'}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_matformer/#metadata","title":"Metadata:","text":"tasks recorded 1/13 complete? \u2717 composition complete? \u2717 structure complete? \u2717 regression complete? \u2717 classification complete? \u2717"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_matformer/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['torch',\n            'torchvision',\n            'torchaudio',\n            'torch_geometric',\n            'git+https://github.com/YKQ98/Matformer']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_matformer/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_matformer/#matbench_mp_is_metal","title":"<code>matbench_mp_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_matformer/#fold-scores","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.8670 0.8503 0.8252 0.8503 fold_1 0.8584 0.8403 0.8116 0.8403 fold_2 0.8710 0.8553 0.8321 0.8553 fold_3 0.7829 0.7518 0.6728 0.7518 fold_4 0.7908 0.7609 0.6883 0.7609"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_matformer/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std accuracy 0.8340 0.8710 0.7829 0.0388 balanced_accuracy 0.8117 0.8553 0.7518 0.0455 f1 0.7660 0.8321 0.6728 0.0702 rocauc 0.8117 0.8553 0.7518 0.0455"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_matformer/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{'atom_features': 'cgcnn', 'batch_size': 64, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': None, 'distributed': False, 'epochs': 500, 'filename': 'sample', 'id_tag': ...</code> fold_1 <code>{'atom_features': 'cgcnn', 'batch_size': 64, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': None, 'distributed': False, 'epochs': 500, 'filename': 'sample', 'id_tag': ...</code> fold_2 <code>{'atom_features': 'cgcnn', 'batch_size': 64, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': None, 'distributed': False, 'epochs': 500, 'filename': 'sample', 'id_tag': ...</code> fold_3 <code>{'atom_features': 'cgcnn', 'batch_size': 64, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': None, 'distributed': False, 'epochs': 500, 'filename': 'sample', 'id_tag': ...</code> fold_4 <code>{'atom_features': 'cgcnn', 'batch_size': 64, 'classification_threshold': None, 'criterion': 'mse', 'cutoff': 8.0, 'dataset': None, 'distributed': False, 'epochs': 500, 'filename': 'sample', 'id_tag': ...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/","title":"matbench_v0.1: MODNet (v0.1.10)","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#algorithm-description","title":"Algorithm description:","text":"<p>MODNet, the Materials Optimal Descriptor Network (v0.1.10). A feed-forward neural network, using all compatible matminer features and a relevance-redundancy based feature selection algorithm. Hyperparameter optimisation is performed with a nested grid search for the 9 smaller tasks, and with a genetic algorithm for the 4 larger tasks (<code>matbench_perovskites</code>, <code>matbench_mp_gap</code>, <code>matbench_mp_is_metal</code>, <code>matbench_mp_eform</code>. Benchmark results were loaded from https://github.com/ml-evs/modnet-matbench/releases/tag/v0.3.0, archived at 10.5281/zenodo.5562338.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#notes","title":"Notes:","text":"<p>None</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>('@article{De_Breuck_2021, doi = {10.1088/1361-648x/ac1280}, url = '\n '{https://doi.org/10.1088/1361-648x/ac1280}, year = 2021, month = {jul}, '\n 'publisher = {{IOP} Publishing}, volume = {33}, number = {40}, pages = '\n '{404002}, author = {Pierre-Paul De Breuck and Matthew L Evans and Gian-Marco '\n 'Rignanese}, title = {Robust model benchmarking and bias-imbalance in '\n 'data-driven materials science: a case study on {MODNet}}, journal = {Journal '\n 'of Physics: Condensed Matter}, abstract = {As the number of novel '\n 'data-driven approaches to material science continues to grow, it is crucial '\n 'to perform consistent quality, reliability and applicability assessments of '\n 'model performance. In this paper, we benchmark the Materials Optimal '\n 'Descriptor Network (MODNet) method and architecture against the recently '\n 'released MatBench v0.1, a curated test suite of materials datasets. MODNet '\n 'is shown to outperform current leaders on 6 of the 13 tasks, while closely '\n 'matching the current leaders on a further 2 tasks; MODNet performs '\n 'particularly well when the number of samples is below 10\\xa0000. Attention '\n 'is paid to two topics of concern when benchmarking models. First, we '\n 'encourage the reporting of a more diverse set of metrics as it leads to a '\n 'more comprehensive and holistic comparison of model performance. Second, an '\n 'equally important task is the uncertainty assessment of a model towards a '\n 'target domain. Significant variations in validation errors can be observed, '\n 'depending on the imbalance and bias in the training set (i.e., similarity '\n 'between training and application space). By using an ensemble MODNet model, '\n 'confidence intervals can be built and the uncertainty on individual '\n 'predictions can be quantified. Imbalance and bias issues are often '\n 'overlooked, and yet are important for successful real-world applications of '\n 'machine learning in materials science and condensed matter.}}, '\n '@article{DeBreuck2021, doi = {10.1038/s41524-021-00552-2}, url = '\n '{https://doi.org/10.1038/s41524-021-00552-2}, year = {2021}, month = jun, '\n 'publisher = {Springer Science and Business Media {LLC}}, volume = {7}, '\n 'number = {1}, author = {Pierre-Paul De Breuck and Geoffroy Hautier and '\n 'Gian-Marco Rignanese}, title = {Materials property prediction for limited '\n 'datasets enabled by feature selection and joint learning with {MODNet}}, '\n 'journal = {npj Computational Materials}}')\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#user-metadata","title":"User metadata:","text":"<pre><code>{}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#metadata","title":"Metadata:","text":"tasks recorded 13/13 complete? \u2713 composition complete? \u2713 structure complete? \u2713 regression complete? \u2713 classification complete? \u2713"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['modnet==0.1.10', 'matbench==0.2.0']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_dielectric","title":"<code>matbench_dielectric</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.1939 0.7043 0.0657 13.9549 fold_1 0.2669 1.0559 0.0897 19.4132 fold_2 0.4138 2.9360 0.0873 58.9519 fold_3 0.2880 2.2447 0.0593 52.4648 fold_4 0.3223 1.6518 0.1040 28.0662"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.2970 0.4138 0.1939 0.0720 rmse 1.7185 2.9360 0.7043 0.8039 mape* 0.0812 0.1040 0.0593 0.0164 max_error 34.5702 58.9519 13.9549 17.9539"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{'std': [[0.06733036786317825], [0.0744570940732956], [0.4551847279071808], [0.6979547739028931], [0.05083160847425461], [0.09550821781158447], [0.19389964640140533], [0.45796462893486023], [0.0457437...</code> fold_1 <code>{'std': [[0.072625070810318], [0.20568081736564636], [0.06122368574142456], [0.1985706239938736], [0.13508345186710358], [0.5729472637176514], [0.18508531153202057], [0.36901697516441345], [0.15902499...</code> fold_2 <code>{'std': [[0.07455231994390488], [0.40818431973457336], [0.17178542912006378], [0.1756463497877121], [0.05205323547124863], [0.18280482292175293], [0.029979035258293152], [0.13881000876426697], [0.1849...</code> fold_3 <code>{'std': [[0.07038000971078873], [0.052069056779146194], [0.11985469609498978], [0.2917916774749756], [0.07153098285198212], [0.16248461604118347], [0.03178466856479645], [0.06994788348674774], [0.0775...</code> fold_4 <code>{'std': [[0.062172286212444305], [0.1020524799823761], [0.046170447021722794], [0.2582769989967346], [0.5205304622650146], [0.09285475313663483], [0.04396134242415428], [0.1190856322646141], [0.159720...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_expt_gap","title":"<code>matbench_expt_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_1","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.3272 0.7062 0.3510 6.3096 fold_1 0.3594 0.7340 0.3187 6.3544 fold_2 0.3845 0.8563 0.3841 9.8567 fold_3 0.3259 0.6888 0.3231 5.1081 fold_4 0.3382 0.7334 0.4075 6.5141"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_1","title":"Fold score stats","text":"metric mean max min std mae 0.3470 0.3845 0.3259 0.0222 rmse 0.7437 0.8563 0.6888 0.0588 mape* 0.3569 0.4075 0.3187 0.0345 max_error 6.8286 9.8567 5.1081 1.5952"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_1","title":"Fold parameters","text":"fold params dict fold_0 <code>{'std': [[0.3934377431869507], [0.6812934875488281], [0.46057939529418945], [0.21048687398433685], [0.39122024178504944], [2.184469699859619], [1.0323148965835571], [1.1202787160873413], [0.8973723649...</code> fold_1 <code>{'std': [[0.42153677344322205], [0.10141757875680923], [0.2717689573764801], [0.0055972738191485405], [0.12942852079868317], [0.19773989915847778], [0.1537284404039383], [0.152150496840477], [0.127241...</code> fold_2 <code>{'std': [[0.5310537219047546], [0.09472547471523285], [0.6016039848327637], [0.7606176137924194], [0.2108703851699829], [0.3892253637313843], [0.8048807382583618], [0.058867525309324265], [0.236589178...</code> fold_3 <code>{'std': [[0.4957612454891205], [0.24328213930130005], [1.1489912271499634], [0.4026401937007904], [0.38004472851753235], [0.235760897397995], [0.2802310287952423], [0.23525512218475342], [0.9116547703...</code> fold_4 <code>{'std': [[0.17024394869804382], [1.0889294147491455], [0.0037015366833657026], [0.45974406599998474], [0.7000935673713684], [1.2791191339492798], [1.037060260772705], [1.1216192245483398], [1.26752507...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_expt_is_metal","title":"<code>matbench_expt_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_2","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9269 0.9269 0.9255 0.9269 fold_1 0.9136 0.9136 0.9121 0.9136 fold_2 0.9177 0.9177 0.9173 0.9177 fold_3 0.9177 0.9177 0.9169 0.9177 fold_4 0.9045 0.9045 0.9049 0.9045"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_2","title":"Fold score stats","text":"metric mean max min std accuracy 0.9161 0.9269 0.9045 0.0073 balanced_accuracy 0.9161 0.9269 0.9045 0.0072 f1 0.9153 0.9255 0.9049 0.0068 rocauc 0.9161 0.9269 0.9045 0.0072"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_2","title":"Fold parameters","text":"fold params dict fold_0 <code>{'std': [[0.17845642566680908, 0.1784563958644867], [0.38880154490470886, 0.38880154490470886], [0.11527526378631592, 0.11527524888515472], [0.29507318139076233, 0.29507318139076233], [0.4294841885566...</code> fold_1 <code>{'std': [[0.250985711812973, 0.250985711812973], [0.15300564467906952, 0.15300562977790833], [0.11072004586458206, 0.11072004586458206], [0.07669822871685028, 0.07669822126626968], [0.1074658855795860...</code> fold_2 <code>{'std': [[0.16936197876930237, 0.16936197876930237], [0.28381362557411194, 0.2838136553764343], [0.3199393153190613, 0.3199393153190613], [0.14618311822414398, 0.1461830586194992], [0.1249608173966407...</code> fold_3 <code>{'std': [[0.13702887296676636, 0.13702887296676636], [0.1351342797279358, 0.1351342648267746], [0.40080583095550537, 0.40080583095550537], [0.1579451709985733, 0.1579451709985733], [0.1655253022909164...</code> fold_4 <code>{'std': [[0.28618890047073364, 0.28618890047073364], [0.27044594287872314, 0.27044594287872314], [0.29565274715423584, 0.29565274715423584], [0.29736053943634033, 0.29736053943634033], [0.237021714448...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_glass","title":"<code>matbench_glass</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_3","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.8759 0.8262 0.9153 0.8262 fold_1 0.8539 0.7783 0.9030 0.7783 fold_2 0.8565 0.8063 0.9016 0.8063 fold_3 0.8856 0.8402 0.9217 0.8402 fold_4 0.8662 0.8023 0.9102 0.8023"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_3","title":"Fold score stats","text":"metric mean max min std accuracy 0.8676 0.8856 0.8539 0.0119 balanced_accuracy 0.8107 0.8402 0.7783 0.0212 f1 0.9104 0.9217 0.9016 0.0075 rocauc 0.8107 0.8402 0.7783 0.0212"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_3","title":"Fold parameters","text":"fold params dict fold_0 <code>{'std': [[0.1912706196308136, 0.1912706196308136], [0.3220626413822174, 0.3220626413822174], [0.38618433475494385, 0.38618433475494385], [0.3689897954463959, 0.36898982524871826], [0.296833336353302, ...</code> fold_1 <code>{'std': [[0.3554098606109619, 0.3554098606109619], [0.19303181767463684, 0.19303181767463684], [0.2967971861362457, 0.2967972159385681], [0.3302050232887268, 0.3302050232887268], [0.2770985960960388, ...</code> fold_2 <code>{'std': [[0.3961077332496643, 0.39610767364501953], [0.19110238552093506, 0.19110238552093506], [0.22688446938991547, 0.22688449919223785], [0.34065985679626465, 0.3406599164009094], [0.25127366185188...</code> fold_3 <code>{'std': [[0.18866945803165436, 0.18866944313049316], [0.17435620725154877, 0.17435620725154877], [0.18012933433055878, 0.1801293045282364], [0.11812251806259155, 0.11812251806259155], [0.1196716576814...</code> fold_4 <code>{'std': [[0.16088004410266876, 0.16088005900382996], [0.2377340942621231, 0.2377340942621231], [0.3177623748779297, 0.3177623748779297], [0.3061956465244293, 0.3061956465244293], [0.2921837270259857, ...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_jdft2d","title":"<code>matbench_jdft2d</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_4","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 27.5769 49.7512 21.3632 243.2504 fold_1 27.9722 63.3103 0.2282 364.1909 fold_2 51.3402 142.7963 0.6111 845.7528 fold_3 26.9141 52.8447 0.2724 311.7558 fold_4 38.8806 152.4413 0.4853 1534.9797"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_4","title":"Fold score stats","text":"metric mean max min std mae 34.5368 51.3402 26.9141 9.4959 rmse 92.2288 152.4413 49.7512 45.5508 mape* 4.5920 21.3632 0.2282 8.3868 max_error 659.9859 1534.9797 243.2504 486.3231"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_4","title":"Fold parameters","text":"fold params dict fold_0 <code>{'std': [[9.497343063354492], [15.862295150756836], [74.97210693359375], [25.96040916442871], [47.26897048950195], [14.80854606628418], [22.77548599243164], [10.362432479858398], [8.255328178405762], ...</code> fold_1 <code>{'std': [[5.382687568664551], [25.67997932434082], [16.605792999267578], [7.763948917388916], [10.631340026855469], [36.21831512451172], [12.867671012878418], [3.2303359508514404], [38.958377838134766...</code> fold_2 <code>{'std': [[71.73993682861328], [18.688243865966797], [7.084332466125488], [16.097488403320312], [83.72747802734375], [12.528894424438477], [16.004690170288086], [14.574416160583496], [7.346397399902344...</code> fold_3 <code>{'std': [[2.2033019065856934], [17.148666381835938], [6.929365634918213], [3.3733177185058594], [19.175621032714844], [9.659783363342285], [2.456592321395874], [13.089242935180664], [44.94028091430664...</code> fold_4 <code>{'std': [[24.92951202392578], [17.333660125732422], [10.269680976867676], [4.752265453338623], [3.5876128673553467], [4.854499340057373], [12.900960922241211], [6.644251823425293], [9.120869636535645]...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_log_gvrh","title":"<code>matbench_log_gvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_5","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0731 0.1089 0.0576 0.9014 fold_1 0.0738 0.1111 0.0579 1.1745 fold_2 0.0731 0.1101 0.0587 0.9076 fold_3 0.0738 0.1115 0.0567 0.9225 fold_4 0.0718 0.1101 0.0560 0.8007"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_5","title":"Fold score stats","text":"metric mean max min std mae 0.0731 0.0738 0.0718 0.0007 rmse 0.1103 0.1115 0.1089 0.0009 mape* 0.0574 0.0587 0.0560 0.0009 max_error 0.9413 1.1745 0.8007 0.1243"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_5","title":"Fold parameters","text":"fold params dict fold_0 <code>{'std': [0.06334669888019562, 0.04876908287405968, 0.0713210254907608, 0.06149518862366676, 0.05233978480100632, 0.053833525627851486, 0.045166339725255966, 0.09107258170843124, 0.08312246203422546, 0...</code> fold_1 <code>{'std': [0.04058562591671944, 0.09664303809404373, 0.06196340546011925, 0.07074710726737976, 0.05361659824848175, 0.05300111323595047, 0.04533914476633072, 0.060226064175367355, 0.15155699849128723, 0...</code> fold_2 <code>{'std': [0.04066888242959976, 0.05564378947019577, 0.05513373762369156, 0.03629153221845627, 0.08530019223690033, 0.0363982692360878, 0.07014258950948715, 0.07834821194410324, 0.056601572781801224, 0....</code> fold_3 <code>{'std': [0.06376504898071289, 0.2838374972343445, 0.025865282863378525, 0.04888685792684555, 0.18576562404632568, 0.045733798295259476, 0.047175027430057526, 0.04196206107735634, 0.06469003856182098, ...</code> fold_4 <code>{'std': [0.06425822526216507, 0.07589271664619446, 0.04857879504561424, 0.07567392289638519, 0.07976284623146057, 0.05443073436617851, 0.0474713109433651, 0.08143744617700577, 0.10169852524995804, 0.0...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_log_kvrh","title":"<code>matbench_log_kvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_6","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0536 0.1013 0.0356 1.5366 fold_1 0.0559 0.1079 0.0366 1.2998 fold_2 0.0510 0.0949 0.0340 1.1808 fold_3 0.0585 0.1126 0.0418 1.1355 fold_4 0.0549 0.1046 0.0370 1.3202"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_6","title":"Fold score stats","text":"metric mean max min std mae 0.0548 0.0585 0.0510 0.0025 rmse 0.1043 0.1126 0.0949 0.0060 mape* 0.0370 0.0418 0.0340 0.0026 max_error 1.2946 1.5366 1.1355 0.1397"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_6","title":"Fold parameters","text":"fold params dict fold_0 <code>{'std': [0.03473027050495148, 0.05344022810459137, 0.04392522946000099, 0.09693300724029541, 0.0621185339987278, 0.0515923835337162, 0.034392938017845154, 0.0368841215968132, 0.09843463450670242, 0.03...</code> fold_1 <code>{'std': [0.037284620106220245, 0.0660589188337326, 0.05483892932534218, 0.05504067987203598, 0.045397065579891205, 0.053156472742557526, 0.04068203642964363, 0.04492218419909477, 0.1503378003835678, 0...</code> fold_2 <code>{'std': [0.04053986072540283, 0.039209164679050446, 0.04213540256023407, 0.036292385309934616, 0.06385202705860138, 0.032488591969013214, 0.0784469023346901, 0.0694998949766159, 0.050309233367443085, ...</code> fold_3 <code>{'std': [0.04948587343096733, 0.11705353856086731, 0.025648461654782295, 0.03585298731923103, 0.11334579437971115, 0.03046250157058239, 0.040365662425756454, 0.03331249952316284, 0.038164108991622925,...</code> fold_4 <code>{'std': [0.04571979492902756, 0.0366676039993763, 0.036114685237407684, 0.06556463986635208, 0.07480020076036453, 0.03638936206698418, 0.05547630041837692, 0.10959770530462265, 0.16662324965000153, 0....</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_mp_e_form","title":"<code>matbench_mp_e_form</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_7","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0402 0.0817 0.3786 4.0438 fold_1 0.0497 0.1018 0.3121 4.8803 fold_2 0.0475 0.0905 0.2562 1.6230 fold_3 0.0464 0.0889 0.3515 1.5189 fold_4 0.0400 0.0812 0.2882 3.3787"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_7","title":"Fold score stats","text":"metric mean max min std mae 0.0448 0.0497 0.0400 0.0039 rmse 0.0888 0.1018 0.0812 0.0075 mape* 0.3173 0.3786 0.2562 0.0436 max_error 3.0889 4.8803 1.5189 1.3281"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_7","title":"Fold parameters","text":"fold params dict fold_0 <code>{'std': [[0.0636366754770279], [0.02924380451440811], [0.11916627734899521], [0.11677506566047668], [0.1760452687740326], [0.1811746507883072], [0.08742818236351013], [0.1322329342365265], [0.14015400...</code> fold_1 <code>{'std': [[0.10467445850372314], [0.2568114399909973], [0.08591523766517639], [0.11847899109125137], [1.0217572450637817], [0.2770746350288391], [0.20971281826496124], [0.19037210941314697], [0.0730839...</code> fold_2 <code>{'std': [[0.07034026086330414], [0.07515157759189606], [0.1308293640613556], [0.23308764398097992], [0.2118426114320755], [0.1338074803352356], [0.17896589636802673], [0.09289371967315674], [0.0988285...</code> fold_3 <code>{'std': [[0.17922396957874298], [0.21060164272785187], [0.04639369249343872], [0.0925942063331604], [0.06210273131728172], [0.28422462940216064], [0.2840571105480194], [0.2760363817214966], [0.1231188...</code> fold_4 <code>{'std': [[0.1517249494791031], [0.13391436636447906], [0.40770843625068665], [0.13683228194713593], [0.124815434217453], [0.042988162487745285], [0.13916344940662384], [0.06709353625774384], [0.053676...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_mp_gap","title":"<code>matbench_mp_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_8","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2147 0.4441 2.8966 5.0558 fold_1 0.2161 0.4484 2.6899 6.2874 fold_2 0.2165 0.4433 4.1912 7.5685 fold_3 0.2309 0.4705 4.6749 6.9325 fold_4 0.2211 0.4564 4.9590 4.9406"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_8","title":"Fold score stats","text":"metric mean max min std mae 0.2199 0.2309 0.2147 0.0059 rmse 0.4525 0.4705 0.4433 0.0101 mape* 3.8823 4.9590 2.6899 0.9248 max_error 6.1570 7.5685 4.9406 1.0299"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_8","title":"Fold parameters","text":"fold params dict fold_0 <code>{'std': [[0.2779600918292999], [0.1588134467601776], [0.0013879217440262437], [0.0013879217440262437], [0.0013879217440262437], [0.15315547585487366], [0.4301016926765442], [0.19215451180934906], [0.0...</code> fold_1 <code>{'std': [[0.0023871688172221184], [0.0023871688172221184], [0.0023871688172221184], [0.0023871688172221184], [0.0023871688172221184], [0.0023871688172221184], [0.35058045387268066], [0.439932823181152...</code> fold_2 <code>{'std': [[0.17874807119369507], [0.0015997957671061158], [0.0015997957671061158], [0.35170578956604004], [0.0015997957671061158], [0.0015997957671061158], [0.0015997957671061158], [0.00156632636208087...</code> fold_3 <code>{'std': [[0.004137647803872824], [0.004137647803872824], [0.004137647803872824], [0.004137647803872824], [0.004137647803872824], [0.004137647803872824], [0.004137647803872824], [0.004137647803872824],...</code> fold_4 <code>{'std': [[0.4364481568336487], [0.0038157568778842688], [0.003807253669947386], [0.003807792905718088], [0.003815052565187216], [0.0038899907376617193], [0.0038147747982293367], [0.19303250312805176],...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_mp_is_metal","title":"<code>matbench_mp_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_9","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.8515 0.8415 0.8175 0.8415 fold_1 0.8824 0.8709 0.8526 0.8709 fold_2 0.5650 0.5000 0.0000 0.5000 fold_3 0.8575 0.8447 0.8200 0.8447 fold_4 0.8588 0.8453 0.8203 0.8453"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_9","title":"Fold score stats","text":"metric mean max min std accuracy 0.8031 0.8824 0.5650 0.1195 balanced_accuracy 0.7805 0.8709 0.5000 0.1406 f1 0.6621 0.8526 0.0000 0.3313 rocauc 0.7805 0.8709 0.5000 0.1406"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_9","title":"Fold parameters","text":"fold params dict fold_0 <code>{'std': [[0.0416233129799366, 0.041623327881097794], [0.06803157180547714, 0.06803156435489655], [0.008189204148948193, 0.008189203217625618], [0.0037693644408136606, 0.003769365604966879], [0.0107376...</code> fold_1 <code>{'std': [[0.2837996482849121, 0.2837996482849121], [0.28376519680023193, 0.28376519680023193], [0.2669283449649811, 0.2669283449649811], [0.2666773200035095, 0.2666773200035095], [0.3405170142650604, ...</code> fold_2 <code>{'std': [[0.1777520626783371, 0.1777520775794983], [0.1777520626783371, 0.1777520775794983], [0.1777520626783371, 0.1777520775794983], [0.1777520626783371, 0.1777520775794983], [0.1777520626783371, 0....</code> fold_3 <code>{'std': [[0.22140955924987793, 0.22140958905220032], [0.2370903342962265, 0.2370903342962265], [0.2370903342962265, 0.2370903342962265], [0.2370903342962265, 0.2370903342962265], [0.2370903342962265, ...</code> fold_4 <code>{'std': [[0.09707242995500565, 0.09707243740558624], [0.259949266910553, 0.2599492371082306], [0.09707242995500565, 0.09707243740558624], [0.23583407700061798, 0.2358340471982956], [0.2358340770006179...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_perovskites","title":"<code>matbench_perovskites</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_10","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0932 0.1304 0.0970 0.8705 fold_1 0.0939 0.1283 0.1058 1.0063 fold_2 0.0861 0.1216 0.0939 0.9432 fold_3 0.0892 0.1274 0.0995 0.8501 fold_4 0.0914 0.1310 0.0894 1.1780"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_10","title":"Fold score stats","text":"metric mean max min std mae 0.0908 0.0939 0.0861 0.0028 rmse 0.1277 0.1310 0.1216 0.0033 mape* 0.0971 0.1058 0.0894 0.0055 max_error 0.9696 1.1780 0.8501 0.1180"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_10","title":"Fold parameters","text":"fold params dict fold_0 <code>{'std': [[0.10714199393987656], [0.0770525336265564], [0.07103670388460159], [0.047520048916339874], [0.09854762256145477], [0.054435212165117264], [0.06670265644788742], [0.12760771811008453], [0.110...</code> fold_1 <code>{'std': [[0.06410787999629974], [0.09309504926204681], [0.07608579844236374], [0.08194778114557266], [0.11951383203268051], [0.07481898367404938], [0.04808051139116287], [0.08761747926473618], [0.0603...</code> fold_2 <code>{'std': [[0.10084810853004456], [0.10042519122362137], [0.10863561928272247], [0.11654899269342422], [0.08363119512796402], [0.11726558208465576], [0.12616018950939178], [0.104669950902462], [0.083491...</code> fold_3 <code>{'std': [[0.0883394405245781], [0.0751652866601944], [0.07409299165010452], [0.12206761538982391], [0.10416710376739502], [0.11867869645357132], [0.15680250525474548], [0.07212385535240173], [0.066893...</code> fold_4 <code>{'std': [[0.15121375024318695], [0.09383570402860641], [0.10639220476150513], [0.09952569007873535], [0.060146454721689224], [0.0721314549446106], [0.09489388763904572], [0.0831003338098526], [0.09796...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_phonons","title":"<code>matbench_phonons</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_11","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 40.2218 99.9366 0.0661 1031.8168 fold_1 41.1190 83.0600 0.0680 721.2376 fold_2 38.8526 70.0409 0.0705 452.0254 fold_3 37.1039 78.3636 0.0710 662.8152 fold_4 36.4648 59.7092 0.0665 342.3226"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_11","title":"Fold score stats","text":"metric mean max min std mae 38.7524 41.1190 36.4648 1.7732 rmse 78.2220 99.9366 59.7092 13.4507 mape* 0.0684 0.0710 0.0661 0.0020 max_error 642.0435 1031.8168 342.3226 238.5648"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_11","title":"Fold parameters","text":"fold params dict fold_0 <code>{'std': [[26.26407814025879], [175.91537475585938], [15.736849784851074], [16.808921813964844], [18.036314010620117], [16.40987777709961], [31.393617630004883], [26.229381561279297], [16.6152362823486...</code> fold_1 <code>{'std': [[32.547828674316406], [18.21637535095215], [34.24558639526367], [27.42135238647461], [23.881690979003906], [151.67642211914062], [18.94878578186035], [19.094982147216797], [16.469425201416016...</code> fold_2 <code>{'std': [[21.542694091796875], [21.627588272094727], [15.593945503234863], [67.26934814453125], [11.872613906860352], [11.879145622253418], [12.56555461883545], [24.557519912719727], [22.6404819488525...</code> fold_3 <code>{'std': [[30.841398239135742], [17.576093673706055], [20.379390716552734], [24.910297393798828], [13.184524536132812], [24.256025314331055], [26.51211166381836], [18.35163116455078], [17.3094120025634...</code> fold_4 <code>{'std': [[11.17216968536377], [16.963390350341797], [32.19032287597656], [16.677236557006836], [27.273052215576172], [28.90708351135254], [25.442333221435547], [21.135835647583008], [16.36865615844726...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#matbench_steels","title":"<code>matbench_steels</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-scores_12","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 112.2905 189.8130 0.0707 931.3261 fold_1 81.9908 115.9188 0.0604 404.5644 fold_2 99.3739 139.4921 0.0699 411.7195 fold_3 93.2877 152.1443 0.0672 827.5305 fold_4 94.1265 152.3995 0.0709 672.9292"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-score-stats_12","title":"Fold score stats","text":"metric mean max min std mae 96.2139 112.2905 81.9908 9.8352 rmse 149.9535 189.8130 115.9188 23.9473 mape* 0.0678 0.0709 0.0604 0.0039 max_error 649.6139 931.3261 404.5644 213.6365"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.10/#fold-parameters_12","title":"Fold parameters","text":"fold params dict fold_0 <code>{'std': [[181.11865234375], [192.23825073242188], [42.135902404785156], [54.896053314208984], [164.36167907714844], [53.29085159301758], [41.6890869140625], [68.6667709350586], [96.96005249023438], [3...</code> fold_1 <code>{'std': [[69.18898010253906], [72.29112243652344], [54.083961486816406], [66.05774688720703], [51.890892028808594], [41.604408264160156], [207.0948028564453], [56.53154373168945], [111.53943634033203]...</code> fold_2 <code>{'std': [[179.28602600097656], [267.37554931640625], [125.63412475585938], [117.67745971679688], [43.56736755371094], [56.37009811401367], [37.02374267578125], [116.51256561279297], [162.7328186035156...</code> fold_3 <code>{'std': [[264.0724182128906], [320.3443603515625], [69.12999725341797], [98.54374694824219], [102.41849517822266], [85.94804382324219], [39.834190368652344], [159.82240295410156], [59.77300262451172],...</code> fold_4 <code>{'std': [[172.47418212890625], [83.7674560546875], [355.5929260253906], [119.87616729736328], [59.057350158691406], [119.39688873291016], [50.491127014160156], [79.44507598876953], [93.9663314819336],...</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/","title":"matbench_v0.1: MODNet (v0.1.12)","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#algorithm-description","title":"Algorithm description:","text":"<p>MODNet, the Materials Optimal Descriptor Network (v0.1.12). A feed-forward neural network, using all compatible matminer features and a relevance-redundancy based feature selection algorithm. Hyperparameter optimisation is performed with a nested grid search for the 9 smaller tasks, and with a genetic algorithm for the 4 larger tasks (<code>matbench_perovskites</code>, <code>matbench_mp_gap</code>, <code>matbench_mp_is_metal</code>, <code>matbench_mp_eform</code>. Benchmark results were loaded from https://github.com/ml-evs/modnet-matbench/releases/tag/v0.4.0, archived at 10.5281/zenodo.5109941. This latest benchmark uses an improved GA-based hyperparameter optimization.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#notes","title":"Notes:","text":"<p>None</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>('@article{De_Breuck_2021, doi = {10.1088/1361-648x/ac1280}, url = '\n '{https://doi.org/10.1088/1361-648x/ac1280}, year = 2021, month = {jul}, '\n 'publisher = {{IOP} Publishing}, volume = {33}, number = {40}, pages = '\n '{404002}, author = {Pierre-Paul De Breuck and Matthew L Evans and Gian-Marco '\n 'Rignanese}, title = {Robust model benchmarking and bias-imbalance in '\n 'data-driven materials science: a case study on {MODNet}}, journal = {Journal '\n 'of Physics: Condensed Matter}, abstract = {As the number of novel '\n 'data-driven approaches to material science continues to grow, it is crucial '\n 'to perform consistent quality, reliability and applicability assessments of '\n 'model performance. In this paper, we benchmark the Materials Optimal '\n 'Descriptor Network (MODNet) method and architecture against the recently '\n 'released MatBench v0.1, a curated test suite of materials datasets. MODNet '\n 'is shown to outperform current leaders on 6 of the 13 tasks, while closely '\n 'matching the current leaders on a further 2 tasks; MODNet performs '\n 'particularly well when the number of samples is below 10\\xa0000. Attention '\n 'is paid to two topics of concern when benchmarking models. First, we '\n 'encourage the reporting of a more diverse set of metrics as it leads to a '\n 'more comprehensive and holistic comparison of model performance. Second, an '\n 'equally important task is the uncertainty assessment of a model towards a '\n 'target domain. Significant variations in validation errors can be observed, '\n 'depending on the imbalance and bias in the training set (i.e., similarity '\n 'between training and application space). By using an ensemble MODNet model, '\n 'confidence intervals can be built and the uncertainty on individual '\n 'predictions can be quantified. Imbalance and bias issues are often '\n 'overlooked, and yet are important for successful real-world applications of '\n 'machine learning in materials science and condensed matter.}}, '\n '@article{DeBreuck2021, doi = {10.1038/s41524-021-00552-2}, url = '\n '{https://doi.org/10.1038/s41524-021-00552-2}, year = {2021}, month = jun, '\n 'publisher = {Springer Science and Business Media {LLC}}, volume = {7}, '\n 'number = {1}, author = {Pierre-Paul De Breuck and Geoffroy Hautier and '\n 'Gian-Marco Rignanese}, title = {Materials property prediction for limited '\n 'datasets enabled by feature selection and joint learning with {MODNet}}, '\n 'journal = {npj Computational Materials}}')\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#user-metadata","title":"User metadata:","text":"<pre><code>{}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#metadata","title":"Metadata:","text":"tasks recorded 13/13 complete? \u2713 composition complete? \u2713 structure complete? \u2713 regression complete? \u2713 classification complete? \u2713"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['modnet==0.1.12', 'matbench==0.2.0']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_dielectric","title":"<code>matbench_dielectric</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.1691 0.6273 0.0541 14.3880 fold_1 0.2410 1.0270 0.0786 18.1817 fold_2 0.3899 2.9174 0.0759 59.1179 fold_3 0.2775 2.2353 0.0535 52.1521 fold_4 0.2781 1.6090 0.0762 28.0821"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.2711 0.3899 0.1691 0.0714 rmse 1.6832 2.9174 0.6273 0.8221 mape* 0.0677 0.0786 0.0535 0.0113 max_error 34.3844 59.1179 14.3880 18.0529"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_expt_gap","title":"<code>matbench_expt_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_1","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.3121 0.7028 0.3201 5.7101 fold_1 0.3388 0.7483 0.3066 6.8526 fold_2 0.3763 0.8917 0.4073 9.8955 fold_3 0.3121 0.7313 0.3327 6.0927 fold_4 0.3241 0.7684 0.3777 6.9757"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_1","title":"Fold score stats","text":"metric mean max min std mae 0.3327 0.3763 0.3121 0.0239 rmse 0.7685 0.8917 0.7028 0.0653 mape* 0.3489 0.4073 0.3066 0.0377 max_error 7.1053 9.8955 5.7101 1.4723"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_1","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_expt_is_metal","title":"<code>matbench_expt_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_2","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9269 0.9269 0.9255 0.9269 fold_1 0.9136 0.9136 0.9121 0.9136 fold_2 0.9177 0.9177 0.9173 0.9177 fold_3 0.9177 0.9177 0.9169 0.9177 fold_4 0.9045 0.9045 0.9049 0.9045"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_2","title":"Fold score stats","text":"metric mean max min std accuracy 0.9161 0.9269 0.9045 0.0073 balanced_accuracy 0.9161 0.9269 0.9045 0.0072 f1 0.9153 0.9255 0.9049 0.0068 rocauc 0.9161 0.9269 0.9045 0.0072"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_2","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_glass","title":"<code>matbench_glass</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_3","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9789 0.9743 0.9851 0.9743 fold_1 0.9701 0.9618 0.9790 0.9618 fold_2 0.9639 0.9539 0.9747 0.9539 fold_3 0.9621 0.9545 0.9733 0.9545 fold_4 0.9710 0.9570 0.9798 0.9570"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_3","title":"Fold score stats","text":"metric mean max min std accuracy 0.9692 0.9789 0.9621 0.0059 balanced_accuracy 0.9603 0.9743 0.9539 0.0075 f1 0.9784 0.9851 0.9733 0.0042 rocauc 0.9603 0.9743 0.9539 0.0075"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_3","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_jdft2d","title":"<code>matbench_jdft2d</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_4","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 25.5515 61.1616 18.6554 487.7418 fold_1 30.4506 74.1756 0.1995 366.3580 fold_2 45.1925 134.5285 0.5392 871.3962 fold_3 26.9801 58.2340 0.2126 318.7579 fold_4 37.7845 155.5663 0.4803 1564.8245"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_4","title":"Fold score stats","text":"metric mean max min std mae 33.1918 45.1925 25.5515 7.3428 rmse 96.7332 155.5663 58.2340 40.3638 mape* 4.0174 18.6554 0.1995 7.3203 max_error 721.8157 1564.8245 318.7579 464.0333"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_4","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_log_gvrh","title":"<code>matbench_log_gvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_5","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0731 0.1089 0.0576 0.9014 fold_1 0.0738 0.1111 0.0579 1.1745 fold_2 0.0731 0.1101 0.0587 0.9076 fold_3 0.0738 0.1115 0.0567 0.9225 fold_4 0.0718 0.1101 0.0560 0.8007"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_5","title":"Fold score stats","text":"metric mean max min std mae 0.0731 0.0738 0.0718 0.0007 rmse 0.1103 0.1115 0.1089 0.0009 mape* 0.0574 0.0587 0.0560 0.0009 max_error 0.9413 1.1745 0.8007 0.1243"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_5","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_log_kvrh","title":"<code>matbench_log_kvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_6","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0536 0.1013 0.0356 1.5366 fold_1 0.0559 0.1079 0.0366 1.2998 fold_2 0.0510 0.0949 0.0340 1.1808 fold_3 0.0585 0.1126 0.0418 1.1355 fold_4 0.0549 0.1046 0.0370 1.3202"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_6","title":"Fold score stats","text":"metric mean max min std mae 0.0548 0.0585 0.0510 0.0025 rmse 0.1043 0.1126 0.0949 0.0060 mape* 0.0370 0.0418 0.0340 0.0026 max_error 1.2946 1.5366 1.1355 0.1397"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_6","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_mp_e_form","title":"<code>matbench_mp_e_form</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_7","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0402 0.0817 0.3786 4.0438 fold_1 0.0497 0.1018 0.3121 4.8803 fold_2 0.0475 0.0905 0.2562 1.6230 fold_3 0.0464 0.0889 0.3515 1.5189 fold_4 0.0400 0.0812 0.2882 3.3787"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_7","title":"Fold score stats","text":"metric mean max min std mae 0.0448 0.0497 0.0400 0.0039 rmse 0.0888 0.1018 0.0812 0.0075 mape* 0.3173 0.3786 0.2562 0.0436 max_error 3.0889 4.8803 1.5189 1.3281"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_7","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_mp_gap","title":"<code>matbench_mp_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_8","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2147 0.4441 2.8966 5.0558 fold_1 0.2161 0.4484 2.6899 6.2874 fold_2 0.2165 0.4433 4.1912 7.5685 fold_3 0.2309 0.4705 4.6749 6.9325 fold_4 0.2211 0.4564 4.9590 4.9406"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_8","title":"Fold score stats","text":"metric mean max min std mae 0.2199 0.2309 0.2147 0.0059 rmse 0.4525 0.4705 0.4433 0.0101 mape* 3.8823 4.9590 2.6899 0.9248 max_error 6.1570 7.5685 4.9406 1.0299"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_8","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_mp_is_metal","title":"<code>matbench_mp_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_9","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9169 0.9135 0.9028 0.9135 fold_1 0.9030 0.8995 0.8867 0.8995 fold_2 0.9131 0.9096 0.8984 0.9096 fold_3 0.8874 0.8849 0.8699 0.8849 fold_4 0.9140 0.9116 0.9003 0.9116"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_9","title":"Fold score stats","text":"metric mean max min std accuracy 0.9069 0.9169 0.8874 0.0108 balanced_accuracy 0.9038 0.9135 0.8849 0.0106 f1 0.8916 0.9028 0.8699 0.0122 rocauc 0.9038 0.9135 0.8849 0.0106"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_9","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_perovskites","title":"<code>matbench_perovskites</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_10","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0932 0.1304 0.0970 0.8705 fold_1 0.0939 0.1283 0.1058 1.0063 fold_2 0.0861 0.1216 0.0939 0.9432 fold_3 0.0892 0.1274 0.0995 0.8501 fold_4 0.0914 0.1310 0.0894 1.1780"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_10","title":"Fold score stats","text":"metric mean max min std mae 0.0908 0.0939 0.0861 0.0028 rmse 0.1277 0.1310 0.1216 0.0033 mape* 0.0971 0.1058 0.0894 0.0055 max_error 0.9696 1.1780 0.8501 0.1180"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_10","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_phonons","title":"<code>matbench_phonons</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_11","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 34.7662 87.4531 0.0580 1079.1280 fold_1 36.3582 75.3959 0.0631 640.3050 fold_2 36.5373 71.7215 0.0636 575.7557 fold_3 32.1725 61.8200 0.0658 456.9764 fold_4 31.5413 53.9441 0.0592 396.9667"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_11","title":"Fold score stats","text":"metric mean max min std mae 34.2751 36.5373 31.5413 2.0781 rmse 70.0669 87.4531 53.9441 11.5011 mape* 0.0619 0.0658 0.0580 0.0029 max_error 629.8264 1079.1280 396.9667 240.4189"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_11","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#matbench_steels","title":"<code>matbench_steels</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-scores_12","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 103.5846 185.4940 0.0659 1121.0504 fold_1 72.3160 96.1504 0.0534 394.0216 fold_2 80.5134 117.5962 0.0562 452.9860 fold_3 81.6766 133.7020 0.0587 711.4582 fold_4 100.7231 190.9186 0.0777 932.3040"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-score-stats_12","title":"Fold score stats","text":"metric mean max min std mae 87.7627 103.5846 72.3160 12.2188 rmse 144.7722 190.9186 96.1504 37.4511 mape* 0.0624 0.0777 0.0534 0.0087 max_error 722.3641 1121.0504 394.0216 276.9541"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_modnet_v0.1.12/#fold-parameters_12","title":"Fold parameters","text":"fold params dict fold_0 <code>{}</code> fold_1 <code>{}</code> fold_2 <code>{}</code> fold_3 <code>{}</code> fold_4 <code>{}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/","title":"matbench_v0.1: RF-SCM/Magpie","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#algorithm-description","title":"Algorithm description:","text":"<p>A random forest using features from the Sine Coulomb Matrix and MagPie featurization algorithms. Sine Coulomb Matrix creates structural features based on Coulombic interactions inside a periodic boundary condition (i.e., for crystalline materials with known structure). MagPie features are weighted elemental features based on elemental data such as electronegativity, melting point, and electron affinity. Algorithms were run inside of the Automatminer v1.0.3.20191111 framework for convenience, though no auto-featurization or AutoML were run. Data cleaning dropped features with more than 1% nan samples, imputing missing samples using the mean of the training data. No feature reduction was performed. Both featurization techniques were applied to structure problems, only MagPie features were applied to problems without structure. Random forest uses 500 estimators.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#notes","title":"Notes:","text":"<p>No hyperparameter tuning was performed on the RF, as a large, constant number of trees were used in constructing each fold's model; the entire training+validation set was used as training data for the RF.</p> <p>Raw data download and example notebook available on the matbench repo.</p>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#references-in-bibtex-format","title":"References (in bibtex format):","text":"<pre><code>['@article{Dunn2020,\\n'\n '  doi = {10.1038/s41524-020-00406-3},\\n'\n '  url = {https://doi.org/10.1038/s41524-020-00406-3},\\n'\n '  year = {2020},\\n'\n '  month = sep,\\n'\n '  publisher = {Springer Science and Business Media {LLC}},\\n'\n '  volume = {6},\\n'\n '  number = {1},\\n'\n '  author = {Alexander Dunn and Qi Wang and Alex Ganose and Daniel Dopp and '\n 'Anubhav Jain},\\n'\n '  title = {Benchmarking materials property prediction methods: the Matbench '\n 'test set and Automatminer reference algorithm},\\n'\n '  journal = {npj Computational Materials}\\n'\n '}',\n '@article{Breiman2001,\\n'\n '  doi = {10.1023/a:1010933404324},\\n'\n '  url = {https://doi.org/10.1023/a:1010933404324},\\n'\n '  year = {2001},\\n'\n '  publisher = {Springer Science and Business Media {LLC}},\\n'\n '  volume = {45},\\n'\n '  number = {1},\\n'\n '  pages = {5--32},\\n'\n '  author = {Leo Breiman},\\n'\n '  journal = {Machine Learning}\\n'\n '}',\n '@article{Ward2016,\\n'\n '  doi = {10.1038/npjcompumats.2016.28},\\n'\n '  url = {https://doi.org/10.1038/npjcompumats.2016.28},\\n'\n '  year = {2016},\\n'\n '  month = aug,\\n'\n '  publisher = {Springer Science and Business Media {LLC}},\\n'\n '  volume = {2},\\n'\n '  number = {1},\\n'\n '  author = {Logan Ward and Ankit Agrawal and Alok Choudhary and Christopher '\n 'Wolverton},\\n'\n '  title = {A general-purpose machine learning framework for predicting '\n 'properties of inorganic materials},\\n'\n '  journal = {npj Computational Materials}\\n'\n '}',\n '@article {QUA:QUA24917,author = {Faber, Felix and Lindmaa, Alexander and von '\n 'Lilienfeld, O. Anatole and Armiento, Rickard},title = {Crystal structure '\n 'representations for machine learning models of formation energies},journal = '\n '{International Journal of Quantum Chemistry},volume = {115},number = '\n '{16},issn = {1097-461X},url = {http://dx.doi.org/10.1002/qua.24917},doi = '\n '{10.1002/qua.24917},pages = {1094--1101},keywords = {machine learning, '\n 'formation energies, representations, crystal structure, periodic '\n 'systems},year = {2015},}']\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#user-metadata","title":"User metadata:","text":"<pre><code>{'__deepcopy__': {},\n '__getstate__': {},\n '_ipython_canary_method_should_not_exist_': {'__deepcopy__': {},\n                                              '__getstate__': {}},\n 'autofeaturizer_kwargs': {'n_jobs': 10, 'preset': 'debug'},\n 'best_pipeline': 'RandomForestRegressor(bootstrap=true, criterion=mse, '\n                  'max_depth=null,\\n'\n                  '           max_features=auto, max_leaf_nodes=null,\\n'\n                  '           min_impurity_decrease=0.0, '\n                  'min_impurity_split=null,\\n'\n                  '           min_samples_leaf=1, min_samples_split=2,\\n'\n                  '           min_weight_fraction_leaf=0.0, n_estimators=500, '\n                  'n_jobs=null,\\n'\n                  '           oob_score=false, random_state=null, verbose=0, '\n                  'warm_start=false)',\n 'cleaner_kwargs': {'feature_na_method': 'mean',\n                    'max_na_frac': 0.01,\n                    'na_method_fit': 'drop',\n                    'na_method_transform': 'mean'},\n 'features_all': ['MagpieData minimum Number',\n                  'MagpieData maximum Number',\n                  'MagpieData range Number',\n                  'MagpieData mean Number',\n                  'MagpieData avg_dev Number',\n                  'MagpieData mode Number',\n                  'MagpieData minimum MendeleevNumber',\n                  'MagpieData maximum MendeleevNumber',\n                  'MagpieData range MendeleevNumber',\n                  'MagpieData mean MendeleevNumber',\n                  'MagpieData avg_dev MendeleevNumber',\n                  'MagpieData mode MendeleevNumber',\n                  'MagpieData minimum AtomicWeight',\n                  'MagpieData maximum AtomicWeight',\n                  'MagpieData range AtomicWeight',\n                  'MagpieData mean AtomicWeight',\n                  'MagpieData avg_dev AtomicWeight',\n                  'MagpieData mode AtomicWeight',\n                  'MagpieData minimum MeltingT',\n                  'MagpieData maximum MeltingT',\n                  'MagpieData range MeltingT',\n                  'MagpieData mean MeltingT',\n                  'MagpieData avg_dev MeltingT',\n                  'MagpieData mode MeltingT',\n                  'MagpieData minimum Column',\n                  'MagpieData maximum Column',\n                  'MagpieData range Column',\n                  'MagpieData mean Column',\n                  'MagpieData avg_dev Column',\n                  'MagpieData mode Column',\n                  'MagpieData minimum Row',\n                  'MagpieData maximum Row',\n                  'MagpieData range Row',\n                  'MagpieData mean Row',\n                  'MagpieData avg_dev Row',\n                  'MagpieData mode Row',\n                  'MagpieData minimum CovalentRadius',\n                  'MagpieData maximum CovalentRadius',\n                  'MagpieData range CovalentRadius',\n                  'MagpieData mean CovalentRadius',\n                  'MagpieData avg_dev CovalentRadius',\n                  'MagpieData mode CovalentRadius',\n                  'MagpieData minimum Electronegativity',\n                  'MagpieData maximum Electronegativity',\n                  'MagpieData range Electronegativity',\n                  'MagpieData mean Electronegativity',\n                  'MagpieData avg_dev Electronegativity',\n                  'MagpieData mode Electronegativity',\n                  'MagpieData minimum NsValence',\n                  'MagpieData maximum NsValence',\n                  'MagpieData range NsValence',\n                  'MagpieData mean NsValence',\n                  'MagpieData avg_dev NsValence',\n                  'MagpieData mode NsValence',\n                  'MagpieData minimum NpValence',\n                  'MagpieData maximum NpValence',\n                  'MagpieData range NpValence',\n                  'MagpieData mean NpValence',\n                  'MagpieData avg_dev NpValence',\n                  'MagpieData mode NpValence',\n                  'MagpieData minimum NdValence',\n                  'MagpieData maximum NdValence',\n                  'MagpieData range NdValence',\n                  'MagpieData mean NdValence',\n                  'MagpieData avg_dev NdValence',\n                  'MagpieData mode NdValence',\n                  'MagpieData minimum NfValence',\n                  'MagpieData maximum NfValence',\n                  'MagpieData range NfValence',\n                  'MagpieData mean NfValence',\n                  'MagpieData avg_dev NfValence',\n                  'MagpieData mode NfValence',\n                  'MagpieData minimum NValence',\n                  'MagpieData maximum NValence',\n                  'MagpieData range NValence',\n                  'MagpieData mean NValence',\n                  'MagpieData avg_dev NValence',\n                  'MagpieData mode NValence',\n                  'MagpieData minimum NsUnfilled',\n                  'MagpieData maximum NsUnfilled',\n                  'MagpieData range NsUnfilled',\n                  'MagpieData mean NsUnfilled',\n                  'MagpieData avg_dev NsUnfilled',\n                  'MagpieData mode NsUnfilled',\n                  'MagpieData minimum NpUnfilled',\n                  'MagpieData maximum NpUnfilled',\n                  'MagpieData range NpUnfilled',\n                  'MagpieData mean NpUnfilled',\n                  'MagpieData avg_dev NpUnfilled',\n                  'MagpieData mode NpUnfilled',\n                  'MagpieData minimum NdUnfilled',\n                  'MagpieData maximum NdUnfilled',\n                  'MagpieData range NdUnfilled',\n                  'MagpieData mean NdUnfilled',\n                  'MagpieData avg_dev NdUnfilled',\n                  'MagpieData mode NdUnfilled',\n                  'MagpieData minimum NfUnfilled',\n                  'MagpieData maximum NfUnfilled',\n                  'MagpieData range NfUnfilled',\n                  'MagpieData mean NfUnfilled',\n                  'MagpieData avg_dev NfUnfilled',\n                  'MagpieData mode NfUnfilled',\n                  'MagpieData minimum NUnfilled',\n                  'MagpieData maximum NUnfilled',\n                  'MagpieData range NUnfilled',\n                  'MagpieData mean NUnfilled',\n                  'MagpieData avg_dev NUnfilled',\n                  'MagpieData mode NUnfilled',\n                  'MagpieData minimum GSvolume_pa',\n                  'MagpieData maximum GSvolume_pa',\n                  'MagpieData range GSvolume_pa',\n                  'MagpieData mean GSvolume_pa',\n                  'MagpieData avg_dev GSvolume_pa',\n                  'MagpieData mode GSvolume_pa',\n                  'MagpieData minimum GSbandgap',\n                  'MagpieData maximum GSbandgap',\n                  'MagpieData range GSbandgap',\n                  'MagpieData mean GSbandgap',\n                  'MagpieData avg_dev GSbandgap',\n                  'MagpieData mode GSbandgap',\n                  'MagpieData minimum GSmagmom',\n                  'MagpieData maximum GSmagmom',\n                  'MagpieData range GSmagmom',\n                  'MagpieData mean GSmagmom',\n                  'MagpieData avg_dev GSmagmom',\n                  'MagpieData mode GSmagmom',\n                  'MagpieData minimum SpaceGroupNumber',\n                  'MagpieData maximum SpaceGroupNumber',\n                  'MagpieData range SpaceGroupNumber',\n                  'MagpieData mean SpaceGroupNumber',\n                  'MagpieData avg_dev SpaceGroupNumber',\n                  'MagpieData mode SpaceGroupNumber',\n                  'sine coulomb matrix eig 0',\n                  'sine coulomb matrix eig 1',\n                  'sine coulomb matrix eig 2',\n                  'sine coulomb matrix eig 3',\n                  'sine coulomb matrix eig 4',\n                  'sine coulomb matrix eig 5',\n                  'sine coulomb matrix eig 6',\n                  'sine coulomb matrix eig 7',\n                  'sine coulomb matrix eig 8',\n                  'sine coulomb matrix eig 9',\n                  'sine coulomb matrix eig 10',\n                  'sine coulomb matrix eig 11',\n                  'sine coulomb matrix eig 12',\n                  'sine coulomb matrix eig 13',\n                  'sine coulomb matrix eig 14',\n                  'sine coulomb matrix eig 15',\n                  'sine coulomb matrix eig 16',\n                  'sine coulomb matrix eig 17',\n                  'sine coulomb matrix eig 18',\n                  'sine coulomb matrix eig 19',\n                  'sine coulomb matrix eig 20',\n                  'sine coulomb matrix eig 21',\n                  'sine coulomb matrix eig 22',\n                  'sine coulomb matrix eig 23',\n                  'sine coulomb matrix eig 24',\n                  'sine coulomb matrix eig 25',\n                  'sine coulomb matrix eig 26',\n                  'sine coulomb matrix eig 27',\n                  'sine coulomb matrix eig 28',\n                  'sine coulomb matrix eig 29',\n                  'sine coulomb matrix eig 30',\n                  'sine coulomb matrix eig 31',\n                  'sine coulomb matrix eig 32',\n                  'sine coulomb matrix eig 33',\n                  'sine coulomb matrix eig 34',\n                  'sine coulomb matrix eig 35',\n                  'sine coulomb matrix eig 36',\n                  'sine coulomb matrix eig 37',\n                  'sine coulomb matrix eig 38',\n                  'sine coulomb matrix eig 39',\n                  'sine coulomb matrix eig 40',\n                  'sine coulomb matrix eig 41',\n                  'sine coulomb matrix eig 42',\n                  'sine coulomb matrix eig 43',\n                  'sine coulomb matrix eig 44',\n                  'sine coulomb matrix eig 45',\n                  'sine coulomb matrix eig 46',\n                  'sine coulomb matrix eig 47',\n                  'sine coulomb matrix eig 48',\n                  'sine coulomb matrix eig 49',\n                  'sine coulomb matrix eig 50',\n                  'sine coulomb matrix eig 51',\n                  'sine coulomb matrix eig 52',\n                  'sine coulomb matrix eig 53',\n                  'sine coulomb matrix eig 54',\n                  'sine coulomb matrix eig 55',\n                  'sine coulomb matrix eig 56',\n                  'sine coulomb matrix eig 57',\n                  'sine coulomb matrix eig 58',\n                  'sine coulomb matrix eig 59',\n                  'sine coulomb matrix eig 60',\n                  'sine coulomb matrix eig 61',\n                  'sine coulomb matrix eig 62',\n                  'sine coulomb matrix eig 63',\n                  'sine coulomb matrix eig 64',\n                  'sine coulomb matrix eig 65',\n                  'sine coulomb matrix eig 66',\n                  'sine coulomb matrix eig 67',\n                  'sine coulomb matrix eig 68',\n                  'sine coulomb matrix eig 69',\n                  'sine coulomb matrix eig 70',\n                  'sine coulomb matrix eig 71',\n                  'sine coulomb matrix eig 72',\n                  'sine coulomb matrix eig 73',\n                  'sine coulomb matrix eig 74',\n                  'sine coulomb matrix eig 75',\n                  'sine coulomb matrix eig 76',\n                  'sine coulomb matrix eig 77',\n                  'sine coulomb matrix eig 78',\n                  'sine coulomb matrix eig 79',\n                  'sine coulomb matrix eig 80',\n                  'sine coulomb matrix eig 81',\n                  'sine coulomb matrix eig 82',\n                  'sine coulomb matrix eig 83',\n                  'sine coulomb matrix eig 84',\n                  'sine coulomb matrix eig 85',\n                  'sine coulomb matrix eig 86',\n                  'sine coulomb matrix eig 87',\n                  'sine coulomb matrix eig 88',\n                  'sine coulomb matrix eig 89',\n                  'sine coulomb matrix eig 90',\n                  'sine coulomb matrix eig 91',\n                  'sine coulomb matrix eig 92',\n                  'sine coulomb matrix eig 93',\n                  'sine coulomb matrix eig 94',\n                  'sine coulomb matrix eig 95',\n                  'sine coulomb matrix eig 96',\n                  'sine coulomb matrix eig 97',\n                  'sine coulomb matrix eig 98',\n                  'sine coulomb matrix eig 99',\n                  'sine coulomb matrix eig 100',\n                  'sine coulomb matrix eig 101',\n                  'sine coulomb matrix eig 102',\n                  'sine coulomb matrix eig 103',\n                  'sine coulomb matrix eig 104',\n                  'sine coulomb matrix eig 105',\n                  'sine coulomb matrix eig 106',\n                  'sine coulomb matrix eig 107',\n                  'sine coulomb matrix eig 108',\n                  'sine coulomb matrix eig 109',\n                  'sine coulomb matrix eig 110',\n                  'sine coulomb matrix eig 111',\n                  'sine coulomb matrix eig 112',\n                  'sine coulomb matrix eig 113',\n                  'sine coulomb matrix eig 114',\n                  'sine coulomb matrix eig 115',\n                  'sine coulomb matrix eig 116',\n                  'sine coulomb matrix eig 117',\n                  'sine coulomb matrix eig 118',\n                  'sine coulomb matrix eig 119',\n                  'sine coulomb matrix eig 120',\n                  'sine coulomb matrix eig 121',\n                  'sine coulomb matrix eig 122',\n                  'sine coulomb matrix eig 123',\n                  'sine coulomb matrix eig 124',\n                  'sine coulomb matrix eig 125',\n                  'sine coulomb matrix eig 126',\n                  'sine coulomb matrix eig 127',\n                  'sine coulomb matrix eig 128',\n                  'sine coulomb matrix eig 129',\n                  'sine coulomb matrix eig 130',\n                  'sine coulomb matrix eig 131',\n                  'sine coulomb matrix eig 132',\n                  'sine coulomb matrix eig 133',\n                  'sine coulomb matrix eig 134',\n                  'sine coulomb matrix eig 135',\n                  'sine coulomb matrix eig 136',\n                  'sine coulomb matrix eig 137',\n                  'sine coulomb matrix eig 138',\n                  'sine coulomb matrix eig 139',\n                  'sine coulomb matrix eig 140',\n                  'sine coulomb matrix eig 141',\n                  'sine coulomb matrix eig 142',\n                  'sine coulomb matrix eig 143',\n                  'sine coulomb matrix eig 144',\n                  'sine coulomb matrix eig 145',\n                  'sine coulomb matrix eig 146',\n                  'sine coulomb matrix eig 147',\n                  'sine coulomb matrix eig 148',\n                  'sine coulomb matrix eig 149',\n                  'sine coulomb matrix eig 150',\n                  'sine coulomb matrix eig 151',\n                  'sine coulomb matrix eig 152',\n                  'sine coulomb matrix eig 153',\n                  'sine coulomb matrix eig 154',\n                  'sine coulomb matrix eig 155',\n                  'sine coulomb matrix eig 156',\n                  'sine coulomb matrix eig 157',\n                  'sine coulomb matrix eig 158',\n                  'sine coulomb matrix eig 159',\n                  'sine coulomb matrix eig 160',\n                  'sine coulomb matrix eig 161',\n                  'sine coulomb matrix eig 162',\n                  'sine coulomb matrix eig 163',\n                  'sine coulomb matrix eig 164',\n                  'sine coulomb matrix eig 165',\n                  'sine coulomb matrix eig 166',\n                  'sine coulomb matrix eig 167',\n                  'sine coulomb matrix eig 168',\n                  'sine coulomb matrix eig 169',\n                  'sine coulomb matrix eig 170',\n                  'sine coulomb matrix eig 171',\n                  'sine coulomb matrix eig 172',\n                  'sine coulomb matrix eig 173',\n                  'sine coulomb matrix eig 174',\n                  'sine coulomb matrix eig 175',\n                  'sine coulomb matrix eig 176',\n                  'sine coulomb matrix eig 177',\n                  'sine coulomb matrix eig 178',\n                  'sine coulomb matrix eig 179',\n                  'sine coulomb matrix eig 180',\n                  'sine coulomb matrix eig 181',\n                  'sine coulomb matrix eig 182',\n                  'sine coulomb matrix eig 183',\n                  'sine coulomb matrix eig 184',\n                  'sine coulomb matrix eig 185',\n                  'sine coulomb matrix eig 186',\n                  'sine coulomb matrix eig 187',\n                  'sine coulomb matrix eig 188',\n                  'sine coulomb matrix eig 189',\n                  'sine coulomb matrix eig 190',\n                  'sine coulomb matrix eig 191',\n                  'sine coulomb matrix eig 192',\n                  'sine coulomb matrix eig 193',\n                  'sine coulomb matrix eig 194',\n                  'sine coulomb matrix eig 195',\n                  'sine coulomb matrix eig 196',\n                  'sine coulomb matrix eig 197',\n                  'sine coulomb matrix eig 198',\n                  'sine coulomb matrix eig 199',\n                  'sine coulomb matrix eig 200',\n                  'sine coulomb matrix eig 201',\n                  'sine coulomb matrix eig 202',\n                  'sine coulomb matrix eig 203',\n                  'sine coulomb matrix eig 204',\n                  'sine coulomb matrix eig 205',\n                  'sine coulomb matrix eig 206',\n                  'sine coulomb matrix eig 207',\n                  'sine coulomb matrix eig 208',\n                  'sine coulomb matrix eig 209',\n                  'sine coulomb matrix eig 210',\n                  'sine coulomb matrix eig 211',\n                  'sine coulomb matrix eig 212',\n                  'sine coulomb matrix eig 213',\n                  'sine coulomb matrix eig 214',\n                  'sine coulomb matrix eig 215',\n                  'sine coulomb matrix eig 216',\n                  'sine coulomb matrix eig 217',\n                  'sine coulomb matrix eig 218',\n                  'sine coulomb matrix eig 219',\n                  'sine coulomb matrix eig 220',\n                  'sine coulomb matrix eig 221',\n                  'sine coulomb matrix eig 222',\n                  'sine coulomb matrix eig 223',\n                  'sine coulomb matrix eig 224',\n                  'sine coulomb matrix eig 225',\n                  'sine coulomb matrix eig 226',\n                  'sine coulomb matrix eig 227',\n                  'sine coulomb matrix eig 228',\n                  'sine coulomb matrix eig 229',\n                  'sine coulomb matrix eig 230',\n                  'sine coulomb matrix eig 231',\n                  'sine coulomb matrix eig 232',\n                  'sine coulomb matrix eig 233',\n                  'sine coulomb matrix eig 234',\n                  'sine coulomb matrix eig 235',\n                  'sine coulomb matrix eig 236',\n                  'sine coulomb matrix eig 237',\n                  'sine coulomb matrix eig 238',\n                  'sine coulomb matrix eig 239',\n                  'sine coulomb matrix eig 240',\n                  'sine coulomb matrix eig 241',\n                  'sine coulomb matrix eig 242',\n                  'sine coulomb matrix eig 243',\n                  'sine coulomb matrix eig 244',\n                  'sine coulomb matrix eig 245',\n                  'sine coulomb matrix eig 246',\n                  'sine coulomb matrix eig 247',\n                  'sine coulomb matrix eig 248',\n                  'sine coulomb matrix eig 249',\n                  'sine coulomb matrix eig 250',\n                  'sine coulomb matrix eig 251',\n                  'sine coulomb matrix eig 252',\n                  'sine coulomb matrix eig 253',\n                  'sine coulomb matrix eig 254',\n                  'sine coulomb matrix eig 255',\n                  'sine coulomb matrix eig 256',\n                  'sine coulomb matrix eig 257',\n                  'sine coulomb matrix eig 258',\n                  'sine coulomb matrix eig 259',\n                  'sine coulomb matrix eig 260',\n                  'sine coulomb matrix eig 261',\n                  'sine coulomb matrix eig 262',\n                  'sine coulomb matrix eig 263',\n                  'sine coulomb matrix eig 264',\n                  'sine coulomb matrix eig 265',\n                  'sine coulomb matrix eig 266',\n                  'sine coulomb matrix eig 267',\n                  'sine coulomb matrix eig 268',\n                  'sine coulomb matrix eig 269',\n                  'sine coulomb matrix eig 270',\n                  'sine coulomb matrix eig 271',\n                  'sine coulomb matrix eig 272',\n                  'sine coulomb matrix eig 273',\n                  'sine coulomb matrix eig 274',\n                  'sine coulomb matrix eig 275',\n                  'sine coulomb matrix eig 276',\n                  'sine coulomb matrix eig 277',\n                  'sine coulomb matrix eig 278',\n                  'sine coulomb matrix eig 279',\n                  'sine coulomb matrix eig 280',\n                  'sine coulomb matrix eig 281',\n                  'sine coulomb matrix eig 282',\n                  'sine coulomb matrix eig 283',\n                  'sine coulomb matrix eig 284',\n                  'sine coulomb matrix eig 285',\n                  'sine coulomb matrix eig 286',\n                  'sine coulomb matrix eig 287'],\n 'learner_kwargs': {'n_estimators': 500},\n 'learner_name': 'rf',\n 'reducer_kwargs': {'reducers': []}}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#metadata","title":"Metadata:","text":"tasks recorded 13/13 complete? \u2713 composition complete? \u2713 structure complete? \u2713 regression complete? \u2713 classification complete? \u2713"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#software-requirements","title":"Software Requirements","text":"<pre><code>{'python': ['scikit-learn==0.24.1',\n            'numpy==1.20.1',\n            'matbench==0.1.0',\n            'automatminer==v1.0.3.20191111']}\n</code></pre>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#task-data","title":"Task data:","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_dielectric","title":"<code>matbench_dielectric</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.3042 0.7850 0.1176 14.5979 fold_1 0.4079 1.2316 0.1509 20.1279 fold_2 0.5220 2.9832 0.1370 59.1201 fold_3 0.3879 2.1680 0.1057 49.4924 fold_4 0.4760 2.1012 0.1886 31.0645"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats","title":"Fold score stats","text":"metric mean max min std mae 0.4196 0.5220 0.3042 0.0750 rmse 1.8538 2.9832 0.7850 0.7700 mape* 0.1400 0.1886 0.1057 0.0289 max_error 34.8806 59.1201 14.5979 16.9980"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters","title":"Fold parameters","text":"fold params dict fold_0 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_1 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_2 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_3 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_4 <code>{'note': 'single config; see benchmark user metadata'}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_expt_gap","title":"<code>matbench_expt_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_1","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.4360 0.7985 0.3380 5.1654 fold_1 0.4387 0.7819 0.3044 4.7122 fold_2 0.4812 0.9435 0.4019 9.5428 fold_3 0.4345 0.8059 0.3647 5.2288 fold_4 0.4400 0.7918 0.4385 5.5833"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_1","title":"Fold score stats","text":"metric mean max min std mae 0.4461 0.4812 0.4345 0.0177 rmse 0.8243 0.9435 0.7819 0.0601 mape* 0.3695 0.4385 0.3044 0.0470 max_error 6.0465 9.5428 4.7122 1.7700"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_1","title":"Fold parameters","text":"fold params dict fold_0 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_1 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_2 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_3 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_4 <code>{'note': 'single config; see benchmark user metadata'}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_expt_is_metal","title":"<code>matbench_expt_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_2","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9249 0.9248 0.9236 0.9248 fold_1 0.9167 0.9166 0.9156 0.9166 fold_2 0.9096 0.9095 0.9076 0.9095 fold_3 0.9228 0.9227 0.9221 0.9227 fold_4 0.9096 0.9096 0.9104 0.9096"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_2","title":"Fold score stats","text":"metric mean max min std accuracy 0.9167 0.9249 0.9096 0.0064 balanced_accuracy 0.9167 0.9248 0.9095 0.0064 f1 0.9159 0.9236 0.9076 0.0063 rocauc 0.9167 0.9248 0.9095 0.0064"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_2","title":"Fold parameters","text":"fold params dict fold_0 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_1 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_2 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_3 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_4 <code>{'note': 'single config; see benchmark user metadata'}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_glass","title":"<code>matbench_glass</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_3","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9199 0.8860 0.9449 0.8860 fold_1 0.8856 0.8402 0.9217 0.8402 fold_2 0.8847 0.8495 0.9200 0.8495 fold_3 0.8891 0.8526 0.9233 0.8526 fold_4 0.8979 0.8651 0.9292 0.8651"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_3","title":"Fold score stats","text":"metric mean max min std accuracy 0.8954 0.9199 0.8847 0.0131 balanced_accuracy 0.8587 0.8860 0.8402 0.0158 f1 0.9278 0.9449 0.9200 0.0091 rocauc 0.8587 0.8860 0.8402 0.0158"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_3","title":"Fold parameters","text":"fold params dict fold_0 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_1 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_2 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_3 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_4 <code>{'note': 'single config; see benchmark user metadata'}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_jdft2d","title":"<code>matbench_jdft2d</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_4","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 42.7473 72.7391 23.7625 295.7437 fold_1 45.7510 94.3771 0.4382 581.4859 fold_2 66.2421 153.0635 0.8747 836.6225 fold_3 44.0340 81.5112 0.4818 337.7693 fold_4 51.4457 159.6390 0.6384 1538.6073"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_4","title":"Fold score stats","text":"metric mean max min std mae 50.0440 66.2421 42.7473 8.6271 rmse 112.2660 159.6390 72.7391 36.7066 mape* 5.2391 23.7625 0.4382 9.2629 max_error 718.0457 1538.6073 295.7437 453.6473"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_4","title":"Fold parameters","text":"fold params dict fold_0 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_1 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_2 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_3 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_4 <code>{'note': 'single config; see benchmark user metadata'}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_log_gvrh","title":"<code>matbench_log_gvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_5","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.1046 0.1515 0.0817 1.1754 fold_1 0.1024 0.1557 0.0815 1.6942 fold_2 0.1025 0.1533 0.0798 1.0668 fold_3 0.1037 0.1495 0.0777 0.9041 fold_4 0.1067 0.1601 0.0832 0.9480"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_5","title":"Fold score stats","text":"metric mean max min std mae 0.1040 0.1067 0.1024 0.0016 rmse 0.1540 0.1601 0.1495 0.0037 mape* 0.0808 0.0832 0.0777 0.0019 max_error 1.1577 1.6942 0.9041 0.2845"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_5","title":"Fold parameters","text":"fold params dict fold_0 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_1 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_2 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_3 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_4 <code>{'note': 'single config; see benchmark user metadata'}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_log_kvrh","title":"<code>matbench_log_kvrh</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_6","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.0809 0.1415 0.0522 1.4432 fold_1 0.0808 0.1503 0.0532 1.7642 fold_2 0.0783 0.1383 0.0509 1.1189 fold_3 0.0863 0.1478 0.0608 1.1620 fold_4 0.0836 0.1489 0.0558 1.3775"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_6","title":"Fold score stats","text":"metric mean max min std mae 0.0820 0.0863 0.0783 0.0027 rmse 0.1454 0.1503 0.1383 0.0046 mape* 0.0546 0.0608 0.0509 0.0035 max_error 1.3732 1.7642 1.1189 0.2311"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_6","title":"Fold parameters","text":"fold params dict fold_0 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_1 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_2 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_3 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_4 <code>{'note': 'single config; see benchmark user metadata'}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_mp_e_form","title":"<code>matbench_mp_e_form</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_7","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.1158 0.2386 0.9331 4.2469 fold_1 0.1160 0.2459 0.5068 5.4382 fold_2 0.1179 0.2443 0.5549 4.0782 fold_3 0.1159 0.2373 0.7206 2.9374 fold_4 0.1166 0.2435 0.6836 3.8910"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_7","title":"Fold score stats","text":"metric mean max min std mae 0.1165 0.1179 0.1158 0.0008 rmse 0.2419 0.2459 0.2373 0.0034 mape* 0.6798 0.9331 0.5068 0.1492 max_error 4.1183 5.4382 2.9374 0.8008"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_7","title":"Fold parameters","text":"fold params dict fold_0 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_1 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_2 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_3 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_4 <code>{'note': 'single config; see benchmark user metadata'}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_mp_gap","title":"<code>matbench_mp_gap</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_8","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.3456 0.6097 5.6881 6.3322 fold_1 0.3417 0.6104 4.3547 7.0601 fold_2 0.3445 0.6047 6.9303 5.9201 fold_3 0.3427 0.6101 11.9090 6.6456 fold_4 0.3512 0.6276 9.2752 6.0212"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_8","title":"Fold score stats","text":"metric mean max min std mae 0.3452 0.3512 0.3417 0.0033 rmse 0.6125 0.6276 0.6047 0.0079 mape* 7.6315 11.9090 4.3547 2.6835 max_error 6.3958 7.0601 5.9201 0.4182"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_8","title":"Fold parameters","text":"fold params dict fold_0 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_1 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_2 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_3 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_4 <code>{'note': 'single config; see benchmark user metadata'}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_mp_is_metal","title":"<code>matbench_mp_is_metal</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_9","title":"Fold scores","text":"fold accuracy balanced_accuracy f1 rocauc fold_0 0.9080 0.9025 0.8905 0.9025 fold_1 0.9027 0.8968 0.8839 0.8968 fold_2 0.9049 0.8987 0.8862 0.8987 fold_3 0.9051 0.8994 0.8869 0.8994 fold_4 0.9047 0.8984 0.8858 0.8984"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_9","title":"Fold score stats","text":"metric mean max min std accuracy 0.9051 0.9080 0.9027 0.0017 balanced_accuracy 0.8992 0.9025 0.8968 0.0019 f1 0.8866 0.8905 0.8839 0.0022 rocauc 0.8992 0.9025 0.8968 0.0019"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_9","title":"Fold parameters","text":"fold params dict fold_0 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_1 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_2 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_3 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_4 <code>{'note': 'single config; see benchmark user metadata'}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_perovskites","title":"<code>matbench_perovskites</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_10","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 0.2357 0.3292 0.2634 2.8870 fold_1 0.2367 0.3394 0.2888 2.2083 fold_2 0.2365 0.3382 0.2631 2.5900 fold_3 0.2395 0.3369 0.2827 2.6112 fold_4 0.2291 0.3293 0.2411 2.4921"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_10","title":"Fold score stats","text":"metric mean max min std mae 0.2355 0.2395 0.2291 0.0034 rmse 0.3346 0.3394 0.3292 0.0044 mape* 0.2678 0.2888 0.2411 0.0168 max_error 2.5577 2.8870 2.2083 0.2185"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_10","title":"Fold parameters","text":"fold params dict fold_0 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_1 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_2 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_3 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_4 <code>{'note': 'single config; see benchmark user metadata'}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_phonons","title":"<code>matbench_phonons</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_11","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 82.3863 171.1524 0.1348 1004.2770 fold_1 72.8871 172.8015 0.1172 2024.7301 fold_2 59.2712 128.7871 0.1040 1206.8703 fold_3 58.6036 122.1566 0.1167 861.9005 fold_4 64.9149 136.4846 0.1197 1255.6664"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_11","title":"Fold score stats","text":"metric mean max min std mae 67.6126 82.3863 58.6036 8.9900 rmse 146.2764 172.8015 122.1566 21.4752 mape* 0.1185 0.1348 0.1040 0.0098 max_error 1270.6889 2024.7301 861.9005 402.7307"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_11","title":"Fold parameters","text":"fold params dict fold_0 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_1 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_2 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_3 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_4 <code>{'note': 'single config; see benchmark user metadata'}</code>"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#matbench_steels","title":"<code>matbench_steels</code>","text":""},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-scores_12","title":"Fold scores","text":"fold mae rmse mape* max_error fold_0 114.6331 196.3586 0.0731 1121.1276 fold_1 85.6694 113.1549 0.0654 362.6630 fold_2 110.0055 150.1283 0.0807 448.9038 fold_3 111.5273 153.4522 0.0801 633.6092 fold_4 95.7271 133.8257 0.0730 408.6042"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-score-stats_12","title":"Fold score stats","text":"metric mean max min std mae 103.5125 114.6331 85.6694 11.0368 rmse 149.3839 196.3586 113.1549 27.4893 mape* 0.0745 0.0807 0.0654 0.0056 max_error 594.9816 1121.1276 362.6630 278.7002"},{"location":"Full%20Benchmark%20Data/matbench_v0.1_rf/#fold-parameters_12","title":"Fold parameters","text":"fold params dict fold_0 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_1 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_2 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_3 <code>{'note': 'single config; see benchmark user metadata'}</code> fold_4 <code>{'note': 'single config; see benchmark user metadata'}</code>"},{"location":"How%20To%20Use/1install/","title":"1 - Install matbench","text":""},{"location":"How%20To%20Use/1install/#via-github","title":"Via GitHub","text":"<p>Clone the repository with: <pre><code>git clone https://github.com/hackingmaterials/matbench\n</code></pre></p> <p>To install for the current user: <pre><code>pip install --user ./matbench\n</code></pre></p> <p>For development, install with</p> <pre><code>cd matbench\npip install -e . -r requirements.txt\n</code></pre>"},{"location":"How%20To%20Use/1install/#via-pypi","title":"Via PyPi","text":"<p>Install matbench with:</p> <pre><code>pip install matbench\n</code></pre>"},{"location":"How%20To%20Use/1install/#troubleshooting","title":"Troubleshooting","text":"<p>Matbench is supported on all Unix systems. It does not officially support Windows installations, but may work. Please use our friendly matsci.org help forum to ask for help; we don't bite!</p>"},{"location":"How%20To%20Use/2run/","title":"2 - Run benchmark on algorithm","text":""},{"location":"How%20To%20Use/2run/#recording-your-data","title":"Recording your data","text":"<p>You can use the matbench python package to retrieve the training and testing splits as well as record new predictions. Recording and saving your data with matbench should take no more than  10 lines of matbench code.</p> <p>The only things you need are:</p> <ol> <li>Your algorithm/model - we'll call it <code>my_model</code> in this example</li> <li>The <code>MatbenchBenchmark</code> class.</li> </ol> <p>Here's an example of running an entire benchmark (13 tasks) using matbench.</p> <pre><code>from matbench.bench import MatbenchBenchmark\n\nmb = MatbenchBenchmark(autoload=False)\n\nfor task in mb.tasks:\n    task.load()\n    for fold in task.folds:\n\n        # Inputs are either chemical compositions as strings\n        # or crystal structures as pymatgen.Structure objects.\n        # Outputs are either floats (regression tasks) or bools (classification tasks)\n        train_inputs, train_outputs = task.get_train_and_val_data(fold)\n\n        # train and validate your model\n        my_model.train_and_validate(train_inputs, train_outputs)\n\n        # Get testing data\n        test_inputs = task.get_test_data(fold, include_target=False)\n\n        # Predict on the testing data\n        # Your output should be a pandas series, numpy array, or python iterable\n        # where the array elements are floats or bools\n        predictions = my_model.predict(test_inputs)\n\n        # Record your data!\n        task.record(fold, predictions)\n\n# Save your results\nmb.to_file(\"my_models_benchmark.json.gz\")\n</code></pre> <p>And you're done! Your benchmark has been recorded and saved.</p> <p>The output file, in this case <code>my_models_benchmark.json.gz</code> contains everything predicted by your  benchmark. Keep this file, as it is the core result that will be submitted to the leaderboard.</p> <p>Please see the docs for Submitting to leaderboard to learn how to upload your data to the automated leaderboard.</p>"},{"location":"How%20To%20Use/2run/#note-benchmark-subsets","title":"Note: Benchmark subsets","text":"<p>If you want to benchmark on a subset of Matbench tasks, set the <code>subset</code> argument when creating <code>MatbenchBenchmark</code> and use the same code as above. The repo accepts subsets of matbench tasks as well which will appear on a separate \"task-specific\" leaderboard.</p>"},{"location":"How%20To%20Use/2run/#recording-hyperparameters-and-user-metadata","title":"Recording hyperparameters and user metadata","text":""},{"location":"How%20To%20Use/2run/#hyperparameters-for-each-fold","title":"Hyperparameters for each fold","text":"<p>Record parameters (<code>dict</code> type) for each fold using the <code>parameters</code> argument to <code>MatbenchBenchmark.record</code>:</p> <pre><code>from matbench.bench import MatbenchBenchmark\n\nmb = MatbenchBenchmark(autoload=False)\n\nfor task in mb.tasks:\n    task.load()\n    for fold in task.folds:\n        train_inputs, train_outputs = task.get_train_and_val_data(fold)\n        my_model.train_and_validate(train_inputs, train_outputs)\n        test_inputs = task.get_test_data(fold, include_target=False)\n        predictions = my_model.predict(test_inputs)\n\n        # Get your model's parameters \n        # Parameters must be a dictionary of python native types, e.g., lists of strings, dicts, etc.\n        params = my_model.get_parameters_as_dictionary()\n        task.record(fold, predictions, params=params)\n</code></pre> <p>We recommend you record the hyperparameters on each fold - but it is optional. </p> <p>Your parameters can be freeform, though we encourage brevity - only recording the most important parameters,  not large arrays or weight matrices.</p>"},{"location":"How%20To%20Use/2run/#user-metadata-for-benchmark","title":"User metadata for benchmark","text":"<p>Add arbitrary metadata about your algorithm, in <code>dict</code> format, to the benchmark. This will be included as shown on the benchmark leaderboard on the website.</p> <pre><code>my_metadata = {\n    \"algorithm_version\": \"v1\",\n    \"tree_type\": \"entropy\",\n    \"configuration\": {\n        \"some_param\": 4,\n        \"other_vector\": [1, 2, 3]\n    }\n}\n\nmb.add_metadata(my_metadata)\n</code></pre>"},{"location":"How%20To%20Use/3submit/","title":"3 - Submit to leaderboard","text":""},{"location":"How%20To%20Use/3submit/#step-1-create-3-required-files","title":"Step 1: Create 3 required files","text":"<p>To submit to the leaderboard, you need 3 files:</p> <ol> <li><code>results.json.gz</code>: The file you saved when recording your data. Instructions on how to create this file</li> <li><code>info.json</code>: A short file of some metadata about your algorithm. Instructions on how to create this file, with template</li> <li>Either (a) an <code>.ipynb</code> notebook detailing your algorithm with code for running it, or (b) one or more <code>.py</code> files with source code for running/benchmarking your algorithm. Instructions here</li> </ol>"},{"location":"How%20To%20Use/3submit/#step-2-put-files-in-appropriate-folder","title":"Step 2: Put files in appropriate folder","text":"<ul> <li>a. If you are using matbench through pypi, clone the source repository in order to make a pull request. Find instructions for cloning the source repository on the Installation page.</li> <li>b. Locate the <code>matbench/benchmarks</code> directory.</li> <li>c. Create a new directory <code>&lt;benchmark name&gt;_&lt;algorithm name&gt;</code> according to your algorithm and the benchmark you ran (e.g., <code>matbench_v0.1_my_algorithm_namev2</code>).</li> <li>d. Put the required files from Step 1 into this directory.</li> </ul> <p>The files should look like:</p> <pre><code>\u251c\u2500\u2500 benchmarks\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 matbench_v0.1_&lt;your algorithm name&gt;\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 info.json\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 my_python_file.py\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 results.json.gz\n</code></pre> <p>Warning: the <code>info.json</code> and <code>results.json.gz</code> must have these names exactly for your PR to go through without problems, automatically. You can include any other small files (no naming scheme required) for running your code in this directory.</p>"},{"location":"How%20To%20Use/3submit/#step-3-create-a-pr-to-the-matbench-repository","title":"Step 3: Create a PR to the Matbench repository","text":"<ol> <li> <p>Commit your new changes to the repo with, and create a pull request (PR) to the Matbench repository.</p> </li> <li> <p>Find instructions for creating a PR here.</p> </li> <li> <p>Label your PR with the \"new_benchmark\" label.</p> </li> </ol> <p></p> <p>And you're done! If the tests pass, your submission will be added to the leaderboard!</p>"},{"location":"How%20To%20Use/3submit/#resultsjsongz","title":"<code>results.json.gz</code>","text":"<p>This file is the <code>MatbenchBenchmark</code> you saved during your benchmark. You can find docs about how to record and save a benchmark on the Running a benchmark page. This file is required for a submission.</p>"},{"location":"How%20To%20Use/3submit/#infojson","title":"<code>info.json</code>","text":"<p>A metadata file about your algorithm, the authors, and any relevant citations. Please ensure the following keys are included, as they are required by our automated leaderboard:</p> <ul> <li><code>\"authors\"</code>: The author names for this PR</li> <li><code>\"algorithm\"</code>: The short or abbreviated name for your algorithm, e.g., <code>\"MegNET v1.0\"</code>. Should be 5-15 characters.</li> <li><code>\"algorithm_long\"</code>: A longer description of your algorithm, to be shown as details for your results. Can be up to 1000 words.</li> <li><code>\"bibtex_refs\"</code>: A comprehensive list of references for your algorithm, including manuscripts and preprints for the algorithm itself, each formatted as bibtex.</li> <li><code>\"notes\"</code>: Any other freeform notes you'd like to include as details for your algorithm/submission. Can include things like computing resources used to train/run the algorithm, methodology, alternative configurations, links, etc.</li> <li><code>\"requirements\"</code>: A dictionary of software requirements for running your algorithm. In particular, installing these should ensure your Source files run without issues. Please include the matbench version in these requirements.</li> </ul> <p>Here's an template <code>info.json</code> you can copy+paste and edit to get started:</p> <pre><code>{\n  \"authors\": \"My name\",\n  \"algorithm\": \"COOLNet v14\",\n  \"algorithm_long\": \"A longer description of my super cool algorithm, COOLNet v14.\",\n  \"bibtex_refs\": \"@article{Dunn2020,\\n  doi = {10.1038/s41524-020-00406-3},\\n  url = {https://doi.org/10.1038/s41524-020-00406-3},\\n  year = {2020},\\n  month = sep,\\n  publisher = {Springer Science and Business Media {LLC}},\\n  volume = {6},\\n  number = {1},\\n  author = {Alexander Dunn and Qi Wang and Alex Ganose and Daniel Dopp and Anubhav Jain},\\n  title = {Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm},\\n  journal = {npj Computational Materials}\\n}\",\n  \"notes\": \"Some freeform notes users might be interested in, if they were to run your source code files.\",\n  \"requirements\": {\"python\":  [\"scikit-learn==0.24.1\", \"numpy==1.20.1\", \"matbench==0.1.0\"]}\n}\n</code></pre>"},{"location":"How%20To%20Use/3submit/#source-files","title":"Source files","text":"<p>At least one source file (one or more <code>.py</code> files or a Jupyter notebook <code>.ipynb</code>) must be included with submission. This is to help others run and understand your code and results.</p>"},{"location":"How%20To%20Use/3submit/#general-guidelines","title":"General guidelines","text":"<p>The source file should contain all the code needed for configuring, training, and running your algorithm on all the benchmark tasks you decide to run.</p> <p>The easiest way to create a source file is just use the source file you used while recording your benchmark results.</p> <p>There are no naming requirements for these source files. You can also include other supporting files, like metadata, features, etc. if they are critical for the algorithm to run and they are small (&lt;10MB).</p> <p>Please include the matbench code (e.g., <code>mb.record(...)</code>) for obtaining benchmarks/recording/examining results in the source files.</p>"},{"location":"How%20To%20Use/3submit/#jupyter-notebooks","title":"Jupyter notebooks","text":"<p>The preferred format for source files is a jupyter notebook with some code for running your algorithm on Matbench. You can find an example</p> <p></p> <p>The notebook should generally follow the format of the example notebook <code>/benchmarks/matbench_v0.1_dummy/notebook.ipynb</code>. Try to include a long form, human readable description of how your algorithm works, any package versions needed to have it run correctly, and most importantly, a link to a publication for your algorithm.</p> <p>Aside from that, what goes in your notebook is pretty freeform; put whatever is needed to allow someone else to train and run your algorithm on the benchmark.</p> <p>You can find an example template for a notebook in the matbench repo under <code>/benchmarks/matbench_v0.1_dummy/notebook.ipynb</code></p>"},{"location":"How%20To%20Use/3submit/#py-files","title":"<code>.py</code> files","text":"<p>If you use <code>.py</code> files as source in the submission, please comment your code as much as you can to help others run it!</p>"},{"location":"How%20To%20Use/advanced/","title":"Advanced usage","text":"<p>Once you have recorded some data, you can examine it with the <code>MatbenchBenchmark</code> object. If you are looking to record data, see the Recording data page.</p> <p>Pretty much everything in Matbench - including scoring, saving, loading, recording, inspecting, and more - can be done thru <code>MatbenchBenchmark</code> directly.</p>"},{"location":"How%20To%20Use/advanced/#loading-and-saving","title":"Loading and saving","text":""},{"location":"How%20To%20Use/advanced/#load-a-completed-valid-benchmark-from-disk","title":"Load a completed, valid benchmark from disk:","text":"<pre><code>mb = MatbenchBechmark.from_file(\"path/to/my_results.json.gz\")\n\n&gt;&gt;&gt; mb\n&lt;MatbenchBenchmark&gt;\n</code></pre>"},{"location":"How%20To%20Use/advanced/#save-a-completed-valid-benchmark-to-disk","title":"Save a completed, valid benchmark to disk","text":"<pre><code>mb.to_file(\"path/to/my_results.json.gz\")\n</code></pre>"},{"location":"How%20To%20Use/advanced/#task-data","title":"Task data","text":"<p>Tasks (<code>MatbenchTask</code>) are accessible as <code>MatbenchBenchmark</code> attributes through their names.</p> <p>Let's say we are interested in <code>matbench_dielectric</code>.  <pre><code># Access task thru attribute\ntask = mb.matbench_dielectric\n\n\n# This task is a MatbenchTask object\n&gt;&gt;&gt; print(task)\n\n&lt;MatbenchTask&gt;\n</code></pre></p>"},{"location":"How%20To%20Use/advanced/#see-task-metadata","title":"See task metadata","text":"<p>See metadata for an individual task.</p> <pre><code>metadata = mb.matbench_dielectric.metadata\n\n&gt;&gt;&gt; metadata\n{\n'input_type': 'structure',\n 'mad': 0.808534704217072,\n 'n_samples': 4764,\n 'target': 'n',\n 'task_type': 'regression',\n 'unit': 'unitless',\n 'bibtex_refs': [\"@Article{Dunn2020,\\nauthor={Dunn, Alexander\\nand Wang, Qi\\nand Ganose, Alex\\nand Dopp, Daniel\\nand Jain, Anubhav},\\ntitle={Benchmarking materials property prediction methods: the Matbench test set and Automatminer reference algorithm},\\njournal={npj Computational Materials},\\nyear={2020},\\nmonth={Sep},\\nday={15},\\nvolume={6},\\nnumber={1},\\npages={138},\\nabstract={We present a benchmark test suite and an automated machine learning procedure for evaluating supervised machine learning (ML) models for predicting properties of inorganic bulk materials. The test suite, Matbench, is a set of 13{\\\\thinspace}ML tasks that range in size from 312 to 132k samples and contain data from 10 density functional theory-derived and experimental sources. Tasks include predicting optical, thermal, electronic, thermodynamic, tensile, and elastic properties given a material's composition and/or crystal structure. The reference algorithm, Automatminer, is a highly-extensible, fully automated ML pipeline for predicting materials properties from materials primitives (such as composition and crystal structure) without user intervention or hyperparameter tuning. We test Automatminer on the Matbench test suite and compare its predictive power with state-of-the-art crystal graph neural networks and a traditional descriptor-based Random Forest model. We find Automatminer achieves the best performance on 8 of 13 tasks in the benchmark. We also show our test suite is capable of exposing predictive advantages of each algorithm---namely, that crystal graph methods appear to outperform traditional machine learning methods given {\\\\textasciitilde}104 or greater data points. We encourage evaluating materials ML algorithms on the Matbench benchmark and comparing them against the latest version of Automatminer.},\\nissn={2057-3960},\\ndoi={10.1038/s41524-020-00406-3},\\nurl={https://doi.org/10.1038/s41524-020-00406-3}\\n}\\n\",\n  '@article{Jain2013,\\nauthor = {Jain, Anubhav and Ong, Shyue Ping and Hautier, Geoffroy and Chen, Wei and Richards, William Davidson and Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and Skinner, David and Ceder, Gerbrand and Persson, Kristin a.},\\ndoi = {10.1063/1.4812323},\\nissn = {2166532X},\\njournal = {APL Materials},\\nnumber = {1},\\npages = {011002},\\ntitle = {{The Materials Project: A materials genome approach to accelerating materials innovation}},\\nurl = {http://link.aip.org/link/AMPADS/v1/i1/p011002/s1\\\\&amp;Agg=doi},\\nvolume = {1},\\nyear = {2013}\\n}',\n  '@article{Petousis2017,\\nauthor={Petousis, Ioannis and Mrdjenovich, David and Ballouz, Eric\\nand Liu, Miao and Winston, Donald and Chen, Wei and Graf, Tanja\\nand Schladt, Thomas D. and Persson, Kristin A. and Prinz, Fritz B.},\\ntitle={High-throughput screening of inorganic compounds for the\\ndiscovery of novel dielectric and optical materials},\\njournal={Scientific Data},\\nyear={2017},\\nmonth={Jan},\\nday={31},\\npublisher={The Author(s)},\\nvolume={4},\\npages={160134},\\nnote={Data Descriptor},\\nurl={http://dx.doi.org/10.1038/sdata.2016.134}\\n}'],\n 'columns': {'n': 'Target variable. Refractive index (unitless).',\n  'structure': 'Pymatgen Structure of the material.'},\n 'description': 'Matbench v0.1 test dataset for predicting refractive index from structure. Adapted from Materials Project database. Removed entries having a formation energy (or energy above the convex hull) more than 150meV and those having refractive indices less than 1 and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details.',\n 'file_type': 'json.gz',\n 'num_entries': 4764,\n 'url': 'https://ml.materialsproject.org/projects/matbench_dielectric.json.gz',\n 'hash': '83befa09bc2ec2f4b6143afc413157827a90e5e2e42c1eb507ccfa01bf26a1d6',\n 'reference': 'Petousis, I., Mrdjenovich, D., Ballouz, E., Liu, M., Winston, D.,\\nChen, W., Graf, T., Schladt, T. D., Persson, K. A. &amp; Prinz, F. B.\\nHigh-throughput screening of inorganic compounds for the discovery\\nof novel dielectric and optical materials. Sci. Data 4, 160134 (2017).',\n}\n\n\n\n# Metadata is also accessible as attributes\n&gt;&gt;&gt; metadata.unit\n\n\"unitless\"\n</code></pre>"},{"location":"How%20To%20Use/advanced/#see-which-folds-of-this-task-are-recorded","title":"See which folds of this task are recorded","text":"<pre><code>recorded_folds = mb.matbench_dielectric.is_recorded\n\n# In this example, we only have folds 0 and 1 recorded.\n&gt;&gt;&gt; recorded_folds\n\n{0: True, 1: True, 2: False, 3: False, 4: False}\n</code></pre>"},{"location":"How%20To%20Use/advanced/#see-task-score-stats-among-folds","title":"See task score stats among folds","text":"<p>All folds must be recorded to see score stats.</p> <pre><code>scores = mb.matbench_dielectric.scores\n\n\n# Show score stats taken over all folds\n&gt;&gt;&gt; scores\n\n{'mae': {'mean': 0.31502894856879793,\n  'max': 0.42569840085084304,\n  'min': 0.21883030230732342,\n  'std': 0.0672172232063864},\n 'rmse': {'mean': 1.7202043807691947,\n  'max': 2.9472145483123082,\n  'min': 0.6855155532720747,\n  'std': 0.8140297551209411},\n 'mape': {'mean': 0.08510552426501797,\n  'max': 0.09872854141937873,\n  'min': 0.07201546203802894,\n  'std': 0.009760258167856002},\n 'max_error': {'mean': 34.996903717427166,\n  'max': 59.01119325894446,\n  'min': 14.665353016975205,\n  'std': 17.978224948280573}\n }\n\n\n# scores are also accessible as attrs\n\n&gt;&gt;&gt; scores.mae.max\n\n0.42569840085084304\n</code></pre>"},{"location":"How%20To%20Use/advanced/#see-outputs-parameters-and-scores-for-individual-task-folds","title":"See outputs, parameters, and scores for individual task folds","text":"<pre><code># Get all of our recorded results\nresults = mb.matbench_dielectric.results\n\n&gt;&gt;&gt; results\n{\n    'fold_0': \n         {'data': \n              {\n                'mb-dielectric-0008': 2.1816278769942685,\n                'mb-dielectric-0010': 2.1449892069940995,\n                'mb-dielectric-0019': 3.9022885489716175,\n                'mb-dielectric-0025': 4.105947591302149,\n                ...\n               },\n          'parameters': {\n                'best_pipeline': '[\"(selectfwe, SelectFwe(alpha=0.006, score_func=&lt;function f_regression at 0x2aaaef1a0840&gt;))...\"'\n                ...\n               },\n          'scores': {\n                'mae': 0.21883030230732342,\n                'mape': 0.07602888421332273,\n                'max_error': 14.665353016975205,\n                'rmse': 0.6855155532720747\n            }\n          },\n    'fold_1': {...},\n    ...\n}\n\n\n# Individual fold data are available thru attrs\n&gt;&gt;&gt; results.fold_4.data['mb-dielectric-4751']\n2.5696947646331614\n\n# Including ML parameters for a specific fold, if made available\n&gt;&gt;&gt; results.fold_4.parameters\n{'best_pipeline': ['(selectfwe, SelectFwe(alpha=0.034, score_func=&lt;function f_regression at 0x2aaaf35a08c8&gt;))',\n    '(zerocount, ZeroCount())',\n    '(gradientboostingregressor, GradientBoostingRegressor(alpha=0.85, criterion=friedman_mse, init=null,\\n                          learning_rate=0.1, loss=huber, max_depth=9,\\n                          max_features=0.7500000000000001, max_leaf_nodes=null,\\n                          min_impurity_decrease=0.0, min_impurity_split=null,\\n                          min_samples_leaf=13, min_samples_split=17,\\n                          min_weight_fraction_leaf=0.0, n_estimators=100,\\n                          n_iter_no_change=null, presort=auto,\\n                          random_state=null, subsample=0.7500000000000001,\\n                          tol=0.0001, validation_fraction=0.1, verbose=0,\\n                          warm_start=false))'],\n   'features_reduced': ['MagpieData maximum Number',\n    'MagpieData maximum MendeleevNumber',\n    'MagpieData mean MendeleevNumber',\n    'MagpieData avg_dev MendeleevNumber',\n    'MagpieData range AtomicWeight',\n    ...\n }\n\n# Get score metrics on fold 4\n&gt;&gt;&gt; results.fold_4.scores\n{'mae': 0.3264316502622554,\n 'mape': 0.09872854141937873,\n 'max_error': 28.160118784575193,\n 'rmse': 1.6137009708660595\n }\n</code></pre>"},{"location":"How%20To%20Use/advanced/#validate-an-individual-tasks-results","title":"Validate an individual task's results","text":"<pre><code>&gt;&gt;&gt; mb.matbench_dielectric.validate()\n\n# If does not throw an error, it's valid!\n</code></pre>"},{"location":"How%20To%20Use/advanced/#benchmark-data","title":"Benchmark data","text":"<p>A <code>MatbenchBenchmark</code> is a collection of tasks. Once your benchmark is recorded, you can inspect it.</p>"},{"location":"How%20To%20Use/advanced/#get-information-about-the-state-of-a-benchmark","title":"Get information about the state of a benchmark","text":"<pre><code>&gt;&gt;&gt; mb.get_info()\n\n\"\"\"\nMatbench package 0.1.0 running benchmark 'matbench_v0.1'\n    is complete: True\n    is recorded: True\n    is valid: True\n\nResults:\n\n    - 'matbench_dielectric' MAE mean: 29.09435441521901\n    - 'matbench_expt_gap' MAE mean: 5.097990146029299\n    - 'matbench_expt_is_metal' ROCAUC mean: 0.490515739562644\n    - 'matbench_glass' ROCAUC mean: 0.4915206231191361\n    - 'matbench_mp_e_form' MAE mean: 1.9798749618345852\n    - 'matbench_jdft2d' MAE mean: 624.8594821594436\n    - 'matbench_log_gvrh' MAE mean: 0.7503117195807093\n    - 'matbench_log_kvrh' MAE mean: 0.8337265925158915\n    - 'matbench_mp_gap' MAE mean: 3.9947345263133185\n    - 'matbench_mp_is_metal' ROCAUC mean: 0.4995330363104962\n    - 'matbench_perovskites' MAE mean: 1.6494389339807394\n    - 'matbench_phonons' MAE mean: 1442.1910745917485\n    - 'matbench_steels' MAE mean: 514.6879431114869\n\"\"\"\n</code></pre>"},{"location":"How%20To%20Use/advanced/#access-a-summary-of-score-data-across-all-tasks","title":"Access a summary of score data, across all tasks","text":"<p>Access score data for multiple metrics, including fold statistics, programmatically <pre><code>&gt;&gt;&gt; mb.scores\n\n{'matbench_dielectric': {'mae': {'mean': 29.09435441521901, 'max': 29.790913986352297, 'min': 26.50764023789047, 'std': 1.2938287761791334}, 'rmse': {'mean': 33.654269974352744, 'max': 34.44945162692406, 'min': 30.707221665034698, 'std': 1.4740060199828717}, 'mape': {'mean': 14.169387576348942, 'max': 14.56764274096521, 'min': 12.928095832225917, 'std': 0.6228030143476618}, 'max_error': {'mean': 58.85621300050616, 'max': 60.1966146990726, 'min': 53.98208657241693, 'std': 2.4395502402545453}}, 'matbench_expt_gap': {'mae': {'mean': 5.097990146029299, 'max': 5.290261095781455, 'min': 4.6298670001648965, 'std': 0.2397514292575463}, 'rmse': {'mean': 6.006638705150991, 'max': 6.226508032402611, 'min': 5.47028276176484, 'std': 0.27274122238814}, 'mape': {'mean': 1.38641021305497e+16, 'max': 1.5276180519639252e+16, 'min': 1.2259552001352658e+16, 'std': 986247659935790.8}, 'max_error': {'mean': 11.407347551284193, 'max': 11.688512264782567, 'min': 10.489690494035637, 'std': 0.45961704429199657}}, 'matbench_expt_is_metal': {'accuracy': {'mean': 0.4903474887540754, 'max': 0.5050813008130082, 'min': 0.47459349593495936, 'std': 0.013195738662206162}, 'balanced_accuracy': {'mean': 0.490515739562644, 'max': 0.5052590266875981, 'min': 0.4747707180038007, 'std': 0.013195964150335589}, 'f1': {'mean': 0.5107296153663292, 'max': 0.5248780487804879, 'min': 0.49560975609756097, 'std': 0.012667909247509207}, 'rocauc': {'mean': 0.490515739562644, 'max': 0.5052590266875981, 'min': 0.4747707180038007, 'std': 0.013195964150335589}}, 'matbench_glass': {'accuracy': {'mean': 0.5059859154929578, 'max': 0.528169014084507, 'min': 0.477112676056338, 'std': 0.018718357549298598}, 'balanced_accuracy': {'mean': 0.4915206231191361, 'max': 0.518476250739163, 'min': 0.4564355205025932, 'std': 0.022745473256365906}, 'f1': {'mean': 0.6019858156028368, 'max': 0.6198581560283688, 'min': 0.5787234042553191, 'std': 0.015080889486527119}, 'rocauc': {'mean': 0.4915206231191361, 'max': 0.518476250739163, 'min': 0.4564355205025932, 'std': 0.022745473256365906}}, 'matbench_mp_e_form': {'mae': {'mean': 1.9798749618345852, 'max': 1.9820103943808465, 'min': 1.9764313221160588, 'std': 0.0018588951040352502}, 'rmse': {'mean': 2.376419875235826, 'max': 2.3794812432136196, 'min': 2.3722602233100063, 'std': 0.0023430849418330816}, 'mape': {'mean': 6989111302031.963, 'max': 7492035787402.213, 'min': 6236081301418.79, 'std': 476980899991.28485}, 'max_error': {'mean': 6.9650087167699155, 'max': 7.057955130739103, 'min': 6.878168095265195, 'std': 0.06657839974500762}}, 'matbench_jdft2d': {'mae': {'mean': 624.8594821594436, 'max': 662.8351790033564, 'min': 484.0870035426516, 'std': 70.41763851884579}, 'rmse': {'mean': 754.6594168930902, 'max': 802.851398577492, 'min': 575.4212296101125, 'std': 89.65203353138263}, 'mape': {'mean': 12.691214729498025, 'max': 22.18652735053058, 'min': 9.642403294653164, 'std': 4.833743597331997}, 'max_error': {'mean': 1455.537803743586, 'max': 1532.911339763068, 'min': 1229.7021907932801, 'std': 113.62938957056699}}, 'matbench_log_gvrh': {'mae': {'mean': 0.7503117195807093, 'max': 0.7567499426463542, 'min': 0.7458321525860483, 'std': 0.004177000349054263}, 'rmse': {'mean': 0.8922201073043177, 'max': 0.8965161788869266, 'min': 0.8860255812982848, 'std': 0.0034322474625259137}, 'mape': {'mean': 15059325260426.266, 'max': 26158506009539.293, 'min': 4541885118479.488, 'std': 6978350942510.934}, 'max_error': {'mean': 2.4294014472589063, 'max': 2.7078341735946374, 'min': 2.2460171713812693, 'std': 0.17276767393879686}}, 'matbench_log_kvrh': {'mae': {'mean': 0.8337265925158915, 'max': 0.84093059152486, 'min': 0.8252194857104939, 'std': 0.005960109281798535}, 'rmse': {'mean': 1.0122909056359641, 'max': 1.0190702248693488, 'min': 1.0038726599443502, 'std': 0.005051164726815858}, 'mape': {'mean': 5205086458416.939, 'max': 10062434398435.773, 'min': 1547244178802.9026, 'std': 3081512230166.448}, 'max_error': {'mean': 2.5243586576102204, 'max': 2.7538971602513187, 'min': 2.4510034654636557, 'std': 0.11592723389441413}}, 'matbench_mp_gap': {'mae': {'mean': 3.9947345263133185, 'max': 4.040261917311839, 'min': 3.8419572019120563, 'std': 0.07657166015944829}, 'rmse': {'mean': 4.802562096614456, 'max': 4.852934760261583, 'min': 4.621350867969822, 'std': 0.09070340779972745}, 'mape': {'mean': 9376100521414580.0, 'max': 9530024251770120.0, 'min': 9017068673849420.0, 'std': 191246529837308.34}, 'max_error': {'mean': 9.641818242181197, 'max': 9.721159283071396, 'min': 9.326360936678295, 'std': 0.15772886643823172}}, 'matbench_mp_is_metal': {'accuracy': {'mean': 0.49927909555806177, 'max': 0.5032513429459994, 'min': 0.49498185930358574, 'std': 0.002961735738880825}, 'balanced_accuracy': {'mean': 0.4995330363104962, 'max': 0.5035756141508568, 'min': 0.4951605437227332, 'std': 0.003013293507682773}, 'f1': {'mean': 0.465575654865608, 'max': 0.46982498491249247, 'min': 0.46097364715349026, 'std': 0.0031704147980028555}, 'rocauc': {'mean': 0.4995330363104962, 'max': 0.5035756141508567, 'min': 0.4951605437227331, 'std': 0.0030132935076827893}}, 'matbench_perovskites': {'mae': {'mean': 1.6494389339807394, 'max': 1.6643604327414814, 'min': 1.6083671212370563, 'std': 0.02130042981456539}, 'rmse': {'mean': 1.9895605050492304, 'max': 2.0097384860674103, 'min': 1.9348806762983708, 'std': 0.028069501175258544}, 'mape': {'mean': 8474366075980.172, 'max': 17109693350693.695, 'min': 170695202621.18396, 'std': 5913986606286.262}, 'max_error': {'mean': 5.122830203832267, 'max': 5.401364835279832, 'min': 4.933113748862263, 'std': 0.15432057817183506}}, 'matbench_phonons': {'mae': {'mean': 1442.1910745917485, 'max': 1460.5342302638428, 'min': 1404.6727173726108, 'std': 19.87835062913105}, 'rmse': {'mean': 1739.1638204522908, 'max': 1748.4453111626615, 'min': 1714.4001958506544, 'std': 12.506318415067186}, 'mape': {'mean': 4.535426963268569, 'max': 4.692503460859966, 'min': 4.356729242935622, 'std': 0.11577855407899913}, 'max_error': {'mean': 3387.1756802926197, 'max': 3490.7322416780676, 'min': 3312.8239446861567, 'std': 60.586867518772216}}, 'matbench_steels': {'mae': {'mean': 514.6879431114869, 'max': 548.5353510044772, 'min': 488.97286237333986, 'std': 24.98451122832146}, 'rmse': {'mean': 619.9832706475461, 'max': 651.1520235084482, 'min': 591.9607445092288, 'std': 24.183510586935057}, 'mape': {'mean': 0.39220921441643364, 'max': 0.4201053232886023, 'min': 0.368378839458224, 'std': 0.02076964611162295}, 'max_error': {'mean': 1331.6729147023618, 'max': 1389.1259692340998, 'min': 1272.982373277621, 'std': 40.71026078669035}}}\n</code></pre></p>"},{"location":"How%20To%20Use/advanced/#validate-an-entire-benchmark","title":"Validate an entire benchmark","text":"<p>You can validate an entire benchmark with the <code>validate</code> method of <code>MatbenchBenchmark</code>. </p> <pre><code>&gt;&gt;&gt; mb.is_valid\n\nTrue\n</code></pre> <p>If your results are valid, it ensures the automated leaderboard can understand your data and that all folds for all tasks are recorded.</p>"},{"location":"How%20To%20Use/advanced/#see-if-a-benchmark-is-complete","title":"See if a benchmark is complete","text":"<p>A benchmark is complete if it contains all the tasks specified in the benchmark specification. In the case of the benchmark Matbench v0.1, this means all 13 tasks are present in your benchmark (though they may not be recorded yet!).</p> <pre><code>&gt;&gt;&gt; mb.is_complete\n\nTrue\n</code></pre>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_dielectric/","title":"matbench_v0.1 matbench_dielectric","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_dielectric/#individual-task-leaderboard-for-matbench_dielectric","title":"Individual Task Leaderboard for <code>matbench_dielectric</code>","text":"<p>Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_dielectric/#leaderboard","title":"Leaderboard","text":"algorithm mean mae std mae mean rmse max max_error MODNet (v0.1.12) 0.2711 0.0714 1.6832 59.1179 MODNet (v0.1.10) 0.2970 0.0720 1.7185 58.9519 coGN 0.3088 0.0859 2.0546 58.7728 coNGN 0.3142 0.0740 2.0335 58.8654 AMMExpress v2020 0.3150 0.0672 1.7202 59.0112 Finder_v1.2 structure-based version 0.3197 0.0717 1.7213 59.0606 Finder_v1.2 composition-only version 0.3204 0.0811 1.7189 59.0528 CrabNet 0.3234 0.0714 1.7288 59.1583 SchNet (kgcnn v2.1.0) 0.3277 0.0829 1.8990 58.6071 DeeperGATGNN 0.3355 0.0839 1.7867 58.7139 MegNet (kgcnn v2.1.0) 0.3391 0.0745 1.9871 59.3095 DimeNet++ (kgcnn v2.1.0) 0.3400 0.0570 1.9936 58.5416 ALIGNN 0.3449 0.0871 1.9651 58.7285 RF-SCM/Magpie 0.4196 0.0750 1.8538 59.1201 CGCNN v2019 0.5988 0.0833 1.8976 58.9996 Dummy 0.8088 0.0718 1.9728 59.6653"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_dielectric/#dataset-info","title":"Dataset info","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_dielectric/#description","title":"Description","text":"<p>Matbench v0.1 test dataset for predicting refractive index from structure. Adapted from Materials Project database. Removed entries having a formation energy (or energy above the convex hull) more than 150meV and those having refractive indices less than 1 and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details.</p> <p>Number of samples: 4764</p> <p>Task type: regression</p> <p>Input type: structure</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_dielectric/#dataset-columns","title":"Dataset columns","text":"<ul> <li>n: Target variable. Refractive index (unitless).</li> <li>structure: Pymatgen Structure of the material.</li> </ul>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_dielectric/#dataset-reference","title":"Dataset reference","text":"<p><code>Petousis, I., Mrdjenovich, D., Ballouz, E., Liu, M., Winston, D., Chen, W., Graf, T., Schladt, T. D., Persson, K. A. &amp; Prinz, F. B. High-throughput screening of inorganic compounds for the discovery of novel dielectric and optical materials. Sci. Data 4, 160134 (2017).</code></p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_dielectric/#metadata","title":"Metadata","text":"<pre><code>{'bibtex_refs': ['@Article{Dunn2020,\\n'\n                 'author={Dunn, Alexander\\n'\n                 'and Wang, Qi\\n'\n                 'and Ganose, Alex\\n'\n                 'and Dopp, Daniel\\n'\n                 'and Jain, Anubhav},\\n'\n                 'title={Benchmarking materials property prediction methods: '\n                 'the Matbench test set and Automatminer reference '\n                 'algorithm},\\n'\n                 'journal={npj Computational Materials},\\n'\n                 'year={2020},\\n'\n                 'month={Sep},\\n'\n                 'day={15},\\n'\n                 'volume={6},\\n'\n                 'number={1},\\n'\n                 'pages={138},\\n'\n                 'abstract={We present a benchmark test suite and an automated '\n                 'machine learning procedure for evaluating supervised machine '\n                 'learning (ML) models for predicting properties of inorganic '\n                 'bulk materials. The test suite, Matbench, is a set of '\n                 '13{\\\\thinspace}ML tasks that range in size from 312 to 132k '\n                 'samples and contain data from 10 density functional '\n                 'theory-derived and experimental sources. Tasks include '\n                 'predicting optical, thermal, electronic, thermodynamic, '\n                 \"tensile, and elastic properties given a material's \"\n                 'composition and/or crystal structure. The reference '\n                 'algorithm, Automatminer, is a highly-extensible, fully '\n                 'automated ML pipeline for predicting materials properties '\n                 'from materials primitives (such as composition and crystal '\n                 'structure) without user intervention or hyperparameter '\n                 'tuning. We test Automatminer on the Matbench test suite and '\n                 'compare its predictive power with state-of-the-art crystal '\n                 'graph neural networks and a traditional descriptor-based '\n                 'Random Forest model. We find Automatminer achieves the best '\n                 'performance on 8 of 13 tasks in the benchmark. We also show '\n                 'our test suite is capable of exposing predictive advantages '\n                 'of each algorithm---namely, that crystal graph methods '\n                 'appear to outperform traditional machine learning methods '\n                 'given {\\\\textasciitilde}104 or greater data points. We '\n                 'encourage evaluating materials ML algorithms on the Matbench '\n                 'benchmark and comparing them against the latest version of '\n                 'Automatminer.},\\n'\n                 'issn={2057-3960},\\n'\n                 'doi={10.1038/s41524-020-00406-3},\\n'\n                 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n'\n                 '}\\n',\n                 '@article{Jain2013,\\n'\n                 'author = {Jain, Anubhav and Ong, Shyue Ping and Hautier, '\n                 'Geoffroy and Chen, Wei and Richards, William Davidson and '\n                 'Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and '\n                 'Skinner, David and Ceder, Gerbrand and Persson, Kristin '\n                 'a.},\\n'\n                 'doi = {10.1063/1.4812323},\\n'\n                 'issn = {2166532X},\\n'\n                 'journal = {APL Materials},\\n'\n                 'number = {1},\\n'\n                 'pages = {011002},\\n'\n                 'title = {{The Materials Project: A materials genome approach '\n                 'to accelerating materials innovation}},\\n'\n                 'url = '\n                 '{http://link.aip.org/link/AMPADS/v1/i1/p011002/s1\\\\&amp;Agg=doi},\\n'\n                 'volume = {1},\\n'\n                 'year = {2013}\\n'\n                 '}',\n                 '@article{Petousis2017,\\n'\n                 'author={Petousis, Ioannis and Mrdjenovich, David and '\n                 'Ballouz, Eric\\n'\n                 'and Liu, Miao and Winston, Donald and Chen, Wei and Graf, '\n                 'Tanja\\n'\n                 'and Schladt, Thomas D. and Persson, Kristin A. and Prinz, '\n                 'Fritz B.},\\n'\n                 'title={High-throughput screening of inorganic compounds for '\n                 'the\\n'\n                 'discovery of novel dielectric and optical materials},\\n'\n                 'journal={Scientific Data},\\n'\n                 'year={2017},\\n'\n                 'month={Jan},\\n'\n                 'day={31},\\n'\n                 'publisher={The Author(s)},\\n'\n                 'volume={4},\\n'\n                 'pages={160134},\\n'\n                 'note={Data Descriptor},\\n'\n                 'url={http://dx.doi.org/10.1038/sdata.2016.134}\\n'\n                 '}'],\n 'columns': {'n': 'Target variable. Refractive index (unitless).',\n             'structure': 'Pymatgen Structure of the material.'},\n 'description': 'Matbench v0.1 test dataset for predicting refractive index '\n                'from structure. Adapted from Materials Project database. '\n                'Removed entries having a formation energy (or energy above '\n                'the convex hull) more than 150meV and those having refractive '\n                'indices less than 1 and those containing noble gases. '\n                'Retrieved April 2, 2019. For benchmarking w/ nested cross '\n                'validation, the order of the dataset must be identical to the '\n                'retrieved data; refer to the Automatminer/Matbench '\n                'publication for more details.',\n 'file_type': 'json.gz',\n 'hash': '83befa09bc2ec2f4b6143afc413157827a90e5e2e42c1eb507ccfa01bf26a1d6',\n 'input_type': 'structure',\n 'mad': 0.808534704217072,\n 'n_samples': 4764,\n 'num_entries': 4764,\n 'reference': 'Petousis, I., Mrdjenovich, D., Ballouz, E., Liu, M., Winston, '\n              'D.,\\n'\n              'Chen, W., Graf, T., Schladt, T. D., Persson, K. A. &amp; Prinz, F. '\n              'B.\\n'\n              'High-throughput screening of inorganic compounds for the '\n              'discovery\\n'\n              'of novel dielectric and optical materials. Sci. Data 4, 160134 '\n              '(2017).',\n 'target': 'n',\n 'task_type': 'regression',\n 'unit': 'unitless',\n 'url': 'https://ml.materialsproject.org/projects/matbench_dielectric.json.gz'}\n</code></pre>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_gap/","title":"matbench_v0.1 matbench_expt_gap","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_gap/#individual-task-leaderboard-for-matbench_expt_gap","title":"Individual Task Leaderboard for <code>matbench_expt_gap</code>","text":"<p>Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_gap/#leaderboard","title":"Leaderboard","text":"algorithm mean mae std mae mean rmse max max_error Darwin 0.2865 0.0083 0.7185 7.6000 Ax/SAASBO CrabNet v1.2.7 0.3310 0.0071 0.8123 11.1001 MODNet (v0.1.12) 0.3327 0.0239 0.7685 9.8955 CrabNet 0.3463 0.0088 0.8504 9.8002 MODNet (v0.1.10) 0.3470 0.0222 0.7437 9.8567 Ax+CrabNet v1.2.1 0.3566 0.0248 0.8673 11.0998 Ax(10/90)+CrabNet v1.2.7 0.3632 0.0196 0.8679 11.1003 CrabNet v1.2.1 0.3757 0.0207 0.8805 10.2572 AMMExpress v2020 0.4161 0.0194 0.9918 12.7533 RF-SCM/Magpie 0.4461 0.0177 0.8243 9.5428 gptchem 0.4544 0.0123 1.0737 11.7000 Dummy 1.1435 0.0310 1.4438 10.7354"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_gap/#dataset-info","title":"Dataset info","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_gap/#description","title":"Description","text":"<p>Matbench v0.1 test dataset for predicting experimental band gap from composition alone. Retrieved from Zhuo et al. supplementary information. Deduplicated according to composition, removing compositions with reported band gaps spanning more than a 0.1eV range; remaining compositions were assigned values based on the closest experimental value to the mean experimental value for that composition among all reports. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details.</p> <p>Number of samples: 4604</p> <p>Task type: regression</p> <p>Input type: composition</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_gap/#dataset-columns","title":"Dataset columns","text":"<ul> <li>composition: Chemical formula.</li> <li>gap expt: Target variable. Experimentally measured gap, in eV.</li> </ul>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_gap/#dataset-reference","title":"Dataset reference","text":"<p><code>Y. Zhuo, A. Masouri Tehrani, J. Brgoch (2018) Predicting the Band Gaps of Inorganic Solids by Machine Learning J. Phys. Chem. Lett. 2018, 9, 7, 1668-1673 https:doi.org/10.1021/acs.jpclett.8b00124.</code></p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_gap/#metadata","title":"Metadata","text":"<pre><code>{'bibtex_refs': ['@Article{Dunn2020,\\n'\n                 'author={Dunn, Alexander\\n'\n                 'and Wang, Qi\\n'\n                 'and Ganose, Alex\\n'\n                 'and Dopp, Daniel\\n'\n                 'and Jain, Anubhav},\\n'\n                 'title={Benchmarking materials property prediction methods: '\n                 'the Matbench test set and Automatminer reference '\n                 'algorithm},\\n'\n                 'journal={npj Computational Materials},\\n'\n                 'year={2020},\\n'\n                 'month={Sep},\\n'\n                 'day={15},\\n'\n                 'volume={6},\\n'\n                 'number={1},\\n'\n                 'pages={138},\\n'\n                 'abstract={We present a benchmark test suite and an automated '\n                 'machine learning procedure for evaluating supervised machine '\n                 'learning (ML) models for predicting properties of inorganic '\n                 'bulk materials. The test suite, Matbench, is a set of '\n                 '13{\\\\thinspace}ML tasks that range in size from 312 to 132k '\n                 'samples and contain data from 10 density functional '\n                 'theory-derived and experimental sources. Tasks include '\n                 'predicting optical, thermal, electronic, thermodynamic, '\n                 \"tensile, and elastic properties given a material's \"\n                 'composition and/or crystal structure. The reference '\n                 'algorithm, Automatminer, is a highly-extensible, fully '\n                 'automated ML pipeline for predicting materials properties '\n                 'from materials primitives (such as composition and crystal '\n                 'structure) without user intervention or hyperparameter '\n                 'tuning. We test Automatminer on the Matbench test suite and '\n                 'compare its predictive power with state-of-the-art crystal '\n                 'graph neural networks and a traditional descriptor-based '\n                 'Random Forest model. We find Automatminer achieves the best '\n                 'performance on 8 of 13 tasks in the benchmark. We also show '\n                 'our test suite is capable of exposing predictive advantages '\n                 'of each algorithm---namely, that crystal graph methods '\n                 'appear to outperform traditional machine learning methods '\n                 'given {\\\\textasciitilde}104 or greater data points. We '\n                 'encourage evaluating materials ML algorithms on the Matbench '\n                 'benchmark and comparing them against the latest version of '\n                 'Automatminer.},\\n'\n                 'issn={2057-3960},\\n'\n                 'doi={10.1038/s41524-020-00406-3},\\n'\n                 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n'\n                 '}\\n',\n                 '@article{doi:10.1021/acs.jpclett.8b00124,\\n'\n                 'author = {Zhuo, Ya and Mansouri Tehrani, Aria and Brgoch, '\n                 'Jakoah},\\n'\n                 'title = {Predicting the Band Gaps of Inorganic Solids by '\n                 'Machine Learning},\\n'\n                 'journal = {The Journal of Physical Chemistry Letters},\\n'\n                 'volume = {9},\\n'\n                 'number = {7},\\n'\n                 'pages = {1668-1673},\\n'\n                 'year = {2018},\\n'\n                 'doi = {10.1021/acs.jpclett.8b00124},\\n'\n                 'note ={PMID: 29532658},\\n'\n                 'eprint = {\\n'\n                 'https://doi.org/10.1021/acs.jpclett.8b00124\\n'\n                 '\\n'\n                 '}}'],\n 'columns': {'composition': 'Chemical formula.',\n             'gap expt': 'Target variable. Experimentally measured gap, in '\n                         'eV.'},\n 'description': 'Matbench v0.1 test dataset for predicting experimental band '\n                'gap from composition alone. Retrieved from Zhuo et al. '\n                'supplementary information. Deduplicated according to '\n                'composition, removing compositions with reported band gaps '\n                'spanning more than a 0.1eV range; remaining compositions were '\n                'assigned values based on the closest experimental value to '\n                'the mean experimental value for that composition among all '\n                'reports. For benchmarking w/ nested cross validation, the '\n                'order of the dataset must be identical to the retrieved data; '\n                'refer to the Automatminer/Matbench publication for more '\n                'details.',\n 'file_type': 'json.gz',\n 'hash': '783e7d1461eb83b00b2f2942da4b95fda5e58a0d1ae26b581c24cf8a82ca75b2',\n 'input_type': 'composition',\n 'mad': 1.1432002429044061,\n 'n_samples': 4604,\n 'num_entries': 4604,\n 'reference': 'Y. Zhuo, A. Masouri Tehrani, J. Brgoch (2018) Predicting the '\n              'Band Gaps of Inorganic Solids by Machine Learning J. Phys. '\n              'Chem. Lett. 2018, 9, 7, 1668-1673 '\n              'https:doi.org/10.1021/acs.jpclett.8b00124.',\n 'target': 'gap expt',\n 'task_type': 'regression',\n 'unit': 'eV',\n 'url': 'https://ml.materialsproject.org/projects/matbench_expt_gap.json.gz'}\n</code></pre>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_is_metal/","title":"matbench_v0.1 matbench_expt_is_metal","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_is_metal/#individual-task-leaderboard-for-matbench_expt_is_metal","title":"Individual Task Leaderboard for <code>matbench_expt_is_metal</code>","text":"<p>Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_is_metal/#leaderboard","title":"Leaderboard","text":"algorithm mean rocauc std rocauc mean f1 mean balanced_accuracy Darwin 0.9598 0.0041 0.9599 0.9598 AMMExpress v2020 0.9209 0.0028 0.9200 0.9209 RF-SCM/Magpie 0.9167 0.0064 0.9159 0.9167 MODNet (v0.1.12) 0.9161 0.0072 0.9153 0.9161 MODNet (v0.1.10) 0.9161 0.0072 0.9153 0.9161 gptchem 0.8965 0.0060 0.8953 0.8965 Dummy 0.4924 0.0128 0.4913 0.4924"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_is_metal/#dataset-info","title":"Dataset info","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_is_metal/#description","title":"Description","text":"<p>Matbench v0.1 test dataset for classifying metallicity from composition alone. Retrieved from Zhuo et al. supplementary information. Deduplicated according to composition, ensuring no conflicting reports were entered for any compositions (i.e., no reported compositions were both metal and nonmetal). For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details.</p> <p>Number of samples: 4921</p> <p>Task type: classification</p> <p>Input type: composition</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_is_metal/#dataset-columns","title":"Dataset columns","text":"<ul> <li>composition: Chemical formula.</li> <li>is_metal: Target variable. 1 if is a metal, 0 if nonmetal.</li> </ul>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_is_metal/#dataset-reference","title":"Dataset reference","text":"<p><code>Y. Zhuo, A. Masouri Tehrani, J. Brgoch (2018) Predicting the Band Gaps of Inorganic Solids by Machine Learning J. Phys. Chem. Lett. 2018, 9, 7, 1668-1673   https//:doi.org/10.1021/acs.jpclett.8b00124.</code></p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_expt_is_metal/#metadata","title":"Metadata","text":"<pre><code>{'bibtex_refs': ['@Article{Dunn2020,\\n'\n                 'author={Dunn, Alexander\\n'\n                 'and Wang, Qi\\n'\n                 'and Ganose, Alex\\n'\n                 'and Dopp, Daniel\\n'\n                 'and Jain, Anubhav},\\n'\n                 'title={Benchmarking materials property prediction methods: '\n                 'the Matbench test set and Automatminer reference '\n                 'algorithm},\\n'\n                 'journal={npj Computational Materials},\\n'\n                 'year={2020},\\n'\n                 'month={Sep},\\n'\n                 'day={15},\\n'\n                 'volume={6},\\n'\n                 'number={1},\\n'\n                 'pages={138},\\n'\n                 'abstract={We present a benchmark test suite and an automated '\n                 'machine learning procedure for evaluating supervised machine '\n                 'learning (ML) models for predicting properties of inorganic '\n                 'bulk materials. The test suite, Matbench, is a set of '\n                 '13{\\\\thinspace}ML tasks that range in size from 312 to 132k '\n                 'samples and contain data from 10 density functional '\n                 'theory-derived and experimental sources. Tasks include '\n                 'predicting optical, thermal, electronic, thermodynamic, '\n                 \"tensile, and elastic properties given a material's \"\n                 'composition and/or crystal structure. The reference '\n                 'algorithm, Automatminer, is a highly-extensible, fully '\n                 'automated ML pipeline for predicting materials properties '\n                 'from materials primitives (such as composition and crystal '\n                 'structure) without user intervention or hyperparameter '\n                 'tuning. We test Automatminer on the Matbench test suite and '\n                 'compare its predictive power with state-of-the-art crystal '\n                 'graph neural networks and a traditional descriptor-based '\n                 'Random Forest model. We find Automatminer achieves the best '\n                 'performance on 8 of 13 tasks in the benchmark. We also show '\n                 'our test suite is capable of exposing predictive advantages '\n                 'of each algorithm---namely, that crystal graph methods '\n                 'appear to outperform traditional machine learning methods '\n                 'given {\\\\textasciitilde}104 or greater data points. We '\n                 'encourage evaluating materials ML algorithms on the Matbench '\n                 'benchmark and comparing them against the latest version of '\n                 'Automatminer.},\\n'\n                 'issn={2057-3960},\\n'\n                 'doi={10.1038/s41524-020-00406-3},\\n'\n                 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n'\n                 '}\\n',\n                 '@article{doi:10.1021/acs.jpclett.8b00124,\\n'\n                 'author = {Zhuo, Ya and Mansouri Tehrani, Aria and Brgoch, '\n                 'Jakoah},\\n'\n                 'title= {Predicting the Band Gaps of Inorganic Solids by '\n                 'Machine Learning},\\n'\n                 'journal = {The Journal of Physical Chemistry Letters},\\n'\n                 'volume = {9},\\n'\n                 'number = {7},\\n'\n                 'pages = {1668-1673},\\n'\n                 'year = {2018},\\n'\n                 'doi = {10.1021/acs.jpclett.8b00124},\\n'\n                 'note ={PMID: 29532658},\\n'\n                 'eprint = {\\n'\n                 'https://doi.org/10.1021/acs.jpclett.8b00124\\n'\n                 '\\n'\n                 '}}'],\n 'columns': {'composition': 'Chemical formula.',\n             'is_metal': 'Target variable. 1 if is a metal, 0 if nonmetal.'},\n 'description': 'Matbench v0.1 test dataset for classifying metallicity from '\n                'composition alone. Retrieved from Zhuo et al. supplementary '\n                'information. Deduplicated according to composition, ensuring '\n                'no conflicting reports were entered for any compositions '\n                '(i.e., no reported compositions were both metal and '\n                'nonmetal). For benchmarking w/ nested cross validation, the '\n                'order of the dataset must be identical to the retrieved data; '\n                'refer to the Automatminer/Matbench publication for more '\n                'details.',\n 'file_type': 'json.gz',\n 'frac_true': 0.4980694980694981,\n 'hash': '8f2a4f9bacdcbc5c2c73615629ee7986f09d39bed40ba7db52b61b2889730887',\n 'input_type': 'composition',\n 'n_samples': 4921,\n 'num_entries': 4921,\n 'reference': 'Y. Zhuo, A. Masouri Tehrani, J. Brgoch (2018) Predicting the '\n              'Band Gaps of Inorganic Solids by Machine Learning J. Phys. '\n              'Chem. Lett. 2018, 9, 7, 1668-1673 \\n'\n              ' https//:doi.org/10.1021/acs.jpclett.8b00124.',\n 'target': 'is_metal',\n 'task_type': 'classification',\n 'unit': None,\n 'url': 'https://ml.materialsproject.org/projects/matbench_expt_is_metal.json.gz'}\n</code></pre>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_glass/","title":"matbench_v0.1 matbench_glass","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_glass/#individual-task-leaderboard-for-matbench_glass","title":"Individual Task Leaderboard for <code>matbench_glass</code>","text":"<p>Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_glass/#leaderboard","title":"Leaderboard","text":"algorithm mean rocauc std rocauc mean f1 mean balanced_accuracy MODNet (v0.1.12) 0.9603 0.0075 0.9784 0.9603 AMMExpress v2020 0.8607 0.0199 0.9043 0.8607 RF-SCM/Magpie 0.8587 0.0158 0.9278 0.8587 MODNet (v0.1.10) 0.8107 0.0212 0.9104 0.8107 gptchem 0.7762 0.0122 0.8782 0.7762 Darwin 0.7668 0.0133 0.8722 0.7668 Dummy 0.5005 0.0178 0.7127 0.5005"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_glass/#dataset-info","title":"Dataset info","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_glass/#description","title":"Description","text":"<p>Matbench v0.1 test dataset for predicting full bulk metallic glass formation ability from chemical formula. Retrieved from \"Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys,\u2019 a volume of the Landolt\u2013 B\u00f6rnstein collection. Deduplicated according to composition, ensuring no compositions were reported as both GFA and not GFA (i.e., all reports agreed on the classification designation). For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details.</p> <p>Number of samples: 5680</p> <p>Task type: classification</p> <p>Input type: composition</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_glass/#dataset-columns","title":"Dataset columns","text":"<ul> <li>composition: Chemical formula.</li> <li>gfa: Target variable. Glass forming ability: 1 means glass forming and corresponds to amorphous, 0 means non full glass forming.</li> </ul>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_glass/#dataset-reference","title":"Dataset reference","text":"<p><code>Y. Kawazoe, T. Masumoto, A.-P. Tsai, J.-Z. Yu, T. Aihara Jr. (1997) Y. Kawazoe, J.-Z. Yu, A.-P. Tsai, T. Masumoto (ed.) SpringerMaterials Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys \u00b7 1 Introduction Landolt-B\u00f6rnstein - Group III Condensed Matter 37A (Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys) https://www.springer.com/gp/book/9783540605072 (Springer-Verlag Berlin Heidelberg \u00a9 1997) Accessed: 03-09-2019</code></p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_glass/#metadata","title":"Metadata","text":"<pre><code>{'bibtex_refs': ['@Article{Dunn2020,\\n'\n                 'author={Dunn, Alexander\\n'\n                 'and Wang, Qi\\n'\n                 'and Ganose, Alex\\n'\n                 'and Dopp, Daniel\\n'\n                 'and Jain, Anubhav},\\n'\n                 'title={Benchmarking materials property prediction methods: '\n                 'the Matbench test set and Automatminer reference '\n                 'algorithm},\\n'\n                 'journal={npj Computational Materials},\\n'\n                 'year={2020},\\n'\n                 'month={Sep},\\n'\n                 'day={15},\\n'\n                 'volume={6},\\n'\n                 'number={1},\\n'\n                 'pages={138},\\n'\n                 'abstract={We present a benchmark test suite and an automated '\n                 'machine learning procedure for evaluating supervised machine '\n                 'learning (ML) models for predicting properties of inorganic '\n                 'bulk materials. The test suite, Matbench, is a set of '\n                 '13{\\\\thinspace}ML tasks that range in size from 312 to 132k '\n                 'samples and contain data from 10 density functional '\n                 'theory-derived and experimental sources. Tasks include '\n                 'predicting optical, thermal, electronic, thermodynamic, '\n                 \"tensile, and elastic properties given a material's \"\n                 'composition and/or crystal structure. The reference '\n                 'algorithm, Automatminer, is a highly-extensible, fully '\n                 'automated ML pipeline for predicting materials properties '\n                 'from materials primitives (such as composition and crystal '\n                 'structure) without user intervention or hyperparameter '\n                 'tuning. We test Automatminer on the Matbench test suite and '\n                 'compare its predictive power with state-of-the-art crystal '\n                 'graph neural networks and a traditional descriptor-based '\n                 'Random Forest model. We find Automatminer achieves the best '\n                 'performance on 8 of 13 tasks in the benchmark. We also show '\n                 'our test suite is capable of exposing predictive advantages '\n                 'of each algorithm---namely, that crystal graph methods '\n                 'appear to outperform traditional machine learning methods '\n                 'given {\\\\textasciitilde}104 or greater data points. We '\n                 'encourage evaluating materials ML algorithms on the Matbench '\n                 'benchmark and comparing them against the latest version of '\n                 'Automatminer.},\\n'\n                 'issn={2057-3960},\\n'\n                 'doi={10.1038/s41524-020-00406-3},\\n'\n                 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n'\n                 '}\\n',\n                 '@Misc{LandoltBornstein1997:sm_lbs_978-3-540-47679-5_2,\\n'\n                 'author=\"Kawazoe, Y.\\n'\n                 'and Masumoto, T.\\n'\n                 'and Tsai, A.-P.\\n'\n                 'and Yu, J.-Z.\\n'\n                 'and Aihara Jr., T.\",\\n'\n                 'editor=\"Kawazoe, Y.\\n'\n                 'and Yu, J.-Z.\\n'\n                 'and Tsai, A.-P.\\n'\n                 'and Masumoto, T.\",\\n'\n                 'title=\"Nonequilibrium Phase Diagrams of Ternary Amorphous '\n                 'Alloys {\\\\textperiodcentered} 1 Introduction: Datasheet from '\n                 'Landolt-B{\\\\\"o}rnstein - Group III Condensed Matter '\n                 '{\\\\textperiodcentered} Volume 37A: ``Nonequilibrium Phase '\n                 \"Diagrams of Ternary Amorphous Alloys'' in SpringerMaterials \"\n                 '(https://dx.doi.org/10.1007/10510374{\\\\_}2)\",\\n'\n                 'publisher=\"Springer-Verlag Berlin Heidelberg\",\\n'\n                 'note=\"Copyright 1997 Springer-Verlag Berlin Heidelberg\",\\n'\n                 'note=\"Part of SpringerMaterials\",\\n'\n                 'note=\"accessed 2018-10-23\",\\n'\n                 'doi=\"10.1007/10510374_2\",\\n'\n                 'url=\"https://materials.springer.com/lb/docs/sm_lbs_978-3-540-47679-5_2\"\\n'\n                 '}',\n                 '@Article{Ward2016,\\n'\n                 'author={Ward, Logan\\n'\n                 'and Agrawal, Ankit\\n'\n                 'and Choudhary, Alok\\n'\n                 'and Wolverton, Christopher},\\n'\n                 'title={A general-purpose machine learning framework for '\n                 'predicting properties of inorganic materials},\\n'\n                 'journal={Npj Computational Materials},\\n'\n                 'year={2016},\\n'\n                 'month={Aug},\\n'\n                 'day={26},\\n'\n                 'publisher={The Author(s)},\\n'\n                 'volume={2},\\n'\n                 'pages={16028},\\n'\n                 'note={Article},\\n'\n                 'url={http://dx.doi.org/10.1038/npjcompumats.2016.28}\\n'\n                 '}'],\n 'columns': {'composition': 'Chemical formula.',\n             'gfa': 'Target variable. Glass forming ability: 1 means glass '\n                    'forming and corresponds to amorphous, 0 means non full '\n                    'glass forming.'},\n 'description': 'Matbench v0.1 test dataset for predicting full bulk metallic '\n                'glass formation ability from chemical formula. Retrieved from '\n                '\"Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys,\u2019 '\n                'a volume of the Landolt\u2013 B\u00f6rnstein collection. Deduplicated '\n                'according to composition, ensuring no compositions were '\n                'reported as both GFA and not GFA (i.e., all reports agreed on '\n                'the classification designation). For benchmarking w/ nested '\n                'cross validation, the order of the dataset must be identical '\n                'to the retrieved data; refer to the Automatminer/Matbench '\n                'publication for more details.',\n 'file_type': 'json.gz',\n 'frac_true': 0.710387323943662,\n 'hash': '36beb654e2a463ee2a6572105bea0ca2961eee7c7b26a25377bff2c3b338e53a',\n 'input_type': 'composition',\n 'n_samples': 5680,\n 'num_entries': 5680,\n 'reference': 'Y. Kawazoe, T. Masumoto, A.-P. Tsai, J.-Z. Yu, T. Aihara Jr. '\n              '(1997) Y. Kawazoe, J.-Z. Yu, A.-P. Tsai, T. Masumoto (ed.) '\n              'SpringerMaterials\\n'\n              'Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys \u00b7 1 '\n              'Introduction Landolt-B\u00f6rnstein - Group III Condensed Matter 37A '\n              '(Nonequilibrium Phase Diagrams of Ternary Amorphous Alloys) '\n              'https://www.springer.com/gp/book/9783540605072 (Springer-Verlag '\n              'Berlin Heidelberg \u00a9 1997) Accessed: 03-09-2019',\n 'target': 'gfa',\n 'task_type': 'classification',\n 'unit': None,\n 'url': 'https://ml.materialsproject.org/projects/matbench_glass.json.gz'}\n</code></pre>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_jdft2d/","title":"matbench_v0.1 matbench_jdft2d","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_jdft2d/#individual-task-leaderboard-for-matbench_jdft2d","title":"Individual Task Leaderboard for <code>matbench_jdft2d</code>","text":"<p>Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_jdft2d/#leaderboard","title":"Leaderboard","text":"algorithm mean mae std mae mean rmse max max_error MODNet (v0.1.12) 33.1918 7.3428 96.7332 1564.8245 MODNet (v0.1.10) 34.5368 9.4959 92.2288 1534.9797 coNGN 36.1698 11.5972 95.4766 1496.9020 coGN 37.1652 13.6825 101.1580 1515.5614 AMMExpress v2020 39.8497 9.8835 106.5460 1552.9102 SchNet (kgcnn v2.1.0) 42.6637 13.7201 111.0187 1524.9143 ALIGNN 43.4244 8.9491 117.4213 1519.7424 DeeperGATGNN 45.4611 11.6819 113.4192 1468.3439 CrabNet 45.6104 12.2491 120.0088 1532.0118 Finder_v1.2 structure-based version 46.1339 11.4644 120.0917 1581.4571 Finder_v1.2 composition-only version 47.9614 11.6680 120.8819 1582.3598 DimeNet++ (kgcnn v2.1.0) 49.0243 11.9027 114.9349 1515.0046 CGCNN v2019 49.2440 11.5865 112.7689 1516.9120 RF-SCM/Magpie 50.0440 8.6271 112.2660 1538.6073 MegNet (kgcnn v2.1.0) 54.1719 11.4299 129.3267 1561.5756 Dummy 67.2851 10.1832 126.8446 1491.7993"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_jdft2d/#dataset-info","title":"Dataset info","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_jdft2d/#description","title":"Description","text":"<p>Matbench v0.1 test dataset for predicting exfoliation energies from crystal structure (computed with the OptB88vdW and TBmBJ functionals). Adapted from the JARVIS DFT database. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details.</p> <p>Number of samples: 636</p> <p>Task type: regression</p> <p>Input type: structure</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_jdft2d/#dataset-columns","title":"Dataset columns","text":"<ul> <li>exfoliation_en: Target variable. Exfoliation energy (meV/atom).</li> <li>structure: Pymatgen Structure of the material.</li> </ul>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_jdft2d/#dataset-reference","title":"Dataset reference","text":"<p><code>2D Dataset discussed in: High-throughput Identification and Characterization of Two dimensional Materials using Density functional theory Kamal Choudhary, Irina Kalish, Ryan Beams &amp; Francesca Tavazza Scientific Reports volume 7, Article number: 5179 (2017) Original 2D Data file sourced from: choudhary, kamal; https://orcid.org/0000-0001-9737-8074 (2018): jdft_2d-7-7-2018.json. figshare. Dataset.</code></p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_jdft2d/#metadata","title":"Metadata","text":"<pre><code>{'bibtex_refs': ['@Article{Dunn2020,\\n'\n                 'author={Dunn, Alexander\\n'\n                 'and Wang, Qi\\n'\n                 'and Ganose, Alex\\n'\n                 'and Dopp, Daniel\\n'\n                 'and Jain, Anubhav},\\n'\n                 'title={Benchmarking materials property prediction methods: '\n                 'the Matbench test set and Automatminer reference '\n                 'algorithm},\\n'\n                 'journal={npj Computational Materials},\\n'\n                 'year={2020},\\n'\n                 'month={Sep},\\n'\n                 'day={15},\\n'\n                 'volume={6},\\n'\n                 'number={1},\\n'\n                 'pages={138},\\n'\n                 'abstract={We present a benchmark test suite and an automated '\n                 'machine learning procedure for evaluating supervised machine '\n                 'learning (ML) models for predicting properties of inorganic '\n                 'bulk materials. The test suite, Matbench, is a set of '\n                 '13{\\\\thinspace}ML tasks that range in size from 312 to 132k '\n                 'samples and contain data from 10 density functional '\n                 'theory-derived and experimental sources. Tasks include '\n                 'predicting optical, thermal, electronic, thermodynamic, '\n                 \"tensile, and elastic properties given a material's \"\n                 'composition and/or crystal structure. The reference '\n                 'algorithm, Automatminer, is a highly-extensible, fully '\n                 'automated ML pipeline for predicting materials properties '\n                 'from materials primitives (such as composition and crystal '\n                 'structure) without user intervention or hyperparameter '\n                 'tuning. We test Automatminer on the Matbench test suite and '\n                 'compare its predictive power with state-of-the-art crystal '\n                 'graph neural networks and a traditional descriptor-based '\n                 'Random Forest model. We find Automatminer achieves the best '\n                 'performance on 8 of 13 tasks in the benchmark. We also show '\n                 'our test suite is capable of exposing predictive advantages '\n                 'of each algorithm---namely, that crystal graph methods '\n                 'appear to outperform traditional machine learning methods '\n                 'given {\\\\textasciitilde}104 or greater data points. We '\n                 'encourage evaluating materials ML algorithms on the Matbench '\n                 'benchmark and comparing them against the latest version of '\n                 'Automatminer.},\\n'\n                 'issn={2057-3960},\\n'\n                 'doi={10.1038/s41524-020-00406-3},\\n'\n                 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n'\n                 '}\\n',\n                 '@Article{Choudhary2017,\\n'\n                 'author={Choudhary, Kamal\\n'\n                 'and Kalish, Irina\\n'\n                 'and Beams, Ryan\\n'\n                 'and Tavazza, Francesca},\\n'\n                 'title={High-throughput Identification and Characterization '\n                 'of Two-dimensional Materials using Density functional '\n                 'theory},\\n'\n                 'journal={Scientific Reports},\\n'\n                 'year={2017},\\n'\n                 'volume={7},\\n'\n                 'number={1},\\n'\n                 'pages={5179},\\n'\n                 'abstract={We introduce a simple criterion to identify '\n                 'two-dimensional (2D) materials based on the comparison '\n                 'between experimental lattice constants and lattice constants '\n                 'mainly obtained from Materials-Project (MP) density '\n                 'functional theory (DFT) calculation repository. '\n                 'Specifically, if the relative difference between the two '\n                 'lattice constants for a specific material is greater than or '\n                 'equal to 5%, we predict them to be good candidates for 2D '\n                 'materials. We have predicted at least 1356 such 2D '\n                 'materials. For all the systems satisfying our criterion, we '\n                 'manually create single layer systems and calculate their '\n                 'energetics, structural, electronic, and elastic properties '\n                 'for both the bulk and the single layer cases. Currently the '\n                 'database consists of 1012 bulk and 430 single layer '\n                 'materials, of which 371 systems are common to bulk and '\n                 'single layer. The rest of calculations are underway. To '\n                 'validate our criterion, we calculated the exfoliation energy '\n                 'of the suggested layered materials, and we found that in '\n                 '88.9% of the cases the currently accepted criterion for '\n                 'exfoliation was satisfied. Also, using molybdenum telluride '\n                 'as a test case, we performed X-ray diffraction and Raman '\n                 'scattering experiments to benchmark our calculations and '\n                 'understand their applicability and limitations. The data is '\n                 'publicly available at the website '\n                 'http://www.ctcms.nist.gov/{\\t'\n                 'extasciitilde}knc6/JVASP.html.},\\n'\n                 'issn={2045-2322},\\n'\n                 'doi={10.1038/s41598-017-05402-0},\\n'\n                 'url={https://doi.org/10.1038/s41598-017-05402-0}\\n'\n                 '}',\n                 '@misc{choudhary__2018, title={jdft_2d-7-7-2018.json}, '\n                 'url={https://figshare.com/articles/jdft_2d-7-7-2018_json/6815705/1}, '\n                 'DOI={10.6084/m9.figshare.6815705.v1}, abstractNote={2D '\n                 'materials}, publisher={figshare}, author={choudhary, kamal '\n                 'and https://orcid.org/0000-0001-9737-8074}, year={2018}, '\n                 'month={Jul}}'],\n 'columns': {'exfoliation_en': 'Target variable. Exfoliation energy '\n                               '(meV/atom).',\n             'structure': 'Pymatgen Structure of the material.'},\n 'description': 'Matbench v0.1 test dataset for predicting exfoliation '\n                'energies from crystal structure (computed with the OptB88vdW '\n                'and TBmBJ functionals). Adapted from the JARVIS DFT database. '\n                'For benchmarking w/ nested cross validation, the order of the '\n                'dataset must be identical to the retrieved data; refer to the '\n                'Automatminer/Matbench publication for more details.',\n 'file_type': 'json.gz',\n 'hash': '26057dc4524e193e32abffb296ce819b58b6e11d1278cae329a2f97817a4eddf',\n 'input_type': 'structure',\n 'mad': 67.20200406491116,\n 'n_samples': 636,\n 'num_entries': 636,\n 'reference': '2D Dataset discussed in:\\n'\n              'High-throughput Identification and Characterization of Two '\n              'dimensional Materials using Density functional theory Kamal '\n              'Choudhary, Irina Kalish, Ryan Beams &amp; Francesca Tavazza '\n              'Scientific Reports volume 7, Article number: 5179 (2017)\\n'\n              'Original 2D Data file sourced from:\\n'\n              'choudhary, kamal; https://orcid.org/0000-0001-9737-8074 (2018): '\n              'jdft_2d-7-7-2018.json. figshare. Dataset.',\n 'target': 'exfoliation_en',\n 'task_type': 'regression',\n 'unit': 'meV/atom',\n 'url': 'https://ml.materialsproject.org/projects/matbench_jdft2d.json.gz'}\n</code></pre>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_gvrh/","title":"matbench_v0.1 matbench_log_gvrh","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_gvrh/#individual-task-leaderboard-for-matbench_log_gvrh","title":"Individual Task Leaderboard for <code>matbench_log_gvrh</code>","text":"<p>Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_gvrh/#leaderboard","title":"Leaderboard","text":"algorithm mean mae std mae mean rmse max max_error coNGN 0.0670 0.0006 0.1078 1.1760 coGN 0.0689 0.0009 0.1102 1.0842 ALIGNN 0.0715 0.0006 0.1123 1.1324 MODNet (v0.1.12) 0.0731 0.0007 0.1103 1.1745 MODNet (v0.1.10) 0.0731 0.0007 0.1103 1.1745 DimeNet++ (kgcnn v2.1.0) 0.0792 0.0011 0.1255 1.5558 SchNet (kgcnn v2.1.0) 0.0796 0.0022 0.1260 1.1584 MegNet (kgcnn v2.1.0) 0.0871 0.0013 0.1358 1.5558 AMMExpress v2020 0.0874 0.0020 0.1277 1.1580 CGCNN v2019 0.0895 0.0016 0.1337 1.4520 DeeperGATGNN 0.0903 0.0025 0.1393 1.4002 Finder_v1.2 structure-based version 0.0910 0.0018 0.1412 1.4842 Finder_v1.2 composition-only version 0.0996 0.0018 0.1572 2.3854 CrabNet 0.1014 0.0017 0.1604 2.4220 RF-SCM/Magpie 0.1040 0.0016 0.1540 1.6942 Dummy 0.2931 0.0031 0.3716 1.5552"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_gvrh/#dataset-info","title":"Dataset info","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_gvrh/#description","title":"Description","text":"<p>Matbench v0.1 test dataset for predicting DFT log10 VRH-average shear modulus from structure. Adapted from Materials Project database. Removed entries having a formation energy (or energy above the convex hull) more than 150meV and those having negative G_Voigt, G_Reuss, G_VRH, K_Voigt, K_Reuss, or K_VRH and those failing G_Reuss &lt;= G_VRH &lt;= G_Voigt or K_Reuss &lt;= K_VRH &lt;= K_Voigt and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details.</p> <p>Number of samples: 10987</p> <p>Task type: regression</p> <p>Input type: structure</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_gvrh/#dataset-columns","title":"Dataset columns","text":"<ul> <li>log10(G_VRH): Target variable. Base 10 logarithm of the DFT Voigt-Reuss-Hill average shear moduli in GPa</li> <li>structure: Pymatgen Structure of the material.</li> </ul>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_gvrh/#dataset-reference","title":"Dataset reference","text":"<p><code>Jong, M. De, Chen, W., Angsten, T., Jain, A., Notestine, R., Gamst, A., Sluiter, M., Ande, C. K., Zwaag, S. Van Der, Plata, J. J., Toher, C., Curtarolo, S., Ceder, G., Persson, K. and Asta, M., \"Charting the complete elastic properties of inorganic crystalline compounds\", Scientific Data volume 2, Article number: 150009 (2015)</code></p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_gvrh/#metadata","title":"Metadata","text":"<pre><code>{'bibtex_refs': ['@Article{Dunn2020,\\n'\n                 'author={Dunn, Alexander\\n'\n                 'and Wang, Qi\\n'\n                 'and Ganose, Alex\\n'\n                 'and Dopp, Daniel\\n'\n                 'and Jain, Anubhav},\\n'\n                 'title={Benchmarking materials property prediction methods: '\n                 'the Matbench test set and Automatminer reference '\n                 'algorithm},\\n'\n                 'journal={npj Computational Materials},\\n'\n                 'year={2020},\\n'\n                 'month={Sep},\\n'\n                 'day={15},\\n'\n                 'volume={6},\\n'\n                 'number={1},\\n'\n                 'pages={138},\\n'\n                 'abstract={We present a benchmark test suite and an automated '\n                 'machine learning procedure for evaluating supervised machine '\n                 'learning (ML) models for predicting properties of inorganic '\n                 'bulk materials. The test suite, Matbench, is a set of '\n                 '13{\\\\thinspace}ML tasks that range in size from 312 to 132k '\n                 'samples and contain data from 10 density functional '\n                 'theory-derived and experimental sources. Tasks include '\n                 'predicting optical, thermal, electronic, thermodynamic, '\n                 \"tensile, and elastic properties given a material's \"\n                 'composition and/or crystal structure. The reference '\n                 'algorithm, Automatminer, is a highly-extensible, fully '\n                 'automated ML pipeline for predicting materials properties '\n                 'from materials primitives (such as composition and crystal '\n                 'structure) without user intervention or hyperparameter '\n                 'tuning. We test Automatminer on the Matbench test suite and '\n                 'compare its predictive power with state-of-the-art crystal '\n                 'graph neural networks and a traditional descriptor-based '\n                 'Random Forest model. We find Automatminer achieves the best '\n                 'performance on 8 of 13 tasks in the benchmark. We also show '\n                 'our test suite is capable of exposing predictive advantages '\n                 'of each algorithm---namely, that crystal graph methods '\n                 'appear to outperform traditional machine learning methods '\n                 'given {\\\\textasciitilde}104 or greater data points. We '\n                 'encourage evaluating materials ML algorithms on the Matbench '\n                 'benchmark and comparing them against the latest version of '\n                 'Automatminer.},\\n'\n                 'issn={2057-3960},\\n'\n                 'doi={10.1038/s41524-020-00406-3},\\n'\n                 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n'\n                 '}\\n',\n                 '@Article{deJong2015,\\n'\n                 'author={de Jong, Maarten and Chen, Wei and Angsten, Thomas\\n'\n                 'and Jain, Anubhav and Notestine, Randy and Gamst, Anthony\\n'\n                 'and Sluiter, Marcel and Krishna Ande, Chaitanya\\n'\n                 'and van der Zwaag, Sybrand and Plata, Jose J. and Toher, '\n                 'Cormac\\n'\n                 'and Curtarolo, Stefano and Ceder, Gerbrand and Persson, '\n                 'Kristin A.\\n'\n                 'and Asta, Mark},\\n'\n                 'title={Charting the complete elastic properties\\n'\n                 'of inorganic crystalline compounds},\\n'\n                 'journal={Scientific Data},\\n'\n                 'year={2015},\\n'\n                 'month={Mar},\\n'\n                 'day={17},\\n'\n                 'publisher={The Author(s)},\\n'\n                 'volume={2},\\n'\n                 'pages={150009},\\n'\n                 'note={Data Descriptor},\\n'\n                 'url={http://dx.doi.org/10.1038/sdata.2015.9}\\n'\n                 '}'],\n 'columns': {'log10(G_VRH)': 'Target variable. Base 10 logarithm of the DFT '\n                             'Voigt-Reuss-Hill average shear moduli in GPa',\n             'structure': 'Pymatgen Structure of the material.'},\n 'description': 'Matbench v0.1 test dataset for predicting DFT log10 '\n                'VRH-average shear modulus from structure. Adapted from '\n                'Materials Project database. Removed entries having a '\n                'formation energy (or energy above the convex hull) more than '\n                '150meV and those having negative G_Voigt, G_Reuss, G_VRH, '\n                'K_Voigt, K_Reuss, or K_VRH and those failing G_Reuss &lt;= G_VRH '\n                '&lt;= G_Voigt or K_Reuss &lt;= K_VRH &lt;= K_Voigt and those '\n                'containing noble gases. Retrieved April 2, 2019. For '\n                'benchmarking w/ nested cross validation, the order of the '\n                'dataset must be identical to the retrieved data; refer to the '\n                'Automatminer/Matbench publication for more details.',\n 'file_type': 'json.gz',\n 'hash': '098af941f4c663270f1fe21abf20ffad6fb85ecbfcba5786ceac03983ac29da7',\n 'input_type': 'structure',\n 'mad': 0.29313828328604646,\n 'n_samples': 10987,\n 'num_entries': 10987,\n 'reference': 'Jong, M. De, Chen, W., Angsten, T., Jain, A., Notestine, R., '\n              'Gamst,\\n'\n              'A., Sluiter, M., Ande, C. K., Zwaag, S. Van Der, Plata, J. J., '\n              'Toher,\\n'\n              'C., Curtarolo, S., Ceder, G., Persson, K. and Asta, M., '\n              '\"Charting\\n'\n              'the complete elastic properties of inorganic crystalline '\n              'compounds\",\\n'\n              'Scientific Data volume 2, Article number: 150009 (2015)',\n 'target': 'log10(G_VRH)',\n 'task_type': 'regression',\n 'unit': 'log10(GPa)',\n 'url': 'https://ml.materialsproject.org/projects/matbench_log_gvrh.json.gz'}\n</code></pre>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_kvrh/","title":"matbench_v0.1 matbench_log_kvrh","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_kvrh/#individual-task-leaderboard-for-matbench_log_kvrh","title":"Individual Task Leaderboard for <code>matbench_log_kvrh</code>","text":"<p>Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_kvrh/#leaderboard","title":"Leaderboard","text":"algorithm mean mae std mae mean rmse max max_error coNGN 0.0491 0.0026 0.1037 1.6329 coGN 0.0535 0.0028 0.1082 1.6521 MODNet (v0.1.12) 0.0548 0.0025 0.1043 1.5366 MODNet (v0.1.10) 0.0548 0.0025 0.1043 1.5366 ALIGNN 0.0568 0.0028 0.1106 1.6438 DimeNet++ (kgcnn v2.1.0) 0.0572 0.0032 0.1149 1.7063 SchNet (kgcnn v2.1.0) 0.0590 0.0022 0.1143 1.7542 AMMExpress v2020 0.0647 0.0015 0.1183 1.4823 MegNet (kgcnn v2.1.0) 0.0668 0.0034 0.1287 1.8705 Finder_v1.2 structure-based version 0.0693 0.0035 0.1318 1.6242 DeeperGATGNN 0.0698 0.0030 0.1324 1.7755 CGCNN v2019 0.0712 0.0028 0.1301 1.7725 CrabNet 0.0758 0.0034 0.1471 1.8430 Finder_v1.2 composition-only version 0.0764 0.0025 0.1491 2.3863 RF-SCM/Magpie 0.0820 0.0027 0.1454 1.7642 Dummy 0.2897 0.0043 0.3693 1.8822"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_kvrh/#dataset-info","title":"Dataset info","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_kvrh/#description","title":"Description","text":"<p>Matbench v0.1 test dataset for predicting DFT log10 VRH-average bulk modulus from structure. Adapted from Materials Project database. Removed entries having a formation energy (or energy above the convex hull) more than 150meV and those having negative G_Voigt, G_Reuss, G_VRH, K_Voigt, K_Reuss, or K_VRH and those failing G_Reuss &lt;= G_VRH &lt;= G_Voigt or K_Reuss &lt;= K_VRH &lt;= K_Voigt and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details.</p> <p>Number of samples: 10987</p> <p>Task type: regression</p> <p>Input type: structure</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_kvrh/#dataset-columns","title":"Dataset columns","text":"<ul> <li>log10(K_VRH): Target variable. Base 10 logarithm of the DFT Voigt-Reuss-Hill average bulk moduli in GPa.</li> <li>structure: Pymatgen Structure of the material.</li> </ul>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_kvrh/#dataset-reference","title":"Dataset reference","text":"<p><code>Jong, M. De, Chen, W., Angsten, T., Jain, A., Notestine, R., Gamst, A., Sluiter, M., Ande, C. K., Zwaag, S. Van Der, Plata, J. J., Toher, C., Curtarolo, S., Ceder, G., Persson, K. and Asta, M., \"Charting the complete elastic properties of inorganic crystalline compounds\", Scientific Data volume 2, Article number: 150009 (2015)</code></p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_log_kvrh/#metadata","title":"Metadata","text":"<pre><code>{'bibtex_refs': ['@Article{Dunn2020,\\n'\n                 'author={Dunn, Alexander\\n'\n                 'and Wang, Qi\\n'\n                 'and Ganose, Alex\\n'\n                 'and Dopp, Daniel\\n'\n                 'and Jain, Anubhav},\\n'\n                 'title={Benchmarking materials property prediction methods: '\n                 'the Matbench test set and Automatminer reference '\n                 'algorithm},\\n'\n                 'journal={npj Computational Materials},\\n'\n                 'year={2020},\\n'\n                 'month={Sep},\\n'\n                 'day={15},\\n'\n                 'volume={6},\\n'\n                 'number={1},\\n'\n                 'pages={138},\\n'\n                 'abstract={We present a benchmark test suite and an automated '\n                 'machine learning procedure for evaluating supervised machine '\n                 'learning (ML) models for predicting properties of inorganic '\n                 'bulk materials. The test suite, Matbench, is a set of '\n                 '13{\\\\thinspace}ML tasks that range in size from 312 to 132k '\n                 'samples and contain data from 10 density functional '\n                 'theory-derived and experimental sources. Tasks include '\n                 'predicting optical, thermal, electronic, thermodynamic, '\n                 \"tensile, and elastic properties given a material's \"\n                 'composition and/or crystal structure. The reference '\n                 'algorithm, Automatminer, is a highly-extensible, fully '\n                 'automated ML pipeline for predicting materials properties '\n                 'from materials primitives (such as composition and crystal '\n                 'structure) without user intervention or hyperparameter '\n                 'tuning. We test Automatminer on the Matbench test suite and '\n                 'compare its predictive power with state-of-the-art crystal '\n                 'graph neural networks and a traditional descriptor-based '\n                 'Random Forest model. We find Automatminer achieves the best '\n                 'performance on 8 of 13 tasks in the benchmark. We also show '\n                 'our test suite is capable of exposing predictive advantages '\n                 'of each algorithm---namely, that crystal graph methods '\n                 'appear to outperform traditional machine learning methods '\n                 'given {\\\\textasciitilde}104 or greater data points. We '\n                 'encourage evaluating materials ML algorithms on the Matbench '\n                 'benchmark and comparing them against the latest version of '\n                 'Automatminer.},\\n'\n                 'issn={2057-3960},\\n'\n                 'doi={10.1038/s41524-020-00406-3},\\n'\n                 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n'\n                 '}\\n',\n                 '@Article{deJong2015,\\n'\n                 'author={de Jong, Maarten and Chen, Wei and Angsten, Thomas\\n'\n                 'and Jain, Anubhav and Notestine, Randy and Gamst, Anthony\\n'\n                 'and Sluiter, Marcel and Krishna Ande, Chaitanya\\n'\n                 'and van der Zwaag, Sybrand and Plata, Jose J. and Toher, '\n                 'Cormac\\n'\n                 'and Curtarolo, Stefano and Ceder, Gerbrand and Persson, '\n                 'Kristin A.\\n'\n                 'and Asta, Mark},\\n'\n                 'title={Charting the complete elastic properties\\n'\n                 'of inorganic crystalline compounds},\\n'\n                 'journal={Scientific Data},\\n'\n                 'year={2015},\\n'\n                 'month={Mar},\\n'\n                 'day={17},\\n'\n                 'publisher={The Author(s)},\\n'\n                 'volume={2},\\n'\n                 'pages={150009},\\n'\n                 'note={Data Descriptor},\\n'\n                 'url={http://dx.doi.org/10.1038/sdata.2015.9}\\n'\n                 '}'],\n 'columns': {'log10(K_VRH)': 'Target variable. Base 10 logarithm of the DFT '\n                             'Voigt-Reuss-Hill average bulk moduli in GPa.',\n             'structure': 'Pymatgen Structure of the material.'},\n 'description': 'Matbench v0.1 test dataset for predicting DFT log10 '\n                'VRH-average bulk modulus from structure. Adapted from '\n                'Materials Project database. Removed entries having a '\n                'formation energy (or energy above the convex hull) more than '\n                '150meV and those having negative G_Voigt, G_Reuss, G_VRH, '\n                'K_Voigt, K_Reuss, or K_VRH and those failing G_Reuss &lt;= G_VRH '\n                '&lt;= G_Voigt or K_Reuss &lt;= K_VRH &lt;= K_Voigt and those '\n                'containing noble gases. Retrieved April 2, 2019. For '\n                'benchmarking w/ nested cross validation, the order of the '\n                'dataset must be identical to the retrieved data; refer to the '\n                'Automatminer/Matbench publication for more details.',\n 'file_type': 'json.gz',\n 'hash': '44b113ddb7e23aa18731a62c74afa7e5aa654199e0db5f951c8248a00955c9cd',\n 'input_type': 'structure',\n 'mad': 0.2896736342937069,\n 'n_samples': 10987,\n 'num_entries': 10987,\n 'reference': 'Jong, M. De, Chen, W., Angsten, T., Jain, A., Notestine, R., '\n              'Gamst,\\n'\n              'A., Sluiter, M., Ande, C. K., Zwaag, S. Van Der, Plata, J. J., '\n              'Toher,\\n'\n              'C., Curtarolo, S., Ceder, G., Persson, K. and Asta, M., '\n              '\"Charting\\n'\n              'the complete elastic properties of inorganic crystalline '\n              'compounds\",\\n'\n              'Scientific Data volume 2, Article number: 150009 (2015)',\n 'target': 'log10(K_VRH)',\n 'task_type': 'regression',\n 'unit': 'log10(GPa)',\n 'url': 'https://ml.materialsproject.org/projects/matbench_log_kvrh.json.gz'}\n</code></pre>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_e_form/","title":"matbench_v0.1 matbench_mp_e_form","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_e_form/#individual-task-leaderboard-for-matbench_mp_e_form","title":"Individual Task Leaderboard for <code>matbench_mp_e_form</code>","text":"<p>Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_e_form/#leaderboard","title":"Leaderboard","text":"algorithm mean mae std mae mean rmse max max_error coGN 0.0170 0.0003 0.0483 3.8249 coNGN 0.0178 0.0004 0.0502 3.2378 ALIGNN 0.0215 0.0005 0.0544 3.5487 SchNet (kgcnn v2.1.0) 0.0218 0.0004 0.0529 2.9990 DimeNet++ (kgcnn v2.1.0) 0.0235 0.0004 0.0695 3.6006 GN-OA v1 0.0248 0.0002 0.0636 2.4150 MegNet (kgcnn v2.1.0) 0.0252 0.0003 0.0701 3.6006 CGCNN v2019 0.0337 0.0006 0.0682 7.7205 DeeperGATGNN 0.0340 0.0023 0.0759 3.4390 Finder_v1.2 structure-based version 0.0343 0.0012 0.1331 45.1834 MODNet (v0.1.10) 0.0448 0.0039 0.0888 4.8803 MODNet (v0.1.12) 0.0448 0.0039 0.0888 4.8803 Finder_v1.2 composition-only version 0.0839 0.0011 0.2537 6.3948 CrabNet 0.0862 0.0010 0.2544 6.3774 RF-SCM/Magpie 0.1165 0.0008 0.2419 5.4382 AMMExpress v2020 0.1726 0.0270 0.2602 5.8108 Lattice-XGBoost 0.7515 0.0042 0.9415 4.2425 Dummy 1.0059 0.0030 1.1631 3.9096"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_e_form/#dataset-info","title":"Dataset info","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_e_form/#description","title":"Description","text":"<p>Matbench v0.1 test dataset for predicting DFT formation energy from structure. Adapted from Materials Project database. Removed entries having formation energy more than 2.5eV and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details.</p> <p>Number of samples: 132752</p> <p>Task type: regression</p> <p>Input type: structure</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_e_form/#dataset-columns","title":"Dataset columns","text":"<ul> <li>e_form: Target variable. Formation energy in eV as calculated by the Materials Project.</li> <li>structure: Pymatgen Structure of the material.</li> </ul>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_e_form/#dataset-reference","title":"Dataset reference","text":"<p><code>A. Jain*, S.P. Ong*, G. Hautier, W. Chen, W.D. Richards, S. Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K.A. Persson (*=equal contributions) The Materials Project: A materials genome approach to accelerating materials innovation APL Materials, 2013, 1(1), 011002. doi:10.1063/1.4812323</code></p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_e_form/#metadata","title":"Metadata","text":"<pre><code>{'bibtex_refs': ['@Article{Dunn2020,\\n'\n                 'author={Dunn, Alexander\\n'\n                 'and Wang, Qi\\n'\n                 'and Ganose, Alex\\n'\n                 'and Dopp, Daniel\\n'\n                 'and Jain, Anubhav},\\n'\n                 'title={Benchmarking materials property prediction methods: '\n                 'the Matbench test set and Automatminer reference '\n                 'algorithm},\\n'\n                 'journal={npj Computational Materials},\\n'\n                 'year={2020},\\n'\n                 'month={Sep},\\n'\n                 'day={15},\\n'\n                 'volume={6},\\n'\n                 'number={1},\\n'\n                 'pages={138},\\n'\n                 'abstract={We present a benchmark test suite and an automated '\n                 'machine learning procedure for evaluating supervised machine '\n                 'learning (ML) models for predicting properties of inorganic '\n                 'bulk materials. The test suite, Matbench, is a set of '\n                 '13{\\\\thinspace}ML tasks that range in size from 312 to 132k '\n                 'samples and contain data from 10 density functional '\n                 'theory-derived and experimental sources. Tasks include '\n                 'predicting optical, thermal, electronic, thermodynamic, '\n                 \"tensile, and elastic properties given a material's \"\n                 'composition and/or crystal structure. The reference '\n                 'algorithm, Automatminer, is a highly-extensible, fully '\n                 'automated ML pipeline for predicting materials properties '\n                 'from materials primitives (such as composition and crystal '\n                 'structure) without user intervention or hyperparameter '\n                 'tuning. We test Automatminer on the Matbench test suite and '\n                 'compare its predictive power with state-of-the-art crystal '\n                 'graph neural networks and a traditional descriptor-based '\n                 'Random Forest model. We find Automatminer achieves the best '\n                 'performance on 8 of 13 tasks in the benchmark. We also show '\n                 'our test suite is capable of exposing predictive advantages '\n                 'of each algorithm---namely, that crystal graph methods '\n                 'appear to outperform traditional machine learning methods '\n                 'given {\\\\textasciitilde}104 or greater data points. We '\n                 'encourage evaluating materials ML algorithms on the Matbench '\n                 'benchmark and comparing them against the latest version of '\n                 'Automatminer.},\\n'\n                 'issn={2057-3960},\\n'\n                 'doi={10.1038/s41524-020-00406-3},\\n'\n                 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n'\n                 '}\\n',\n                 '@article{Jain2013,\\n'\n                 'author = {Jain, Anubhav and Ong, Shyue Ping and Hautier, '\n                 'Geoffroy and Chen, Wei and Richards, William Davidson and '\n                 'Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and '\n                 'Skinner, David and Ceder, Gerbrand and Persson, Kristin '\n                 'a.},\\n'\n                 'doi = {10.1063/1.4812323},\\n'\n                 'issn = {2166532X},\\n'\n                 'journal = {APL Materials},\\n'\n                 'number = {1},\\n'\n                 'pages = {011002},\\n'\n                 'title = {{The Materials Project: A materials genome approach '\n                 'to accelerating materials innovation}},\\n'\n                 'url = '\n                 '{http://link.aip.org/link/AMPADS/v1/i1/p011002/s1\\\\&amp;Agg=doi},\\n'\n                 'volume = {1},\\n'\n                 'year = {2013}\\n'\n                 '}'],\n 'columns': {'e_form': 'Target variable. Formation energy in eV as calculated '\n                       'by the Materials Project.',\n             'structure': 'Pymatgen Structure of the material.'},\n 'description': 'Matbench v0.1 test dataset for predicting DFT formation '\n                'energy from structure. Adapted from Materials Project '\n                'database. Removed entries having formation energy more than '\n                '2.5eV and those containing noble gases. Retrieved April 2, '\n                '2019. For benchmarking w/ nested cross validation, the order '\n                'of the dataset must be identical to the retrieved data; refer '\n                'to the Automatminer/Matbench publication for more details.',\n 'file_type': 'json.gz',\n 'hash': 'dedcb1d4ba2e3e50dbdd45ba5bc647a00e9c2bcf8f8bf556dc8e92caa39eb21f',\n 'input_type': 'structure',\n 'mad': 1.0059220443295362,\n 'n_samples': 132752,\n 'num_entries': 132752,\n 'reference': 'A. Jain*, S.P. Ong*, G. Hautier, W. Chen, W.D. Richards, S. '\n              'Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K.A. Persson '\n              '(*=equal contributions)\\n'\n              'The Materials Project: A materials genome approach to '\n              'accelerating materials innovation\\n'\n              'APL Materials, 2013, 1(1), 011002.\\n'\n              'doi:10.1063/1.4812323',\n 'target': 'e_form',\n 'task_type': 'regression',\n 'unit': 'eV/atom',\n 'url': 'https://ml.materialsproject.org/projects/matbench_mp_e_form.json.gz'}\n</code></pre>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_gap/","title":"matbench_v0.1 matbench_mp_gap","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_gap/#individual-task-leaderboard-for-matbench_mp_gap","title":"Individual Task Leaderboard for <code>matbench_mp_gap</code>","text":"<p>Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_gap/#leaderboard","title":"Leaderboard","text":"algorithm mean mae std mae mean rmse max max_error coGN 0.1559 0.0017 0.3956 7.3352 DeeperGATGNN 0.1694 0.0047 0.4175 7.4794 coNGN 0.1697 0.0035 0.4271 7.9674 ALIGNN 0.1861 0.0030 0.4635 7.4756 MegNet (kgcnn v2.1.0) 0.1934 0.0087 0.4715 7.8821 DimeNet++ (kgcnn v2.1.0) 0.1993 0.0058 0.4720 14.0169 Finder_v1.2 structure-based version 0.2193 0.0012 0.4989 7.6676 MODNet (v0.1.12) 0.2199 0.0059 0.4525 7.5685 MODNet (v0.1.10) 0.2199 0.0059 0.4525 7.5685 Finder_v1.2 composition-only version 0.2308 0.0029 0.4837 7.8152 SchNet (kgcnn v2.1.0) 0.2352 0.0034 0.5172 9.1171 CrabNet 0.2655 0.0029 0.5898 7.9829 AMMExpress v2020 0.2824 0.0061 0.5611 6.9105 CGCNN v2019 0.2972 0.0035 0.6771 13.6569 RF-SCM/Magpie 0.3452 0.0033 0.6125 7.0601 Dummy 1.3272 0.0060 1.5989 8.5092"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_gap/#dataset-info","title":"Dataset info","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_gap/#description","title":"Description","text":"<p>Matbench v0.1 test dataset for predicting DFT PBE band gap from structure. Adapted from Materials Project database. Removed entries having a formation energy (or energy above the convex hull) more than 150meV and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details.</p> <p>Number of samples: 106113</p> <p>Task type: regression</p> <p>Input type: structure</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_gap/#dataset-columns","title":"Dataset columns","text":"<ul> <li>gap pbe: Target variable. The band gap as calculated by PBE DFT from the Materials Project, in eV.</li> <li>structure: Pymatgen Structure of the material.</li> </ul>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_gap/#dataset-reference","title":"Dataset reference","text":"<p><code>A. Jain*, S.P. Ong*, G. Hautier, W. Chen, W.D. Richards, S. Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K.A. Persson (*=equal contributions) The Materials Project: A materials genome approach to accelerating materials innovation APL Materials, 2013, 1(1), 011002. doi:10.1063/1.4812323</code></p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_gap/#metadata","title":"Metadata","text":"<pre><code>{'bibtex_refs': ['@Article{Dunn2020,\\n'\n                 'author={Dunn, Alexander\\n'\n                 'and Wang, Qi\\n'\n                 'and Ganose, Alex\\n'\n                 'and Dopp, Daniel\\n'\n                 'and Jain, Anubhav},\\n'\n                 'title={Benchmarking materials property prediction methods: '\n                 'the Matbench test set and Automatminer reference '\n                 'algorithm},\\n'\n                 'journal={npj Computational Materials},\\n'\n                 'year={2020},\\n'\n                 'month={Sep},\\n'\n                 'day={15},\\n'\n                 'volume={6},\\n'\n                 'number={1},\\n'\n                 'pages={138},\\n'\n                 'abstract={We present a benchmark test suite and an automated '\n                 'machine learning procedure for evaluating supervised machine '\n                 'learning (ML) models for predicting properties of inorganic '\n                 'bulk materials. The test suite, Matbench, is a set of '\n                 '13{\\\\thinspace}ML tasks that range in size from 312 to 132k '\n                 'samples and contain data from 10 density functional '\n                 'theory-derived and experimental sources. Tasks include '\n                 'predicting optical, thermal, electronic, thermodynamic, '\n                 \"tensile, and elastic properties given a material's \"\n                 'composition and/or crystal structure. The reference '\n                 'algorithm, Automatminer, is a highly-extensible, fully '\n                 'automated ML pipeline for predicting materials properties '\n                 'from materials primitives (such as composition and crystal '\n                 'structure) without user intervention or hyperparameter '\n                 'tuning. We test Automatminer on the Matbench test suite and '\n                 'compare its predictive power with state-of-the-art crystal '\n                 'graph neural networks and a traditional descriptor-based '\n                 'Random Forest model. We find Automatminer achieves the best '\n                 'performance on 8 of 13 tasks in the benchmark. We also show '\n                 'our test suite is capable of exposing predictive advantages '\n                 'of each algorithm---namely, that crystal graph methods '\n                 'appear to outperform traditional machine learning methods '\n                 'given {\\\\textasciitilde}104 or greater data points. We '\n                 'encourage evaluating materials ML algorithms on the Matbench '\n                 'benchmark and comparing them against the latest version of '\n                 'Automatminer.},\\n'\n                 'issn={2057-3960},\\n'\n                 'doi={10.1038/s41524-020-00406-3},\\n'\n                 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n'\n                 '}\\n',\n                 '@article{Jain2013,\\n'\n                 'author = {Jain, Anubhav and Ong, Shyue Ping and Hautier, '\n                 'Geoffroy and Chen, Wei and Richards, William Davidson and '\n                 'Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and '\n                 'Skinner, David and Ceder, Gerbrand and Persson, Kristin '\n                 'a.},\\n'\n                 'doi = {10.1063/1.4812323},\\n'\n                 'issn = {2166532X},\\n'\n                 'journal = {APL Materials},\\n'\n                 'number = {1},\\n'\n                 'pages = {011002},\\n'\n                 'title = {{The Materials Project: A materials genome approach '\n                 'to accelerating materials innovation}},\\n'\n                 'url = '\n                 '{http://link.aip.org/link/AMPADS/v1/i1/p011002/s1\\\\&amp;Agg=doi},\\n'\n                 'volume = {1},\\n'\n                 'year = {2013}\\n'\n                 '}'],\n 'columns': {'gap pbe': 'Target variable. The band gap as calculated by PBE '\n                        'DFT from the Materials Project, in eV.',\n             'structure': 'Pymatgen Structure of the material.'},\n 'description': 'Matbench v0.1 test dataset for predicting DFT PBE band gap '\n                'from structure. Adapted from Materials Project database. '\n                'Removed entries having a formation energy (or energy above '\n                'the convex hull) more than 150meV and those containing noble '\n                'gases. Retrieved April 2, 2019. For benchmarking w/ nested '\n                'cross validation, the order of the dataset must be identical '\n                'to the retrieved data; refer to the Automatminer/Matbench '\n                'publication for more details.',\n 'file_type': 'json.gz',\n 'hash': '58b65746bd88329986ed66031a2ac1369c7c522f7bc9f9081528e07097c2c057',\n 'input_type': 'structure',\n 'mad': 1.3271449960162496,\n 'n_samples': 106113,\n 'num_entries': 106113,\n 'reference': 'A. Jain*, S.P. Ong*, G. Hautier, W. Chen, W.D. Richards, S. '\n              'Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K.A. Persson '\n              '(*=equal contributions)\\n'\n              'The Materials Project: A materials genome approach to '\n              'accelerating materials innovation\\n'\n              'APL Materials, 2013, 1(1), 011002.\\n'\n              'doi:10.1063/1.4812323',\n 'target': 'gap pbe',\n 'task_type': 'regression',\n 'unit': 'eV',\n 'url': 'https://ml.materialsproject.org/projects/matbench_mp_gap.json.gz'}\n</code></pre>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_is_metal/","title":"matbench_v0.1 matbench_mp_is_metal","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_is_metal/#individual-task-leaderboard-for-matbench_mp_is_metal","title":"Individual Task Leaderboard for <code>matbench_mp_is_metal</code>","text":"<p>Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_is_metal/#leaderboard","title":"Leaderboard","text":"algorithm mean rocauc std rocauc mean f1 mean balanced_accuracy CGCNN v2019 0.9520 0.0074 0.9462 0.9520 ALIGNN 0.9128 0.0015 0.9015 0.9128 coGN 0.9124 0.0023 0.9012 0.9124 AMMExpress v2020 0.9093 0.0008 0.8981 0.9093 coNGN 0.9089 0.0019 0.8972 0.9089 MODNet (v0.1.12) 0.9038 0.0106 0.8916 0.9038 DimeNet++ (kgcnn v2.1.0) 0.9032 0.0036 0.8907 0.9032 MegNet (kgcnn v2.1.0) 0.9021 0.0018 0.8895 0.9021 RF-SCM/Magpie 0.8992 0.0019 0.8866 0.8992 SchNet (kgcnn v2.1.0) 0.8907 0.0018 0.8765 0.8907 Matformer 0.8117 0.0455 0.7660 0.8117 MODNet (v0.1.10) 0.7805 0.1406 0.6621 0.7805 Dummy 0.5012 0.0043 0.4353 0.5012"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_is_metal/#dataset-info","title":"Dataset info","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_is_metal/#description","title":"Description","text":"<p>Matbench v0.1 test dataset for predicting DFT metallicity from structure. Adapted from Materials Project database. Removed entries having a formation energy (or energy above the convex hull) more than 150meV and those containing noble gases. Retrieved April 2, 2019. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details.</p> <p>Number of samples: 106113</p> <p>Task type: classification</p> <p>Input type: structure</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_is_metal/#dataset-columns","title":"Dataset columns","text":"<ul> <li>is_metal: Target variable. 1 if the compound is a metal, 0 if the compound is not a metal. Metallicity determined with pymatgen</li> <li>structure: Pymatgen Structure of the material.</li> </ul>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_is_metal/#dataset-reference","title":"Dataset reference","text":"<p><code>A. Jain*, S.P. Ong*, G. Hautier, W. Chen, W.D. Richards, S. Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K.A. Persson (*=equal contributions) The Materials Project: A materials genome approach to accelerating materials innovation APL Materials, 2013, 1(1), 011002. doi:10.1063/1.4812323</code></p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_mp_is_metal/#metadata","title":"Metadata","text":"<pre><code>{'bibtex_refs': ['@Article{Dunn2020,\\n'\n                 'author={Dunn, Alexander\\n'\n                 'and Wang, Qi\\n'\n                 'and Ganose, Alex\\n'\n                 'and Dopp, Daniel\\n'\n                 'and Jain, Anubhav},\\n'\n                 'title={Benchmarking materials property prediction methods: '\n                 'the Matbench test set and Automatminer reference '\n                 'algorithm},\\n'\n                 'journal={npj Computational Materials},\\n'\n                 'year={2020},\\n'\n                 'month={Sep},\\n'\n                 'day={15},\\n'\n                 'volume={6},\\n'\n                 'number={1},\\n'\n                 'pages={138},\\n'\n                 'abstract={We present a benchmark test suite and an automated '\n                 'machine learning procedure for evaluating supervised machine '\n                 'learning (ML) models for predicting properties of inorganic '\n                 'bulk materials. The test suite, Matbench, is a set of '\n                 '13{\\\\thinspace}ML tasks that range in size from 312 to 132k '\n                 'samples and contain data from 10 density functional '\n                 'theory-derived and experimental sources. Tasks include '\n                 'predicting optical, thermal, electronic, thermodynamic, '\n                 \"tensile, and elastic properties given a material's \"\n                 'composition and/or crystal structure. The reference '\n                 'algorithm, Automatminer, is a highly-extensible, fully '\n                 'automated ML pipeline for predicting materials properties '\n                 'from materials primitives (such as composition and crystal '\n                 'structure) without user intervention or hyperparameter '\n                 'tuning. We test Automatminer on the Matbench test suite and '\n                 'compare its predictive power with state-of-the-art crystal '\n                 'graph neural networks and a traditional descriptor-based '\n                 'Random Forest model. We find Automatminer achieves the best '\n                 'performance on 8 of 13 tasks in the benchmark. We also show '\n                 'our test suite is capable of exposing predictive advantages '\n                 'of each algorithm---namely, that crystal graph methods '\n                 'appear to outperform traditional machine learning methods '\n                 'given {\\\\textasciitilde}104 or greater data points. We '\n                 'encourage evaluating materials ML algorithms on the Matbench '\n                 'benchmark and comparing them against the latest version of '\n                 'Automatminer.},\\n'\n                 'issn={2057-3960},\\n'\n                 'doi={10.1038/s41524-020-00406-3},\\n'\n                 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n'\n                 '}\\n',\n                 '@article{Jain2013,\\n'\n                 'author = {Jain, Anubhav and Ong, Shyue Ping and Hautier, '\n                 'Geoffroy and Chen, Wei and Richards, William Davidson and '\n                 'Dacek, Stephen and Cholia, Shreyas and Gunter, Dan and '\n                 'Skinner, David and Ceder, Gerbrand and Persson, Kristin '\n                 'a.},\\n'\n                 'doi = {10.1063/1.4812323},\\n'\n                 'issn = {2166532X},\\n'\n                 'journal = {APL Materials},\\n'\n                 'number = {1},\\n'\n                 'pages = {011002},\\n'\n                 'title = {{The Materials Project: A materials genome approach '\n                 'to accelerating materials innovation}},\\n'\n                 'url = '\n                 '{http://link.aip.org/link/AMPADS/v1/i1/p011002/s1\\\\&amp;Agg=doi},\\n'\n                 'volume = {1},\\n'\n                 'year = {2013}\\n'\n                 '}'],\n 'columns': {'is_metal': 'Target variable. 1 if the compound is a metal, 0 if '\n                         'the compound is not a metal. Metallicity determined '\n                         'with pymatgen',\n             'structure': 'Pymatgen Structure of the material.'},\n 'description': 'Matbench v0.1 test dataset for predicting DFT metallicity '\n                'from structure. Adapted from Materials Project database. '\n                'Removed entries having a formation energy (or energy above '\n                'the convex hull) more than 150meV and those containing noble '\n                'gases. Retrieved April 2, 2019. For benchmarking w/ nested '\n                'cross validation, the order of the dataset must be identical '\n                'to the retrieved data; refer to the Automatminer/Matbench '\n                'publication for more details.',\n 'file_type': 'json.gz',\n 'frac_true': 0.43492314796490533,\n 'hash': '9a028ed5750a4c76ca36e9f3c8d48fe0bf3fb21b76ec2289e58ae7048d527919',\n 'input_type': 'structure',\n 'n_samples': 106113,\n 'num_entries': 106113,\n 'reference': 'A. Jain*, S.P. Ong*, G. Hautier, W. Chen, W.D. Richards, S. '\n              'Dacek, S. Cholia, D. Gunter, D. Skinner, G. Ceder, K.A. Persson '\n              '(*=equal contributions)\\n'\n              'The Materials Project: A materials genome approach to '\n              'accelerating materials innovation\\n'\n              'APL Materials, 2013, 1(1), 011002.\\n'\n              'doi:10.1063/1.4812323',\n 'target': 'is_metal',\n 'task_type': 'classification',\n 'unit': None,\n 'url': 'https://ml.materialsproject.org/projects/matbench_mp_is_metal.json.gz'}\n</code></pre>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_perovskites/","title":"matbench_v0.1 matbench_perovskites","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_perovskites/#individual-task-leaderboard-for-matbench_perovskites","title":"Individual Task Leaderboard for <code>matbench_perovskites</code>","text":"<p>Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_perovskites/#leaderboard","title":"Leaderboard","text":"algorithm mean mae std mae mean rmse max max_error coGN 0.0269 0.0008 0.0554 0.9449 ALIGNN 0.0288 0.0009 0.0559 0.9028 DeeperGATGNN 0.0288 0.0011 0.0568 1.0267 coNGN 0.0290 0.0011 0.0590 0.9346 Finder_v1.2 structure-based version 0.0320 0.0012 0.0594 0.8875 SchNet (kgcnn v2.1.0) 0.0342 0.0005 0.0599 0.8929 MegNet (kgcnn v2.1.0) 0.0352 0.0016 0.0635 1.0236 DimeNet++ (kgcnn v2.1.0) 0.0376 0.0011 0.0642 0.9676 CGCNN v2019 0.0452 0.0007 0.0722 0.9923 MODNet (v0.1.12) 0.0908 0.0028 0.1277 1.1780 MODNet (v0.1.10) 0.0908 0.0028 0.1277 1.1780 AMMExpress v2020 0.2005 0.0085 0.2954 3.3116 RF-SCM/Magpie 0.2355 0.0034 0.3346 2.8870 CrabNet 0.4065 0.0069 0.5412 2.3726 Dummy 0.5660 0.0048 0.7424 3.6873 Finder_v1.2 composition-only version 0.6450 0.0167 0.8831 3.5402"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_perovskites/#dataset-info","title":"Dataset info","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_perovskites/#description","title":"Description","text":"<p>Matbench v0.1 test dataset for predicting formation energy from crystal structure. Adapted from an original dataset generated by Castelli et al. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details.</p> <p>Number of samples: 18928</p> <p>Task type: regression</p> <p>Input type: structure</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_perovskites/#dataset-columns","title":"Dataset columns","text":"<ul> <li>e_form: Target variable. Heat of formation of the entire 5-atom perovskite cell, in eV as calculated by RPBE GGA-DFT. Note the reference state for oxygen was computed from oxygen's chemical potential in water vapor, not as oxygen molecules, to reflect the application which these perovskites were studied for.</li> <li>structure: Pymatgen Structure of the material.</li> </ul>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_perovskites/#dataset-reference","title":"Dataset reference","text":"<p><code>Ivano E. Castelli, David D. Landis, Kristian S. Thygesen, S\u00f8ren Dahl, Ib Chorkendorff, Thomas F. Jaramillo and Karsten W. Jacobsen (2012) New cubic perovskites for one- and two-photon water splitting using the computational materials repository. Energy Environ. Sci., 2012,5, 9034-9043 https://doi.org/10.1039/C2EE22341D</code></p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_perovskites/#metadata","title":"Metadata","text":"<pre><code>{'bibtex_refs': ['@Article{Dunn2020,\\n'\n                 'author={Dunn, Alexander\\n'\n                 'and Wang, Qi\\n'\n                 'and Ganose, Alex\\n'\n                 'and Dopp, Daniel\\n'\n                 'and Jain, Anubhav},\\n'\n                 'title={Benchmarking materials property prediction methods: '\n                 'the Matbench test set and Automatminer reference '\n                 'algorithm},\\n'\n                 'journal={npj Computational Materials},\\n'\n                 'year={2020},\\n'\n                 'month={Sep},\\n'\n                 'day={15},\\n'\n                 'volume={6},\\n'\n                 'number={1},\\n'\n                 'pages={138},\\n'\n                 'abstract={We present a benchmark test suite and an automated '\n                 'machine learning procedure for evaluating supervised machine '\n                 'learning (ML) models for predicting properties of inorganic '\n                 'bulk materials. The test suite, Matbench, is a set of '\n                 '13{\\\\thinspace}ML tasks that range in size from 312 to 132k '\n                 'samples and contain data from 10 density functional '\n                 'theory-derived and experimental sources. Tasks include '\n                 'predicting optical, thermal, electronic, thermodynamic, '\n                 \"tensile, and elastic properties given a material's \"\n                 'composition and/or crystal structure. The reference '\n                 'algorithm, Automatminer, is a highly-extensible, fully '\n                 'automated ML pipeline for predicting materials properties '\n                 'from materials primitives (such as composition and crystal '\n                 'structure) without user intervention or hyperparameter '\n                 'tuning. We test Automatminer on the Matbench test suite and '\n                 'compare its predictive power with state-of-the-art crystal '\n                 'graph neural networks and a traditional descriptor-based '\n                 'Random Forest model. We find Automatminer achieves the best '\n                 'performance on 8 of 13 tasks in the benchmark. We also show '\n                 'our test suite is capable of exposing predictive advantages '\n                 'of each algorithm---namely, that crystal graph methods '\n                 'appear to outperform traditional machine learning methods '\n                 'given {\\\\textasciitilde}104 or greater data points. We '\n                 'encourage evaluating materials ML algorithms on the Matbench '\n                 'benchmark and comparing them against the latest version of '\n                 'Automatminer.},\\n'\n                 'issn={2057-3960},\\n'\n                 'doi={10.1038/s41524-020-00406-3},\\n'\n                 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n'\n                 '}\\n',\n                 '@Article{C2EE22341D,\\n'\n                 'author =\"Castelli, Ivano E. and Landis, David D. and '\n                 'Thygesen, Kristian S. and Dahl, S\u00f8ren and Chorkendorff, Ib '\n                 'and Jaramillo, Thomas F. and Jacobsen, Karsten W.\",\\n'\n                 'title  =\"New cubic perovskites for one- and two-photon water '\n                 'splitting using the computational materials repository\",\\n'\n                 'journal  =\"Energy Environ. Sci.\",\\n'\n                 'year  =\"2012\",\\n'\n                 'volume  =\"5\",\\n'\n                 'issue  =\"10\",\\n'\n                 'pages  =\"9034-9043\",\\n'\n                 'publisher  =\"The Royal Society of Chemistry\",\\n'\n                 'doi  =\"10.1039/C2EE22341D\",\\n'\n                 'url  =\"http://dx.doi.org/10.1039/C2EE22341D\",\\n'\n                 'abstract  =\"A new efficient photoelectrochemical cell (PEC) '\n                 'is one of the possible solutions to the energy and climate '\n                 'problems of our time. Such a device requires development of '\n                 'new semiconducting materials with tailored properties with '\n                 'respect to stability and light absorption. Here we perform '\n                 'computational screening of around 19\\u2009000 oxides{,} '\n                 'oxynitrides{,} oxysulfides{,} oxyfluorides{,} and '\n                 'oxyfluoronitrides in the cubic perovskite structure with PEC '\n                 'applications in mind. We address three main applications: '\n                 'light absorbers for one- and two-photon water splitting and '\n                 'high-stability transparent shields to protect against '\n                 'corrosion. We end up with 20{,} 12{,} and 15 different '\n                 'combinations of oxides{,} oxynitrides and oxyfluorides{,} '\n                 'respectively{,} inviting further experimental '\n                 'investigation.\"}'],\n 'columns': {'e_form': 'Target variable. Heat of formation of the entire '\n                       '5-atom perovskite cell, in eV as calculated by RPBE '\n                       'GGA-DFT. Note the reference state for oxygen was '\n                       \"computed from oxygen's chemical potential in water \"\n                       'vapor, not as oxygen molecules, to reflect the '\n                       'application which these perovskites were studied for.',\n             'structure': 'Pymatgen Structure of the material.'},\n 'description': 'Matbench v0.1 test dataset for predicting formation energy '\n                'from crystal structure. Adapted from an original dataset '\n                'generated by Castelli et al. For benchmarking w/ nested cross '\n                'validation, the order of the dataset must be identical to the '\n                'retrieved data; refer to the Automatminer/Matbench '\n                'publication for more details.',\n 'file_type': 'json.gz',\n 'hash': '4641e2417f8ec8b50096d2230864468dfa08278dc9d257c327f65d0305278483',\n 'input_type': 'structure',\n 'mad': 0.5659924184827462,\n 'n_samples': 18928,\n 'num_entries': 18928,\n 'reference': 'Ivano E. Castelli, David D. Landis, Kristian S. Thygesen, S\u00f8ren '\n              'Dahl, Ib Chorkendorff, Thomas F. Jaramillo and Karsten W. '\n              'Jacobsen (2012) New cubic perovskites for one- and two-photon '\n              'water splitting using the computational materials repository. '\n              'Energy Environ. Sci., 2012,5, 9034-9043 '\n              'https://doi.org/10.1039/C2EE22341D',\n 'target': 'e_form',\n 'task_type': 'regression',\n 'unit': 'eV/unit cell',\n 'url': 'https://ml.materialsproject.org/projects/matbench_perovskites.json.gz'}\n</code></pre>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_phonons/","title":"matbench_v0.1 matbench_phonons","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_phonons/#individual-task-leaderboard-for-matbench_phonons","title":"Individual Task Leaderboard for <code>matbench_phonons</code>","text":"<p>Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_phonons/#leaderboard","title":"Leaderboard","text":"algorithm mean mae std mae mean rmse max max_error MegNet (kgcnn v2.1.0) 28.7606 2.5767 57.4679 774.1321 coNGN 28.8874 3.2840 57.1375 747.0843 ALIGNN 29.5385 2.1148 53.5010 615.3466 coGN 29.7117 1.9968 57.7099 622.4674 DeeperGATGNN 33.1211 1.4530 78.8475 1134.0565 MODNet (v0.1.12) 34.2751 2.0781 70.0669 1079.1280 DimeNet++ (kgcnn v2.1.0) 37.4619 2.1934 80.3047 1012.6802 MODNet (v0.1.10) 38.7524 1.7732 78.2220 1031.8168 SchNet (kgcnn v2.1.0) 38.9636 1.9760 76.9279 1034.3312 Finder_v1.2 composition-only version 46.5751 3.7415 94.8514 1051.2485 Finder_v1.2 structure-based version 50.7406 5.4036 124.0783 1706.8711 CrabNet 55.1114 5.7317 138.3775 1452.7562 AMMExpress v2020 56.1706 6.7981 109.7048 1151.5570 CGCNN v2019 57.7635 12.3109 141.7018 2504.8743 RF-SCM/Magpie 67.6126 8.9900 146.2764 2024.7301 Dummy 323.9822 17.7269 492.1533 3062.3450"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_phonons/#dataset-info","title":"Dataset info","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_phonons/#description","title":"Description","text":"<p>Matbench v0.1 test dataset for predicting vibration properties from crystal structure. Original data retrieved from Petretto et al. Original calculations done via ABINIT in the harmonic approximation based on density functional perturbation theory. Removed entries having a formation energy (or energy above the convex hull) more than 150meV. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details.</p> <p>Number of samples: 1265</p> <p>Task type: regression</p> <p>Input type: structure</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_phonons/#dataset-columns","title":"Dataset columns","text":"<ul> <li>last phdos peak: Target variable. Frequency of the highest frequency optical phonon mode peak, in units of 1/cm; ; may be used as an estimation of dominant longitudinal optical phonon frequency.</li> <li>structure: Pymatgen Structure of the material.</li> </ul>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_phonons/#dataset-reference","title":"Dataset reference","text":"<p><code>Petretto, G. et al. High-throughput density functional perturbation theory phonons for inorganic materials. Sci. Data 5:180065 doi: 10.1038/sdata.2018.65 (2018). Petretto, G. et al. High-throughput density functional perturbation theory phonons for inorganic materials. (2018). figshare. Collection.</code></p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_phonons/#metadata","title":"Metadata","text":"<pre><code>{'bibtex_refs': ['@Article{Dunn2020,\\n'\n                 'author={Dunn, Alexander\\n'\n                 'and Wang, Qi\\n'\n                 'and Ganose, Alex\\n'\n                 'and Dopp, Daniel\\n'\n                 'and Jain, Anubhav},\\n'\n                 'title={Benchmarking materials property prediction methods: '\n                 'the Matbench test set and Automatminer reference '\n                 'algorithm},\\n'\n                 'journal={npj Computational Materials},\\n'\n                 'year={2020},\\n'\n                 'month={Sep},\\n'\n                 'day={15},\\n'\n                 'volume={6},\\n'\n                 'number={1},\\n'\n                 'pages={138},\\n'\n                 'abstract={We present a benchmark test suite and an automated '\n                 'machine learning procedure for evaluating supervised machine '\n                 'learning (ML) models for predicting properties of inorganic '\n                 'bulk materials. The test suite, Matbench, is a set of '\n                 '13{\\\\thinspace}ML tasks that range in size from 312 to 132k '\n                 'samples and contain data from 10 density functional '\n                 'theory-derived and experimental sources. Tasks include '\n                 'predicting optical, thermal, electronic, thermodynamic, '\n                 \"tensile, and elastic properties given a material's \"\n                 'composition and/or crystal structure. The reference '\n                 'algorithm, Automatminer, is a highly-extensible, fully '\n                 'automated ML pipeline for predicting materials properties '\n                 'from materials primitives (such as composition and crystal '\n                 'structure) without user intervention or hyperparameter '\n                 'tuning. We test Automatminer on the Matbench test suite and '\n                 'compare its predictive power with state-of-the-art crystal '\n                 'graph neural networks and a traditional descriptor-based '\n                 'Random Forest model. We find Automatminer achieves the best '\n                 'performance on 8 of 13 tasks in the benchmark. We also show '\n                 'our test suite is capable of exposing predictive advantages '\n                 'of each algorithm---namely, that crystal graph methods '\n                 'appear to outperform traditional machine learning methods '\n                 'given {\\\\textasciitilde}104 or greater data points. We '\n                 'encourage evaluating materials ML algorithms on the Matbench '\n                 'benchmark and comparing them against the latest version of '\n                 'Automatminer.},\\n'\n                 'issn={2057-3960},\\n'\n                 'doi={10.1038/s41524-020-00406-3},\\n'\n                 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n'\n                 '}\\n',\n                 '@Article{Petretto2018,\\n'\n                 'author={Petretto, Guido\\n'\n                 'and Dwaraknath, Shyam\\n'\n                 'and P.C. Miranda, Henrique\\n'\n                 'and Winston, Donald\\n'\n                 'and Giantomassi, Matteo\\n'\n                 'and van Setten, Michiel J.\\n'\n                 'and Gonze, Xavier\\n'\n                 'and Persson, Kristin A.\\n'\n                 'and Hautier, Geoffroy\\n'\n                 'and Rignanese, Gian-Marco},\\n'\n                 'title={High-throughput density-functional perturbation '\n                 'theory phonons for inorganic materials},\\n'\n                 'journal={Scientific Data},\\n'\n                 'year={2018},\\n'\n                 'month={May},\\n'\n                 'day={01},\\n'\n                 'publisher={The Author(s)},\\n'\n                 'volume={5},\\n'\n                 'pages={180065},\\n'\n                 'note={Data Descriptor},\\n'\n                 'url={http://dx.doi.org/10.1038/sdata.2018.65}\\n'\n                 '}',\n                 '@misc{petretto_dwaraknath_miranda_winston_giantomassi_rignanese_van '\n                 'setten_gonze_persson_hautier_2018, title={High-throughput '\n                 'Density-Functional Perturbation Theory phonons for inorganic '\n                 'materials}, '\n                 'url={https://figshare.com/collections/High-throughput_Density-Functional_Perturbation_Theory_phonons_for_inorganic_materials/3938023/1}, '\n                 'DOI={10.6084/m9.figshare.c.3938023.v1}, abstractNote={The '\n                 'knowledge of the vibrational properties of a material is of '\n                 'key importance to understand physical phenomena such as '\n                 'thermal conductivity, superconductivity, and '\n                 'ferroelectricity among others. However, detailed '\n                 'experimental phonon spectra are available only for a limited '\n                 'number of materials which hinders the large-scale analysis '\n                 'of vibrational properties and their derived quantities. In '\n                 'this work, we perform ab initio calculations of the full '\n                 'phonon dispersion and vibrational density of states for 1521 '\n                 'semiconductor compounds in the harmonic approximation based '\n                 'on density functional perturbation theory. The data is '\n                 'collected along with derived dielectric and thermodynamic '\n                 'properties. We present the procedure used to obtain the '\n                 'results, the details of the provided database and a '\n                 'validation based on the comparison with experimental data.}, '\n                 'publisher={figshare}, author={Petretto, Guido and '\n                 'Dwaraknath, Shyam and Miranda, Henrique P. C. and Winston, '\n                 'Donald and Giantomassi, Matteo and Rignanese, Gian-Marco and '\n                 'Van Setten, Michiel J. and Gonze, Xavier and Persson, '\n                 'Kristin A and Hautier, Geoffroy}, year={2018}, month={Apr}}'],\n 'columns': {'last phdos peak': 'Target variable. Frequency of the highest '\n                                'frequency optical phonon mode peak, in units '\n                                'of 1/cm; ; may be used as an estimation of '\n                                'dominant longitudinal optical phonon '\n                                'frequency.',\n             'structure': 'Pymatgen Structure of the material.'},\n 'description': 'Matbench v0.1 test dataset for predicting vibration '\n                'properties from crystal structure. Original data retrieved '\n                'from Petretto et al. Original calculations done via ABINIT in '\n                'the harmonic approximation based on density functional '\n                'perturbation theory. Removed entries having a formation '\n                'energy (or energy above the convex hull) more than 150meV. '\n                'For benchmarking w/ nested cross validation, the order of the '\n                'dataset must be identical to the retrieved data; refer to the '\n                'Automatminer/Matbench publication for more details.',\n 'file_type': 'json.gz',\n 'hash': '4db551f21ec5f577e6202725f10e34dfc509aa7df3a6bdaac497da7f6dbbb9b3',\n 'input_type': 'structure',\n 'mad': 323.78696979348734,\n 'n_samples': 1265,\n 'num_entries': 1265,\n 'reference': 'Petretto, G. et al. High-throughput density functional '\n              'perturbation theory phonons for inorganic materials. Sci. Data '\n              '5:180065 doi: 10.1038/sdata.2018.65 (2018).\\n'\n              'Petretto, G. et al. High-throughput density functional '\n              'perturbation theory phonons for inorganic materials. (2018). '\n              'figshare. Collection.',\n 'target': 'last phdos peak',\n 'task_type': 'regression',\n 'unit': 'cm^-1',\n 'url': 'https://ml.materialsproject.org/projects/matbench_phonons.json.gz'}\n</code></pre>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_steels/","title":"matbench_v0.1 matbench_steels","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_steels/#individual-task-leaderboard-for-matbench_steels","title":"Individual Task Leaderboard for <code>matbench_steels</code>","text":"<p>Leaderboard for an individual task. Algorithms shown here may include both general purpose and specialized algorithms (i.e., algorithms which are only valid for a subset of tasks in the benchmark.</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_steels/#leaderboard","title":"Leaderboard","text":"algorithm mean mae std mae mean rmse max max_error TPOT-Mat 79.9468 13.5883 115.3675 522.6191 AutoML-Mat 82.3043 8.8565 114.0577 463.0130 MODNet (v0.1.12) 87.7627 12.2188 144.7722 1121.0504 RF-Regex Steels 90.5896 6.7138 128.0865 505.2967 MODNet (v0.1.10) 96.2139 9.8352 149.9535 931.3261 AMMExpress v2020 97.4929 13.7919 154.0161 1142.9223 RF-SCM/Magpie 103.5125 11.0368 149.3839 1121.1276 CrabNet 107.3160 18.9057 153.0041 576.3912 Darwin 123.2932 13.9542 173.9462 628.9000 gptchem 143.0028 16.9642 218.0282 1368.2000 Dummy 229.7445 9.6958 301.2211 1088.0568"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_steels/#dataset-info","title":"Dataset info","text":""},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_steels/#description","title":"Description","text":"<p>Matbench v0.1 test dataset for predicting steel yield strengths from chemical composition alone. Retrieved from Citrine informatics. Deduplicated. For benchmarking w/ nested cross validation, the order of the dataset must be identical to the retrieved data; refer to the Automatminer/Matbench publication for more details.</p> <p>Number of samples: 312</p> <p>Task type: regression</p> <p>Input type: composition</p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_steels/#dataset-columns","title":"Dataset columns","text":"<ul> <li>composition: Chemical formula.</li> <li>yield strength: Target variable. Experimentally measured steel yield strengths, in MPa.</li> </ul>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_steels/#dataset-reference","title":"Dataset reference","text":"<p><code>https://citrination.com/datasets/153092/</code></p>"},{"location":"Leaderboards%20Per-Task/matbench_v0.1_matbench_steels/#metadata","title":"Metadata","text":"<pre><code>{'bibtex_refs': ['@Article{Dunn2020,\\n'\n                 'author={Dunn, Alexander\\n'\n                 'and Wang, Qi\\n'\n                 'and Ganose, Alex\\n'\n                 'and Dopp, Daniel\\n'\n                 'and Jain, Anubhav},\\n'\n                 'title={Benchmarking materials property prediction methods: '\n                 'the Matbench test set and Automatminer reference '\n                 'algorithm},\\n'\n                 'journal={npj Computational Materials},\\n'\n                 'year={2020},\\n'\n                 'month={Sep},\\n'\n                 'day={15},\\n'\n                 'volume={6},\\n'\n                 'number={1},\\n'\n                 'pages={138},\\n'\n                 'abstract={We present a benchmark test suite and an automated '\n                 'machine learning procedure for evaluating supervised machine '\n                 'learning (ML) models for predicting properties of inorganic '\n                 'bulk materials. The test suite, Matbench, is a set of '\n                 '13{\\\\thinspace}ML tasks that range in size from 312 to 132k '\n                 'samples and contain data from 10 density functional '\n                 'theory-derived and experimental sources. Tasks include '\n                 'predicting optical, thermal, electronic, thermodynamic, '\n                 \"tensile, and elastic properties given a material's \"\n                 'composition and/or crystal structure. The reference '\n                 'algorithm, Automatminer, is a highly-extensible, fully '\n                 'automated ML pipeline for predicting materials properties '\n                 'from materials primitives (such as composition and crystal '\n                 'structure) without user intervention or hyperparameter '\n                 'tuning. We test Automatminer on the Matbench test suite and '\n                 'compare its predictive power with state-of-the-art crystal '\n                 'graph neural networks and a traditional descriptor-based '\n                 'Random Forest model. We find Automatminer achieves the best '\n                 'performance on 8 of 13 tasks in the benchmark. We also show '\n                 'our test suite is capable of exposing predictive advantages '\n                 'of each algorithm---namely, that crystal graph methods '\n                 'appear to outperform traditional machine learning methods '\n                 'given {\\\\textasciitilde}104 or greater data points. We '\n                 'encourage evaluating materials ML algorithms on the Matbench '\n                 'benchmark and comparing them against the latest version of '\n                 'Automatminer.},\\n'\n                 'issn={2057-3960},\\n'\n                 'doi={10.1038/s41524-020-00406-3},\\n'\n                 'url={https://doi.org/10.1038/s41524-020-00406-3}\\n'\n                 '}\\n',\n                 '@misc{Citrine Informatics,\\n'\n                 'title = {Mechanical properties of some steels},\\n'\n                 'howpublished = '\n                 '{\\\\url{https://citrination.com/datasets/153092/},\\n'\n                 '}'],\n 'columns': {'composition': 'Chemical formula.',\n             'yield strength': 'Target variable. Experimentally measured steel '\n                               'yield strengths, in MPa.'},\n 'description': 'Matbench v0.1 test dataset for predicting steel yield '\n                'strengths from chemical composition alone. Retrieved from '\n                'Citrine informatics. Deduplicated. For benchmarking w/ nested '\n                'cross validation, the order of the dataset must be identical '\n                'to the retrieved data; refer to the Automatminer/Matbench '\n                'publication for more details.',\n 'file_type': 'json.gz',\n 'hash': '473bc4957b2ea5e6465aef84bc29bb48ac34db27d69ea4ec5f508745c6fae252',\n 'input_type': 'composition',\n 'mad': 229.37426857330706,\n 'n_samples': 312,\n 'num_entries': 312,\n 'reference': 'https://citrination.com/datasets/153092/',\n 'target': 'yield strength',\n 'task_type': 'regression',\n 'unit': 'MPa',\n 'url': 'https://ml.materialsproject.org/projects/matbench_steels.json.gz'}\n</code></pre>"},{"location":"Reference/MatbenchBenchmark/","title":"MatbenchBenchmark","text":"<p>             Bases: <code>MSONable</code>, <code>MSONable2File</code></p> <p>The core class for benchmarking with Matbench.</p> <p>MatbenchBenchmark is capable of benchmarking and validating arbitrary materials science benchmarks. It is a container class for sets of MatbenchTasks, objects which provide predetermined sets of training/validation and testing data for any algorithm to benchmark with. MatbenchBenchmark can also give summaries of entire complex benchmarks, including access to individual score statistics for each metric.</p> <p>MatbenchBenchmark can run any benchmark as long as it has a corresponding benchmark name key. Matbench v0.1 (\"matbench_v0.1\") is the only benchmark currently configured for use with MatbenchBenchmark.</p> <p>MatbenchBenchmark is capable of running benchmark subsets; for example, only 3 of the 13 available Matbench v0.1 problems.</p> <p>See the documentation for more details.</p> <p>Attributes:</p> Name Type Description <code>benchmark_name</code> <code>str</code> <p>The benchmark name, defaults to the original Matbench v0.1 \"matbench_v0.1\". Should have an associated validation file in order for the MatbenchTasks to work correctly.</p> <code>metadata</code> <code>dict</code> <p>The corresponding metadata file for this benchmark, which defines the basic configuration for each task. See matbench_v0.1_validation for an example. Each dataset has the same required keys in order to work correctly.</p> <code>user_metadata</code> <code>dict</code> <p>Any metadata about the algorithm or benchmark that the user wants to keep as part of the benchmark file.</p> <code>tasks_map</code> <code>{str</code> <p>MatbenchTask}): A mapping of task name to the corresponding MatbenchTask object.</p> <code>&lt;&lt;task_names&gt;&gt;</code> <code>MatbenchTask</code> <p>Access any task obj via MatbenchTask.&lt;&gt;. For example: <p>mb = MatbenchBenchmark() mb.matbench_dielectric</p> <p>&lt;&gt; Source code in <code>matbench/bench.py</code> <pre><code>class MatbenchBenchmark(MSONable, MSONable2File):\n    \"\"\"The core class for benchmarking with Matbench.\n\n    MatbenchBenchmark is capable of benchmarking and validating arbitrary\n    materials science benchmarks. It is a container class for sets of\n    MatbenchTasks, objects which provide predetermined sets of\n    training/validation and testing data for any algorithm to benchmark\n    with. MatbenchBenchmark can also give summaries of entire complex\n    benchmarks, including access to individual score statistics for\n    each metric.\n\n    MatbenchBenchmark can run any benchmark as long as it has a corresponding\n    benchmark name key. Matbench v0.1 (\"matbench_v0.1\") is the only benchmark\n    currently configured for use with MatbenchBenchmark.\n\n    MatbenchBenchmark is capable of running benchmark subsets; for example,\n    only 3 of the 13 available Matbench v0.1 problems.\n\n    See the documentation for more details.\n\n    Attributes:\n        benchmark_name (str): The benchmark name, defaults to the original\n            Matbench v0.1 \"matbench_v0.1\". Should have an associated\n            validation file in order for the MatbenchTasks to work\n            correctly.\n        metadata (dict): The corresponding metadata file for this benchmark,\n            which defines the basic configuration for each task. See\n            matbench_v0.1_validation for an example. Each dataset\n            has the same required keys in order to work correctly.\n        user_metadata (dict): Any metadata about the algorithm or benchmark\n            that the user wants to keep as part of the benchmark file.\n        tasks_map ({str: MatbenchTask}): A mapping of task name to the\n            corresponding MatbenchTask object.\n\n        &lt;&lt;task_names&gt;&gt; (MatbenchTask): Access any task obj via\n            MatbenchTask.&lt;&lt;task_name&gt;&gt;. For example:\n\n            mb = MatbenchBenchmark()\n            mb.matbench_dielectric\n\n            &lt;&lt;MatbenchTask object&gt;&gt;\n    \"\"\"\n\n    # For serialization\n    _VERSION_KEY = \"version\"\n    _BENCHMARK_KEY = \"benchmark_name\"\n    _USER_METADATA_KEY = \"user_metadata\"\n    _TASKS_KEY = \"tasks\"\n    _DATESTAMP_KEY = \"datestamp\"\n    _DATESTAMP_FMT = \"%Y.%m.%d %H:%M.%S\"\n    _HASH_KEY = \"hash\"\n\n    # For class usage\n    ALL_KEY = \"all\"\n\n    def __init__(self, benchmark=MBV01_KEY, autoload=False, subset=None):\n        \"\"\"\n\n        Args:\n            benchmark (str): The name of the benchmark. Only supported benchmark\n                currently is \"matbench_v0.1\", though more will be added in the\n                future.\n            autoload (bool): If True, automatically load the dataset into memory\n                For a full benchmark, this can take some time. If False, you'll\n                need to load each task with .load before you can access the raw\n                data.\n            subset ([str]): A list of task names to use as a subset of a full\n                benchmark. Only the named tasks will be contained in the class.\n                Must correspond to the metadata file defined by the benchmark\n                name.\n        \"\"\"\n\n        if benchmark == MBV01_KEY:\n            self.benchmark_name = MBV01_KEY\n            self.metadata = mbv01_metadata\n        else:\n            raise ValueError(\n                f\"Only '{MBV01_KEY}' available. No other benchmarks defined!\"\n            )\n\n        if subset:\n            not_datasets = [k for k in subset if k not in self.metadata]\n            if not_datasets:\n                raise KeyError(\n                    f\"Some tasks in {subset} are not benchmark=\"\n                    f\"'{self.benchmark_name}' datasets! Remove {not_datasets}.\"\n                )\n            else:\n                available_tasks = subset\n        else:\n            available_tasks = self.metadata.keys()\n\n        self.user_metadata = {}\n        self.tasks_map = RecursiveDotDict()\n\n        for ds in available_tasks:\n            self.tasks_map[ds] = MatbenchTask(\n                ds, autoload=autoload, benchmark=self.benchmark_name\n            )\n\n        logger.info(\n            f\"Initialized benchmark '{benchmark}' \"\n            f\"with {len(available_tasks)} tasks: \\n\"\n            f\"{pprint.pformat(list(available_tasks))}\"\n        )\n\n    def __getattr__(self, item):\n        \"\"\"\n        Enable MatbenchBenchmark.task_name behavior.\n\n        Args:\n            item (str): The name of the attr.\n\n        Returns:\n\n            (object): The attr, if not in the metadata defined by the benchmark\n                If the attr is a task name, returns that MatBenchTask object.\n\n        \"\"\"\n        if item in self.metadata:\n            return self.tasks_map[item]\n        else:\n            return self.__getattribute__(item)\n\n    @classmethod\n    def from_preset(cls, benchmark, preset_name, autoload=False):\n        \"\"\"\n        The following presets are defined for each benchmark:\n\n        benchmark: 'matbench_v0.1':\n\n            - preset: 'structure' - Only structure problems\n            - preset: 'composition' - Only composition problems\n            - preset: 'regression' - Only regression problems\n            - preset: 'classification' - Only classification problems\n            - preset: 'all' - All problems in matbench v0.1\n\n        Args:\n            benchmark (str): Name of the benchmark set you'd like to use. The\n                only supported benchmark set currently is \"matbench_v0.1\"\n            preset_name (str): The name of the preset\n            autoload (bool): If true, automatically loads all the datasets\n                upon instantiation. Be warned; this can take a while.\n\n        Returns:\n            (MatbenchBenchmark object): A ready-to-use MatbenchBenchmark\n                object.\n\n        \"\"\"\n        if benchmark == MBV01_KEY:\n            if preset_name == STRUCTURE_KEY:\n                available_tasks = [\n                    k\n                    for k, v in mbv01_metadata.items()\n                    if v.input_type == STRUCTURE_KEY\n                ]\n            elif preset_name == COMPOSITION_KEY:\n                available_tasks = [\n                    k\n                    for k, v in mbv01_metadata.items()\n                    if v.input_type == COMPOSITION_KEY\n                ]\n            elif preset_name == REG_KEY:\n                available_tasks = [\n                    k for k, v in mbv01_metadata.items() if v.task_type == REG_KEY\n                ]\n            elif preset_name == CLF_KEY:\n                available_tasks = [\n                    k for k, v in mbv01_metadata.items() if v.task_type == CLF_KEY\n                ]\n            elif preset_name == cls.ALL_KEY:\n                available_tasks = [k for k, v in mbv01_metadata.items()]\n            else:\n                valid_keys = [\n                    STRUCTURE_KEY,\n                    COMPOSITION_KEY,\n                    CLF_KEY,\n                    REG_KEY,\n                    cls.ALL_KEY,\n                ]\n                raise ValueError(\n                    f\"Preset name '{preset_name}' not recognized for \"\n                    f\"benchmark '{MBV01_KEY}'! Select from \"\n                    f\"{valid_keys}\"\n                )\n        else:\n            raise ValueError(\n                f\"Only '{MBV01_KEY}' available. No other benchmarks defined!\"\n            )\n\n        return cls(benchmark=benchmark, autoload=autoload, subset=available_tasks)\n\n    @classmethod\n    def from_dict(cls, d):\n        \"\"\"Create a MatbenchBenchmark object from a dictionary.\n\n        Args:\n            d (dict): The benchmark as a dictionary.\n\n        Returns:\n            (MatbenchBenchmark): The benchmark as an object.\n\n        \"\"\"\n        required_keys = [\n            \"@module\",\n            \"@class\",\n            cls._VERSION_KEY,\n            cls._BENCHMARK_KEY,\n            cls._TASKS_KEY,\n            cls._USER_METADATA_KEY,\n            cls._DATESTAMP_KEY,\n            cls._HASH_KEY,\n        ]\n\n        missing_keys = []\n        for k in required_keys:\n            if k not in d:\n                missing_keys.append(k)\n\n        extra_keys = []\n        for k in d:\n            if k not in required_keys:\n                extra_keys.append(k)\n\n        if missing_keys and not extra_keys:\n            raise ValueError(\n                f\"Required keys {missing_keys} for {cls.__class__.__name__} \"\n                f\"not found!\"\n            )\n        elif not missing_keys and extra_keys:\n            raise ValueError(\n                f\"Extra keys {extra_keys} for {cls.__class__.__name__} \" f\"present!\"\n            )\n        elif missing_keys and extra_keys:\n            raise ValueError(\n                f\"Missing required keys {missing_keys} and extra keys \"\n                f\"{extra_keys} present!\"\n            )\n\n        # Check all tasks to make sure their benchmark name is matching in the\n        # benchmark and in the tasks\n        not_matching_bench = []\n        for t_dict in d[cls._TASKS_KEY].values():\n            if t_dict[MatbenchTask._BENCHMARK_KEY] != d[cls._BENCHMARK_KEY]:\n                not_matching_bench.append(t_dict[MatbenchTask._DATASET_KEY])\n        if not_matching_bench:\n            raise ValueError(\n                f\"Tasks {not_matching_bench} do not have a benchmark name \"\n                f\"matching the benchmark ({d[cls._BENCHMARK_KEY]})!\"\n            )\n\n        # Ensure the hash is matching, i.e., the data was not modified after\n        # matbench got done with it\n        m_from_dict = d.pop(cls._HASH_KEY)\n        m = hash_dictionary(d)\n        if m != m_from_dict:\n            raise ValueError(\n                f\"Hash of dictionary does not match it's reported value! {m} \"\n                f\"!= {m_from_dict} . Was the data modified after saving?)\"\n            )\n\n        # Check to see if any tasks have task names not matching their key\n        # names in the benchmark\n        not_matching_tasks = []\n        for task_name, task_info in d[cls._TASKS_KEY].items():\n            key_as_per_task = task_info[MatbenchTask._DATASET_KEY]\n            if task_name != key_as_per_task:\n                not_matching_tasks.append((task_name, key_as_per_task))\n        if not_matching_tasks:\n            raise ValueError(\n                f\"Task names in benchmark and task names in tasks not \"\n                f\"matching: {not_matching_tasks}\"\n            )\n\n        # Warn if versions are not matching\n        if d[cls._VERSION_KEY] != VERSION:\n            logger.warning(\n                f\"Warning! Versions not matching: \"\n                f\"(data file has version {d[cls._VERSION_KEY]}, \"\n                f\"this package is {VERSION}).\"\n            )\n\n        return cls._from_args(\n            benchmark_name=d[cls._BENCHMARK_KEY],\n            tasks_dict=d[cls._TASKS_KEY],\n            user_metadata=d[cls._USER_METADATA_KEY],\n        )\n\n    @classmethod\n    def _from_args(cls, benchmark_name, tasks_dict, user_metadata):\n        \"\"\"Create a MatbenchBenchmark object from arguments\n\n        Args:\n            benchmark_name (str): name of the benchmark\n            tasks_dict (dict): formatted dict of task data\n            user_metadata (dict): freeform user metadata\n\n        Returns:\n            (MatbenchBenchmark)\n        \"\"\"\n        subset = list(tasks_dict.keys())\n        obj = cls(benchmark=benchmark_name, autoload=False, subset=subset)\n        obj.tasks_map = RecursiveDotDict(\n            {\n                t_name: MatbenchTask.from_dict(t_dict)\n                for t_name, t_dict in tasks_dict.items()\n            }\n        )\n\n        logger.warning(\n            \"To add new data to this benchmark, the \"\n            \"benchmark must be loaded with .load(). Alternatively, \"\n            \"load individual tasks with MatbenchTask.load().\"\n        )\n\n        # MatbenchTask automatically validates files during its from_dict\n        obj.user_metadata = user_metadata\n\n        logger.debug(f\"Successfully converted dict/args to '{cls.__name__}'.\")\n\n        return obj\n\n    def _determine_completeness(self, completeness_type):\n        \"\"\"Determine the completeness of this benchmark.\n\n        Completeness means the tasks are included (but not\n        necessarily recorded yet) in the benchmark.\n\n        Supported completeness types are:\n        - \"all\": All tasks are included\n        - \"composition\": All composition tasks are included\n        - \"structure\": All structure tasks are included\n        - \"regression\": All regression problems\n        - \"classification\": All classification problems\n\n        Args:\n            completeness_type (str): One of the above completeness\n                types.\n\n        Returns:\n            (bool) True if this benchmark object is complete\n                with respect to the completeness type.\n\n        \"\"\"\n        if completeness_type == self.ALL_KEY:\n            required_tasks = list(self.metadata.keys())\n        elif completeness_type in (COMPOSITION_KEY, STRUCTURE_KEY):\n            required_tasks = [\n                k\n                for k, v in self.metadata.items()\n                if v.input_type == completeness_type\n            ]\n        elif completeness_type in (REG_KEY, CLF_KEY):\n            required_tasks = [\n                k\n                for k, v in self.metadata.items()\n                if v.task_type == completeness_type\n            ]\n        else:\n            allowed_completeness_types = [\n                self.ALL_KEY,\n                COMPOSITION_KEY,\n                STRUCTURE_KEY,\n                REG_KEY,\n                CLF_KEY,\n            ]\n            raise ValueError(\n                \"Only supported completeness types are \"\n                f\"{allowed_completeness_types}\"\n            )\n\n        for task in required_tasks:\n            if task not in self.tasks_map:\n                return False\n        else:\n            return True\n\n    def as_dict(self):\n        \"\"\"Overridden from MSONable.as_dict, get dict repr of this obj\n\n        Returns:\n            d (dict): the object as a dictionary.\n\n        \"\"\"\n        tasksd = {mbt.dataset_name: mbt.as_dict() for mbt in self.tasks}\n        tasksd_jsonable = immutify_dictionary(tasksd)\n\n        d = {\n            \"@module\": self.__class__.__module__,\n            \"@class\": self.__class__.__name__,\n            self._VERSION_KEY: VERSION,\n            self._TASKS_KEY: tasksd_jsonable,\n            self._USER_METADATA_KEY: self.user_metadata,\n            self._BENCHMARK_KEY: self.benchmark_name,\n            self._DATESTAMP_KEY: datetime.datetime.utcnow().strftime(\n                self._DATESTAMP_FMT\n            ),\n        }\n\n        # to obtain a hash for this benchmark, immutify the dictionary\n        # and then stringify it\n        d[self._HASH_KEY] = hash_dictionary(d)\n        logger.debug(\n            f\"Successfully converted {self.__class__.__name__} to dictionary.\"\n        )\n        return d\n\n    def get_info(self):\n        \"\"\"Log info about the benchmark to the respective logging handlers.\n\n        Returns:\n            (NoneType): Output is sent to logger.\n        \"\"\"\n        logger.info(self.info)\n\n    def add_metadata(self, metadata):\n        \"\"\"Add freeform information about this run to the object\n        (and subsequent json), accessible thru the\n        'user_metadata' attr.\n\n\n        All keys must be strings.\n\n        All values must be either:\n            a. a numpy ndarray\n            b. python native types, such as bools, floats, ints, strs\n            c. a pandas series\n            d. a list/tuple of python native types (bools, floats, ints)\n\n            OR\n\n            e. A dictionary where all keys are strs and all values\n               are one of a, b, c, d, or e (recursive).\n\n        Args:\n            metadata (dict): Metadata about the algorithm being\n                run on this benchmark.\n\n        Returns:\n            (NoneType): None. Logger provides information.\n        \"\"\"\n        # Use logging here so bad metadata addition does not\n        # ruin an entire run...\n        if not isinstance(metadata, dict):\n            logger.critical(\n                f\"User metadata must be reducible to dict format, \"\n                f\"not type({type(metadata)})\"\n            )\n            logger.info(\"User metadata not added.\")\n\n        else:\n            if self.user_metadata:\n                logger.warning(\"User metadata already exists! Overwriting...\")\n\n            self.user_metadata = immutify_dictionary(metadata)\n            logger.info(\"User metadata added successfully!\")\n\n    def load(self):\n        \"\"\"Load all tasks in this benchmark.\n        Returns:\n            (NoneType): Datasets are kept in attributes.\n        \"\"\"\n        for t in self.tasks:\n            t.load()\n\n    def validate(self):\n        \"\"\"Run validation on each task in this benchmark.\n\n        Returns:\n            ({str: str}): dict of errors, if they exist\n\n        \"\"\"\n        errors = {}\n        for t, t_obj in self.tasks_map.items():\n            try:\n                t_obj.validate()\n            except BaseException:\n                errors[t] = traceback.format_exc()\n        return errors\n\n    @property\n    def tasks(self):\n        \"\"\"Return the tasks as a list.\n\n        Returns:\n            ([MatbenchTask]): A list of matbench tasks in this benchmark\n        \"\"\"\n        return self.tasks_map.values()\n\n    @property\n    def scores(self):\n        \"\"\"Get all score metrics for all tasks as a dictionary.\n\n        Returns:\n            (RecursiveDotDict): A nested dictionary-like object of scores\n                for each task.\n\n        \"\"\"\n        return RecursiveDotDict({t.dataset_name: t.scores for t in self.tasks})\n\n    @property\n    def info(self):\n        \"\"\"Get a formatted string of info about this benchmark and its current\n        state.\n\n        Returns:\n            s (str): A formatted string describing this benchmark's state.\n\n        \"\"\"\n\n        complete = self.is_complete\n        recorded = self.is_recorded\n        valid = self.is_valid\n\n        s = \"\"\n        s += (\n            f\"\\nMatbench package {VERSION} running benchmark \"\n            f\"'{self.benchmark_name}'\"\n        )\n        s += f\"\\n\\tis complete: {complete}\"\n        s += f\"\\n\\tis recorded: {recorded}\"\n        s += f\"\\n\\tis valid: {valid}\"\n\n        if not recorded:\n            s += (\n                \"\\n\\n Benchmark is not fully recorded; limited information \" \"shown.\"\n            )\n        if not valid:\n            s += \"\\n\\n Benchmark is not valid; limited information shown.\"\n\n        if not valid or not recorded:\n            s += \"\\n\\nTasks:\"\n            for t in self.tasks_map.values():\n                s += f\"\\n\\t- '{t.dataset_name}: recorded={t.all_folds_recorded}\"\n\n        if valid and recorded:\n            s += \"\\n\\nResults:\"\n            for t in self.tasks:\n\n                if t.metadata.task_type == REG_KEY:\n                    score_text = (\n                        f\"MAE mean: \" f\"{self.scores[t.dataset_name].mae.mean}\"\n                    )\n                else:\n                    score_text = (\n                        f\"ROCAUC mean: \" f\"{self.scores[t.dataset_name].rocauc.mean}\"\n                    )\n                s += f\"\\n\\t- '{t.dataset_name}' {score_text}\"\n\n        return s\n\n    @property\n    def is_complete(self):\n        \"\"\"Determine if all available tasks are included in this benchmark.\n\n        For matbench v0.1, this means all 13 tasks are in the benchmark.\n\n        Returns:\n            (bool): Whether benchmark is entirely complete.\n\n        \"\"\"\n        return self._determine_completeness(completeness_type=self.ALL_KEY)\n\n    @property\n    def is_composition_complete(self):\n        \"\"\"Determine if all composition tasks for this benchmark are included\n\n        Returns:\n            (bool): Whether benchmark is composition complete.\n        \"\"\"\n        return self._determine_completeness(completeness_type=COMPOSITION_KEY)\n\n    @property\n    def is_structure_complete(self):\n        \"\"\"Determine if all structure tasks for this benchmark are included\n\n        Returns:\n            (bool): Whether benchmark is structure complete.\n        \"\"\"\n        return self._determine_completeness(completeness_type=STRUCTURE_KEY)\n\n    @property\n    def is_regression_complete(self):\n        \"\"\"Determine if all regression tasks for this benchmark are included\n\n        Returns:\n            (bool): Whether benchmark is regression complete.\n        \"\"\"\n        return self._determine_completeness(completeness_type=REG_KEY)\n\n    @property\n    def is_classification_complete(self):\n        \"\"\"Determine if all classification tasks for this benchmark are included\n\n        Returns:\n            (bool): Whether benchmark is classification complete.\n        \"\"\"\n        return self._determine_completeness(completeness_type=CLF_KEY)\n\n    @property\n    def is_recorded(self):\n        \"\"\"All tasks in this benchmark (whether or not it includes all tasks in\n        the benchmark set) are recorded.\n\n        Returns:\n            (bool): True if all tasks (even if only a subset of all matbench)\n            for this benchmark are recorded.\n\n        \"\"\"\n        return all([t.all_folds_recorded for t in self.tasks_map.values()])\n\n    @property\n    def is_valid(self):\n        \"\"\"Checks all tasks are recorded and valid, as per each task's\n        validation procedure.\n\n        Can take some time, especially if the tasks are not already\n        loaded into memory.\n\n        Returns:\n            (bool): True if all tasks are valid\n        \"\"\"\n        errors = self.validate()\n        if errors:\n            formatted_errors = pprint.pformat(errors)\n            logger.critical(\n                f\"Benchmark has errors! \" f\"Errors:\\n {formatted_errors}\"\n            )\n            return False\n        else:\n            return True\n</code></pre>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.info","title":"<code>info</code>  <code>property</code>","text":"<p>Get a formatted string of info about this benchmark and its current state.</p> <p>Returns:</p> Name Type Description <code>s</code> <code>str</code> <p>A formatted string describing this benchmark's state.</p>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.is_classification_complete","title":"<code>is_classification_complete</code>  <code>property</code>","text":"<p>Determine if all classification tasks for this benchmark are included</p> <p>Returns:</p> Type Description <code>bool</code> <p>Whether benchmark is classification complete.</p>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.is_complete","title":"<code>is_complete</code>  <code>property</code>","text":"<p>Determine if all available tasks are included in this benchmark.</p> <p>For matbench v0.1, this means all 13 tasks are in the benchmark.</p> <p>Returns:</p> Type Description <code>bool</code> <p>Whether benchmark is entirely complete.</p>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.is_composition_complete","title":"<code>is_composition_complete</code>  <code>property</code>","text":"<p>Determine if all composition tasks for this benchmark are included</p> <p>Returns:</p> Type Description <code>bool</code> <p>Whether benchmark is composition complete.</p>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.is_recorded","title":"<code>is_recorded</code>  <code>property</code>","text":"<p>All tasks in this benchmark (whether or not it includes all tasks in the benchmark set) are recorded.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if all tasks (even if only a subset of all matbench)</p> <p>for this benchmark are recorded.</p>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.is_regression_complete","title":"<code>is_regression_complete</code>  <code>property</code>","text":"<p>Determine if all regression tasks for this benchmark are included</p> <p>Returns:</p> Type Description <code>bool</code> <p>Whether benchmark is regression complete.</p>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.is_structure_complete","title":"<code>is_structure_complete</code>  <code>property</code>","text":"<p>Determine if all structure tasks for this benchmark are included</p> <p>Returns:</p> Type Description <code>bool</code> <p>Whether benchmark is structure complete.</p>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.is_valid","title":"<code>is_valid</code>  <code>property</code>","text":"<p>Checks all tasks are recorded and valid, as per each task's validation procedure.</p> <p>Can take some time, especially if the tasks are not already loaded into memory.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if all tasks are valid</p>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.scores","title":"<code>scores</code>  <code>property</code>","text":"<p>Get all score metrics for all tasks as a dictionary.</p> <p>Returns:</p> Type Description <code>RecursiveDotDict</code> <p>A nested dictionary-like object of scores for each task.</p>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.tasks","title":"<code>tasks</code>  <code>property</code>","text":"<p>Return the tasks as a list.</p> <p>Returns:</p> Type Description <code>[MatbenchTask]</code> <p>A list of matbench tasks in this benchmark</p>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.__getattr__","title":"<code>__getattr__(item)</code>","text":"<p>Enable MatbenchBenchmark.task_name behavior.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>str</code> <p>The name of the attr.</p> required <pre><code>(object): The attr, if not in the metadata defined by the benchmark\n    If the attr is a task name, returns that MatBenchTask object.\n</code></pre> Source code in <code>matbench/bench.py</code> <pre><code>def __getattr__(self, item):\n    \"\"\"\n    Enable MatbenchBenchmark.task_name behavior.\n\n    Args:\n        item (str): The name of the attr.\n\n    Returns:\n\n        (object): The attr, if not in the metadata defined by the benchmark\n            If the attr is a task name, returns that MatBenchTask object.\n\n    \"\"\"\n    if item in self.metadata:\n        return self.tasks_map[item]\n    else:\n        return self.__getattribute__(item)\n</code></pre>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.__init__","title":"<code>__init__(benchmark=MBV01_KEY, autoload=False, subset=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>benchmark</code> <code>str</code> <p>The name of the benchmark. Only supported benchmark currently is \"matbench_v0.1\", though more will be added in the future.</p> <code>MBV01_KEY</code> <code>autoload</code> <code>bool</code> <p>If True, automatically load the dataset into memory For a full benchmark, this can take some time. If False, you'll need to load each task with .load before you can access the raw data.</p> <code>False</code> <code>subset</code> <code>[str]</code> <p>A list of task names to use as a subset of a full benchmark. Only the named tasks will be contained in the class. Must correspond to the metadata file defined by the benchmark name.</p> <code>None</code> Source code in <code>matbench/bench.py</code> <pre><code>def __init__(self, benchmark=MBV01_KEY, autoload=False, subset=None):\n    \"\"\"\n\n    Args:\n        benchmark (str): The name of the benchmark. Only supported benchmark\n            currently is \"matbench_v0.1\", though more will be added in the\n            future.\n        autoload (bool): If True, automatically load the dataset into memory\n            For a full benchmark, this can take some time. If False, you'll\n            need to load each task with .load before you can access the raw\n            data.\n        subset ([str]): A list of task names to use as a subset of a full\n            benchmark. Only the named tasks will be contained in the class.\n            Must correspond to the metadata file defined by the benchmark\n            name.\n    \"\"\"\n\n    if benchmark == MBV01_KEY:\n        self.benchmark_name = MBV01_KEY\n        self.metadata = mbv01_metadata\n    else:\n        raise ValueError(\n            f\"Only '{MBV01_KEY}' available. No other benchmarks defined!\"\n        )\n\n    if subset:\n        not_datasets = [k for k in subset if k not in self.metadata]\n        if not_datasets:\n            raise KeyError(\n                f\"Some tasks in {subset} are not benchmark=\"\n                f\"'{self.benchmark_name}' datasets! Remove {not_datasets}.\"\n            )\n        else:\n            available_tasks = subset\n    else:\n        available_tasks = self.metadata.keys()\n\n    self.user_metadata = {}\n    self.tasks_map = RecursiveDotDict()\n\n    for ds in available_tasks:\n        self.tasks_map[ds] = MatbenchTask(\n            ds, autoload=autoload, benchmark=self.benchmark_name\n        )\n\n    logger.info(\n        f\"Initialized benchmark '{benchmark}' \"\n        f\"with {len(available_tasks)} tasks: \\n\"\n        f\"{pprint.pformat(list(available_tasks))}\"\n    )\n</code></pre>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.add_metadata","title":"<code>add_metadata(metadata)</code>","text":"<p>Add freeform information about this run to the object (and subsequent json), accessible thru the 'user_metadata' attr.</p> <p>All keys must be strings.</p> All values must be either <p>a. a numpy ndarray b. python native types, such as bools, floats, ints, strs c. a pandas series d. a list/tuple of python native types (bools, floats, ints)</p> <p>OR</p> <p>e. A dictionary where all keys are strs and all values    are one of a, b, c, d, or e (recursive).</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>dict</code> <p>Metadata about the algorithm being run on this benchmark.</p> required <p>Returns:</p> Type Description <code>NoneType</code> <p>None. Logger provides information.</p> Source code in <code>matbench/bench.py</code> <pre><code>def add_metadata(self, metadata):\n    \"\"\"Add freeform information about this run to the object\n    (and subsequent json), accessible thru the\n    'user_metadata' attr.\n\n\n    All keys must be strings.\n\n    All values must be either:\n        a. a numpy ndarray\n        b. python native types, such as bools, floats, ints, strs\n        c. a pandas series\n        d. a list/tuple of python native types (bools, floats, ints)\n\n        OR\n\n        e. A dictionary where all keys are strs and all values\n           are one of a, b, c, d, or e (recursive).\n\n    Args:\n        metadata (dict): Metadata about the algorithm being\n            run on this benchmark.\n\n    Returns:\n        (NoneType): None. Logger provides information.\n    \"\"\"\n    # Use logging here so bad metadata addition does not\n    # ruin an entire run...\n    if not isinstance(metadata, dict):\n        logger.critical(\n            f\"User metadata must be reducible to dict format, \"\n            f\"not type({type(metadata)})\"\n        )\n        logger.info(\"User metadata not added.\")\n\n    else:\n        if self.user_metadata:\n            logger.warning(\"User metadata already exists! Overwriting...\")\n\n        self.user_metadata = immutify_dictionary(metadata)\n        logger.info(\"User metadata added successfully!\")\n</code></pre>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.as_dict","title":"<code>as_dict()</code>","text":"<p>Overridden from MSONable.as_dict, get dict repr of this obj</p> <p>Returns:</p> Name Type Description <code>d</code> <code>dict</code> <p>the object as a dictionary.</p> Source code in <code>matbench/bench.py</code> <pre><code>def as_dict(self):\n    \"\"\"Overridden from MSONable.as_dict, get dict repr of this obj\n\n    Returns:\n        d (dict): the object as a dictionary.\n\n    \"\"\"\n    tasksd = {mbt.dataset_name: mbt.as_dict() for mbt in self.tasks}\n    tasksd_jsonable = immutify_dictionary(tasksd)\n\n    d = {\n        \"@module\": self.__class__.__module__,\n        \"@class\": self.__class__.__name__,\n        self._VERSION_KEY: VERSION,\n        self._TASKS_KEY: tasksd_jsonable,\n        self._USER_METADATA_KEY: self.user_metadata,\n        self._BENCHMARK_KEY: self.benchmark_name,\n        self._DATESTAMP_KEY: datetime.datetime.utcnow().strftime(\n            self._DATESTAMP_FMT\n        ),\n    }\n\n    # to obtain a hash for this benchmark, immutify the dictionary\n    # and then stringify it\n    d[self._HASH_KEY] = hash_dictionary(d)\n    logger.debug(\n        f\"Successfully converted {self.__class__.__name__} to dictionary.\"\n    )\n    return d\n</code></pre>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.from_dict","title":"<code>from_dict(d)</code>  <code>classmethod</code>","text":"<p>Create a MatbenchBenchmark object from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>dict</code> <p>The benchmark as a dictionary.</p> required <p>Returns:</p> Type Description <code>MatbenchBenchmark</code> <p>The benchmark as an object.</p> Source code in <code>matbench/bench.py</code> <pre><code>@classmethod\ndef from_dict(cls, d):\n    \"\"\"Create a MatbenchBenchmark object from a dictionary.\n\n    Args:\n        d (dict): The benchmark as a dictionary.\n\n    Returns:\n        (MatbenchBenchmark): The benchmark as an object.\n\n    \"\"\"\n    required_keys = [\n        \"@module\",\n        \"@class\",\n        cls._VERSION_KEY,\n        cls._BENCHMARK_KEY,\n        cls._TASKS_KEY,\n        cls._USER_METADATA_KEY,\n        cls._DATESTAMP_KEY,\n        cls._HASH_KEY,\n    ]\n\n    missing_keys = []\n    for k in required_keys:\n        if k not in d:\n            missing_keys.append(k)\n\n    extra_keys = []\n    for k in d:\n        if k not in required_keys:\n            extra_keys.append(k)\n\n    if missing_keys and not extra_keys:\n        raise ValueError(\n            f\"Required keys {missing_keys} for {cls.__class__.__name__} \"\n            f\"not found!\"\n        )\n    elif not missing_keys and extra_keys:\n        raise ValueError(\n            f\"Extra keys {extra_keys} for {cls.__class__.__name__} \" f\"present!\"\n        )\n    elif missing_keys and extra_keys:\n        raise ValueError(\n            f\"Missing required keys {missing_keys} and extra keys \"\n            f\"{extra_keys} present!\"\n        )\n\n    # Check all tasks to make sure their benchmark name is matching in the\n    # benchmark and in the tasks\n    not_matching_bench = []\n    for t_dict in d[cls._TASKS_KEY].values():\n        if t_dict[MatbenchTask._BENCHMARK_KEY] != d[cls._BENCHMARK_KEY]:\n            not_matching_bench.append(t_dict[MatbenchTask._DATASET_KEY])\n    if not_matching_bench:\n        raise ValueError(\n            f\"Tasks {not_matching_bench} do not have a benchmark name \"\n            f\"matching the benchmark ({d[cls._BENCHMARK_KEY]})!\"\n        )\n\n    # Ensure the hash is matching, i.e., the data was not modified after\n    # matbench got done with it\n    m_from_dict = d.pop(cls._HASH_KEY)\n    m = hash_dictionary(d)\n    if m != m_from_dict:\n        raise ValueError(\n            f\"Hash of dictionary does not match it's reported value! {m} \"\n            f\"!= {m_from_dict} . Was the data modified after saving?)\"\n        )\n\n    # Check to see if any tasks have task names not matching their key\n    # names in the benchmark\n    not_matching_tasks = []\n    for task_name, task_info in d[cls._TASKS_KEY].items():\n        key_as_per_task = task_info[MatbenchTask._DATASET_KEY]\n        if task_name != key_as_per_task:\n            not_matching_tasks.append((task_name, key_as_per_task))\n    if not_matching_tasks:\n        raise ValueError(\n            f\"Task names in benchmark and task names in tasks not \"\n            f\"matching: {not_matching_tasks}\"\n        )\n\n    # Warn if versions are not matching\n    if d[cls._VERSION_KEY] != VERSION:\n        logger.warning(\n            f\"Warning! Versions not matching: \"\n            f\"(data file has version {d[cls._VERSION_KEY]}, \"\n            f\"this package is {VERSION}).\"\n        )\n\n    return cls._from_args(\n        benchmark_name=d[cls._BENCHMARK_KEY],\n        tasks_dict=d[cls._TASKS_KEY],\n        user_metadata=d[cls._USER_METADATA_KEY],\n    )\n</code></pre>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.from_preset","title":"<code>from_preset(benchmark, preset_name, autoload=False)</code>  <code>classmethod</code>","text":"<p>The following presets are defined for each benchmark:</p> <p>benchmark: 'matbench_v0.1':</p> <pre><code>- preset: 'structure' - Only structure problems\n- preset: 'composition' - Only composition problems\n- preset: 'regression' - Only regression problems\n- preset: 'classification' - Only classification problems\n- preset: 'all' - All problems in matbench v0.1\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>benchmark</code> <code>str</code> <p>Name of the benchmark set you'd like to use. The only supported benchmark set currently is \"matbench_v0.1\"</p> required <code>preset_name</code> <code>str</code> <p>The name of the preset</p> required <code>autoload</code> <code>bool</code> <p>If true, automatically loads all the datasets upon instantiation. Be warned; this can take a while.</p> <code>False</code> <p>Returns:</p> Type Description <code>MatbenchBenchmark object</code> <p>A ready-to-use MatbenchBenchmark object.</p> Source code in <code>matbench/bench.py</code> <pre><code>@classmethod\ndef from_preset(cls, benchmark, preset_name, autoload=False):\n    \"\"\"\n    The following presets are defined for each benchmark:\n\n    benchmark: 'matbench_v0.1':\n\n        - preset: 'structure' - Only structure problems\n        - preset: 'composition' - Only composition problems\n        - preset: 'regression' - Only regression problems\n        - preset: 'classification' - Only classification problems\n        - preset: 'all' - All problems in matbench v0.1\n\n    Args:\n        benchmark (str): Name of the benchmark set you'd like to use. The\n            only supported benchmark set currently is \"matbench_v0.1\"\n        preset_name (str): The name of the preset\n        autoload (bool): If true, automatically loads all the datasets\n            upon instantiation. Be warned; this can take a while.\n\n    Returns:\n        (MatbenchBenchmark object): A ready-to-use MatbenchBenchmark\n            object.\n\n    \"\"\"\n    if benchmark == MBV01_KEY:\n        if preset_name == STRUCTURE_KEY:\n            available_tasks = [\n                k\n                for k, v in mbv01_metadata.items()\n                if v.input_type == STRUCTURE_KEY\n            ]\n        elif preset_name == COMPOSITION_KEY:\n            available_tasks = [\n                k\n                for k, v in mbv01_metadata.items()\n                if v.input_type == COMPOSITION_KEY\n            ]\n        elif preset_name == REG_KEY:\n            available_tasks = [\n                k for k, v in mbv01_metadata.items() if v.task_type == REG_KEY\n            ]\n        elif preset_name == CLF_KEY:\n            available_tasks = [\n                k for k, v in mbv01_metadata.items() if v.task_type == CLF_KEY\n            ]\n        elif preset_name == cls.ALL_KEY:\n            available_tasks = [k for k, v in mbv01_metadata.items()]\n        else:\n            valid_keys = [\n                STRUCTURE_KEY,\n                COMPOSITION_KEY,\n                CLF_KEY,\n                REG_KEY,\n                cls.ALL_KEY,\n            ]\n            raise ValueError(\n                f\"Preset name '{preset_name}' not recognized for \"\n                f\"benchmark '{MBV01_KEY}'! Select from \"\n                f\"{valid_keys}\"\n            )\n    else:\n        raise ValueError(\n            f\"Only '{MBV01_KEY}' available. No other benchmarks defined!\"\n        )\n\n    return cls(benchmark=benchmark, autoload=autoload, subset=available_tasks)\n</code></pre>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.get_info","title":"<code>get_info()</code>","text":"<p>Log info about the benchmark to the respective logging handlers.</p> <p>Returns:</p> Type Description <code>NoneType</code> <p>Output is sent to logger.</p> Source code in <code>matbench/bench.py</code> <pre><code>def get_info(self):\n    \"\"\"Log info about the benchmark to the respective logging handlers.\n\n    Returns:\n        (NoneType): Output is sent to logger.\n    \"\"\"\n    logger.info(self.info)\n</code></pre>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.load","title":"<code>load()</code>","text":"<p>Load all tasks in this benchmark. Returns:     (NoneType): Datasets are kept in attributes.</p> Source code in <code>matbench/bench.py</code> <pre><code>def load(self):\n    \"\"\"Load all tasks in this benchmark.\n    Returns:\n        (NoneType): Datasets are kept in attributes.\n    \"\"\"\n    for t in self.tasks:\n        t.load()\n</code></pre>"},{"location":"Reference/MatbenchBenchmark/#matbench.bench.MatbenchBenchmark.validate","title":"<code>validate()</code>","text":"<p>Run validation on each task in this benchmark.</p> <p>Returns:</p> Type Description <code>{str: str}</code> <p>dict of errors, if they exist</p> Source code in <code>matbench/bench.py</code> <pre><code>def validate(self):\n    \"\"\"Run validation on each task in this benchmark.\n\n    Returns:\n        ({str: str}): dict of errors, if they exist\n\n    \"\"\"\n    errors = {}\n    for t, t_obj in self.tasks_map.items():\n        try:\n            t_obj.validate()\n        except BaseException:\n            errors[t] = traceback.format_exc()\n    return errors\n</code></pre>"},{"location":"Reference/MatbenchTask/","title":"MatbenchTask","text":"<p>             Bases: <code>MSONable</code>, <code>MSONable2File</code></p> <p>The core interface for running a Matbench task and recording its results.</p> <p>MatbenchTask handles creating training/validation and testing sets, as well as recording and managing all data in a consistent fashion. MatbenchTask also validates data according to the specifications in the validation file.</p> <p>MatbenchTasks have a few core methods:</p> <ul> <li>MatbenchTask.get_train_and_val_data: Get nested cross validation data to     be used for all training and validation.</li> <li>MatbenchTask.get_test_data: Get test data for nested cross validation.</li> <li>MatbenchTask.record: Record your predicted results for the test data.</li> <li>MatbenchTask.validate: Check to make sure the data you recorded for this     task is valid.</li> </ul> <p>You can iterate through the folds of a matbench task using .folds and the .get_*_data methods.</p> <p>You can load the results of a task without having to load large datasets themselves. However, to get training and testing data, you must load the datasets. Tasks loaded from files do not automatically load the dataset into memory; to load a dataset into memory, use MatbenchTask.load().</p> <p>See the full documentation online for more info and tutorials on using MatbenchTask.</p> <p>Attributes:</p> Name Type Description <code>benchmark_name</code> <code>str</code> <p>The name of the benchmark this task belongs to.</p> <code>df</code> <code>DataFrame</code> <p>the dataframe of the dataset for this task</p> <code>info</code> <code>str</code> <p>Info about this dataset</p> <code>metadata</code> <code>RecursiveDotDict</code> <p>all metadata about this dataset</p> <code>validation</code> <code>RecursiveDotDict</code> <p>The validation specification for this task, including the training and testing splits for each fold.</p> <code>folds_keys</code> <code>[str]</code> <p>Keys of folds, fold_i for the ith fold.</p> <code>folds_nums</code> <code>[int]</code> <p>Values of folds, i for the ith fold.</p> <code>folds_map</code> <code>{int</code> <p>str}): Mapping of folds_nums to folds_keys</p> <code>folds</code> <code>[int]</code> <p>Alias for folds_nums</p> <code>results</code> <code>RecursiveDotDict</code> <p>all raw results in dict-like form.</p> Source code in <code>matbench/task.py</code> <pre><code>class MatbenchTask(MSONable, MSONable2File):\n    \"\"\"The core interface for running a Matbench task and recording its results.\n\n    MatbenchTask handles creating training/validation and testing sets, as\n    well as recording and managing all data in a consistent fashion.\n    MatbenchTask also validates data according to the specifications in the\n    validation file.\n\n    MatbenchTasks have a few core methods:\n\n    - MatbenchTask.get_train_and_val_data: Get nested cross validation data to\n        be used for all training and validation.\n    - MatbenchTask.get_test_data: Get test data for nested cross validation.\n    - MatbenchTask.record: Record your predicted results for the test data.\n    - MatbenchTask.validate: Check to make sure the data you recorded for this\n        task is valid.\n\n    You can iterate through the folds of a matbench task using .folds and\n    the .get_*_data methods.\n\n    You can load the results of a task without having to load large\n    datasets themselves. However, to get training and testing data,\n    you must load the datasets. Tasks loaded from files do not\n    automatically load the dataset into memory; to load a dataset into memory,\n    use MatbenchTask.load().\n\n    See the full documentation online for more info and tutorials on\n    using MatbenchTask.\n\n    Attributes:\n        benchmark_name (str): The name of the benchmark this task belongs to.\n        df (pd.DataFrame): the dataframe of the dataset for this task\n        info (str): Info about this dataset\n        metadata (RecursiveDotDict): all metadata about this dataset\n        validation (RecursiveDotDict): The validation specification for this\n            task, including the training and testing splits for each fold.\n        folds_keys ([str]): Keys of folds, fold_i for the ith fold.\n        folds_nums ([int]): Values of folds, i for the ith fold.\n        folds_map ({int: str}): Mapping of folds_nums to folds_keys\n        folds ([int]): Alias for folds_nums\n        results (RecursiveDotDict): all raw results in dict-like form.\n    \"\"\"\n\n    _RESULTS_KEY = \"results\"\n    _BENCHMARK_KEY = \"benchmark_name\"\n    _DATASET_KEY = \"dataset_name\"\n    _DATA_KEY = \"data\"\n    _UNCERTAINTY_KEY = \"uncertainty\"\n    _PARAMS_KEY = \"parameters\"\n    _SCORES_KEY = \"scores\"\n\n    def __init__(self, dataset_name, autoload=True, benchmark=MBV01_KEY):\n        \"\"\"\n        Args:\n            dataset_name (str): Name of the task. Must belong to the benchmark\n                given in the 'benchmark' argument.\n            autoload (bool): If True, will load the benchmark's raw data. This\n                includes deserializing many large structures for some datasets,\n                so loading make take some time. If False, you will need to\n                run .load() before running .get_*_data() methods.\n            benchmark (str): Name of the benchmark this task belongs to.\n        \"\"\"\n        self.dataset_name = dataset_name\n        self.df = load(self.dataset_name) if autoload else None\n        self.info = get_all_dataset_info(dataset_name)\n\n        # define all static data needed for this task\n        # including citations, data size, as well as specific validation splits\n\n        if benchmark == MBV01_KEY:\n            self.benchmark_name = MBV01_KEY\n            self.metadata = mbv01_metadata[dataset_name]\n            self.validation = mbv01_validation.splits[dataset_name]\n        else:\n            raise ValueError(\n                f\"Only {MBV01_KEY} available. No other benchmarks defined!\"\n            )\n\n        # keeping track of folds\n        self.folds_keys = list(self.validation.keys())\n        self.folds_nums = list(range(len(self.folds_keys)))\n        self.folds_map = dict(zip(self.folds_nums, self.folds_keys))\n\n        # Alias for ease of use\n        self.folds = self.folds_nums\n        self.results = RecursiveDotDict({})\n\n    def __repr__(self) -&gt; str:\n        keys = \"input_type mad n_samples target task_type unit\".split()\n\n        md_str = \",\\n  \".join(f\"{k}={self.metadata[k]}\" for k in keys)\n\n        return (\n            f\"{type(self).__name__}(\\n  dataset_name={self.dataset_name},\\n  version\"\n            f\"={self.benchmark_name.replace('matbench_v', '')},\\n  {md_str},\\n)\"\n        )\n\n    def _get_data_from_df(self, ids, as_type):\n        \"\"\"Private function to get fold data from the task dataframe.\n\n        Args:\n            ids (list-like): List of string indices to grab from the df.\n            as_type (str): either \"df\" or \"tuple\". If \"df\", returns the\n                data as a subset of the task df. If \"tuple\", returns\n                list-likes of the inputs and outputs as a 2-tuple.\n\n        Returns:\n            (pd.DataFrame or (list-like, list-like))\n\n        \"\"\"\n        relevant_df = self.df.loc[ids]\n        if as_type == \"df\":\n            return relevant_df\n        elif as_type == \"tuple\":\n            # inputs, outputs\n            return (\n                relevant_df[self.metadata.input_type],\n                relevant_df[self.metadata.target],\n            )\n\n    def _check_is_loaded(self):\n        \"\"\"Private method to check if the dataset is loaded.\n\n        Throws error if the dataset is not loaded.\n\n        Returns:\n            None\n        \"\"\"\n        if self.df is None:\n            raise ValueError(\n                \"Task dataset is not loaded! Run MatbenchTask.load() to \"\n                \"load the dataset into memory.\"\n            )\n\n    def _check_all_folds_recorded(self, msg):\n        \"\"\"Private method to check if all folds have been recorded.\n\n        Throws error if all folds have not been recorded.\n\n        Args:\n            msg (str): Error message to be displayed.\n\n        Returns:\n            None\n        \"\"\"\n        if not self.all_folds_recorded:\n            raise ValueError(\n                f\"{msg}; folds \"\n                f\"{[f for f in self.is_recorded if not self.is_recorded[f]]} \"\n                f\"not recorded!\"\n            )\n\n    @classmethod\n    def from_dict(cls, d):\n        \"\"\"Create a MatbenchTask from a dictionary input.\n\n        Required method from MSONable.\n\n        Args:\n            d (dict):\n\n        Returns:\n            (MatbenchTask): The MatbenchTask object.\n\n        \"\"\"\n        req_base_keys = [\n            \"@module\",\n            \"@class\",\n            cls._DATASET_KEY,\n            cls._RESULTS_KEY,\n            cls._BENCHMARK_KEY,\n        ]\n        for k in req_base_keys:\n            if k not in d:\n                raise KeyError(f\"Required key '{k}' not found.\")\n        extra_base_keys = [k for k in d.keys() if k not in req_base_keys]\n        if extra_base_keys:\n            raise KeyError(f\"Extra keys {extra_base_keys} not allowed.\")\n        return cls._from_args(\n            dataset_name=d[cls._DATASET_KEY],\n            benchmark_name=d[cls._BENCHMARK_KEY],\n            results_dict=d[cls._RESULTS_KEY],\n        )\n\n    @classmethod\n    def _from_args(cls, dataset_name, benchmark_name, results_dict):\n        \"\"\"Instantiate a MatbenchTask from a arguments\n\n        Args:\n            dataset_name (str): The name of the dataset/task\n            benchmark_name (str): The name of the corresponding benchmark\n            results_dict (dict): A formatted dictionary of raw results.\n\n        Returns:\n            (MatbenchTask): The matbench task object.\n        \"\"\"\n        obj = cls(dataset_name, autoload=False, benchmark=benchmark_name)\n        obj.results = RecursiveDotDict(results_dict)\n        obj.validate()\n        return obj\n\n    def load(self):\n        \"\"\"Load the dataset for this task into memory.\n\n        Returns:\n            (NoneType):  The dataset is stored as an attribute.\n        \"\"\"\n        if self.df is None:\n            logger.info(f\"Loading dataset '{self.dataset_name}'...\")\n            self.df = load(self.dataset_name)\n            logger.info(f\"Dataset '{self.dataset_name} loaded.\")\n        else:\n            logger.info(\n                f\"Dataset {self.dataset_name} already loaded; \"\n                f\"not reloading dataset.\"\n            )\n\n    def get_info(self):\n        logger.info(self.info)\n\n    def get_train_and_val_data(self, fold_number, as_type=\"tuple\"):\n        \"\"\"\n        The training + validation data. All model tuning and\n        hyperparameter selection must be done on this data, NOT test data.\n\n        Args:\n            fold_number (int): Index of the fold to retrieve test data.\n\n        Returns:\n            (pd.Dataframe) or (tuple): Returns either a dataframe of\n                training data or a 2-tuple of training data.\n\n        \"\"\"\n        self._check_is_loaded()\n        fold_key = self.folds_map[fold_number]\n        ids = self.validation[fold_key].train\n        return self._get_data_from_df(ids, as_type)\n\n    def get_test_data(self, fold_number, as_type=\"tuple\", include_target=False):\n        \"\"\"\n        The test data used for recording benchmarks.\n\n        Args:\n            fold_number (int): Index of the fold to retrieve.\n\n        Returns:\n            (tuple) or (pd.Dataframe): Data for inference. If target is\n                not included (it should not be, usually) then it should\n                be a single column if a df or a 1-tuple if a tuple.\n        \"\"\"\n        self._check_is_loaded()\n        fold_key = self.folds_map[fold_number]\n        ids = self.validation[fold_key].test\n        if include_target:\n            return self._get_data_from_df(ids, as_type)\n        else:\n            if as_type == \"tuple\":\n                return self._get_data_from_df(ids, as_type)[0]\n            elif as_type == \"df\":\n                return self._get_data_from_df(ids, as_type)[\n                    [self.metadata.input_type]\n                ]\n\n    def record(self, fold_number, predictions, ci=None, std=None, params=None):\n        \"\"\"Record the test data as well as parameters about the model\n        trained on this fold.\n\n        Args:\n            fold_number (int): The fold number.\n            predictions ([float] or [bool] or np.ndarray): A list of predictions for\n            fold number (int): The index of the fold number to record.\n            ci ([tuple] or [list] or np.ndarray): A list of 95% confidence\n                intervals on predictions for fold number {fold_number}. By default\n                None. Only one of `ci` or `std` should be specified, not both.\n            std ([float] or np.ndarray): A list of prediction standard deviations\n                for fold number {fold_number}. By default None. Only one of\n                `ci` or `std` should be specified, not both.\n            params (dict): Any free-form parameters for information\n                about the algorithm on this fold. For example,\n                hyperparameters determined during validation. Parameters\n                must be a dictionary; dictionary types must adhere to\n                the same requirements as in the MatbenchBenchmark.add_metadata\n                docstring.\n\n        Returns:\n            (NoneType): Recorded data is stored in attributes.\n        \"\"\"\n        if self.is_recorded[fold_number]:\n            logger.error(\n                f\"Fold number {fold_number} already recorded! Aborting record...\"\n            )\n        else:\n            # avoid problems with json serialization\n            if isinstance(predictions, np.ndarray):\n                predictions = predictions.tolist()\n\n            if isinstance(std, np.ndarray):\n                std = std.tolist()\n\n            if isinstance(ci, np.ndarray):\n                ci = ci.tolist()\n\n            if std is not None and ci is not None:\n                raise ValueError(\n                    \"\"\"Both standard deviation (`std`) and confidence\n                    intervals (`ci`) were specified as kwargs. Only one\n                    should be specified, not both.\"\"\"\n                )\n\n            fold_key = self.folds_map[fold_number]\n\n            # create map of original df index to prediction, e.g.,\n            # {ix_of_original_df1: prediction1, ... etc.}\n\n            split_ids = self.validation[fold_key].test\n            if len(predictions) != len(split_ids):\n                raise ValueError(\n                    f\"Prediction outputs must be the same length as the \"\n                    f\"inputs! {len(predictions)} != {len(split_ids)}\"\n                )\n\n            ids_to_predictions = {split_ids[i]: p for i, p in enumerate(predictions)}\n            self.results[fold_key][self._DATA_KEY] = ids_to_predictions\n\n            if std is not None or ci is not None:\n                if self.metadata[\"task_type\"] == \"classification\":\n                    raise ValueError(\n                        \"`std` and `ci` are not valid kwargs for classification \"\n                        + \"tasks. See \"\n                        + \"https://github.com/materialsproject/matbench/pull/99/files#issuecomment-1022662192.\"  # noqa: E501\n                    )\n\n                if ci is None:\n                    low_p = 0.05\n                    high_p = 0.95\n                    # convert from two-tail to one-tail probabilities\n                    # for compatibility with `ppf`\n                    # https://stackoverflow.com/a/29562808/13697228\n                    low_p = low_p / 2.0\n                    high_p = (1 + high_p) / 2.0\n                    # convert std to ci, modified from source:\n                    # https://github.com/uncertainty-toolbox/uncertainty-toolbox/blob/b2f342f6606d1d667bf9583919a663adf8643efe/uncertainty_toolbox/metrics_scoring_rule.py#L187 # noqa: E501\n                    pred_l = stats.norm.ppf(low_p, loc=predictions, scale=std)\n                    pred_u = stats.norm.ppf(high_p, loc=predictions, scale=std)\n                    ci = np.vstack((pred_l.ravel(), pred_u.ravel())).T.tolist()\n                    ci = [tuple(c) for c in ci]\n\n                if std is None:\n                    # std calculated and stored iff ci is symmetric within tol\n                    pred_l, pred_u = np.hsplit(np.array(ci), 2)\n                    if np.allclose(-pred_l, pred_u):\n                        high_p = 0.95\n                        # convert from two-tail to one-tail probabilities for\n                        # compatibility with `ppf`\n                        # https://stackoverflow.com/a/29562808/13697228\n                        high_p = (1 + high_p) / 2.0\n                        std = (pred_u - pred_l) / (2 * stats.norm.ppf(high_p))\n                    else:\n                        std = [None] * len(ci)\n\n                if len(ci) != len(split_ids):\n                    raise ValueError(\n                        f\"\"\"Confidence interval outputs (derived from standard\n                         deviations if `std` was supplied) must be the same\n                         length as the inputs! {len(ci)} != {len(split_ids)}\"\"\"\n                    )\n\n                ids_to_uncertainties = {\n                    split_ids[i]: {\"ci_lower\": p[0], \"ci_upper\": p[1], \"std\": s}\n                    for i, (p, s) in enumerate(zip(ci, std))\n                }\n                self.results[fold_key][self._UNCERTAINTY_KEY] = ids_to_uncertainties\n            else:\n                self.results[fold_key][self._UNCERTAINTY_KEY] = None\n\n            if not isinstance(params, (dict, type(None))):\n                raise TypeError(\n                    f\"Parameters must be stored as a dictionary, not {type(params)}!\"\n                )\n            params = immutify_dictionary(params) if params else params\n            self.results[fold_key][self._PARAMS_KEY] = params if params else {}\n            self.is_recorded[fold_number] = True\n\n            logger.info(\n                f\"Recorded fold \" f\"{self.dataset_name}-{fold_number} successfully.\"\n            )\n\n            truth = self._get_data_from_df(split_ids, as_type=\"tuple\")[1]\n            self.results[fold_key][self._SCORES_KEY] = score_array(\n                truth, predictions, self.metadata.task_type\n            )\n            logger.debug(\n                f\"Scored fold '\" f\"{self.dataset_name}-{fold_key} successfully.\"\n            )\n\n    def as_dict(self):\n        \"\"\"Return a MatbenchTask object as a dictionary.\n\n        Required method from MSONAble.\n\n        Returns:\n            (dict): The object as a serialized dictionary.\n        \"\"\"\n        return {\n            \"@module\": self.__class__.__module__,\n            \"@class\": self.__class__.__name__,\n            self._BENCHMARK_KEY: self.benchmark_name,\n            self._DATASET_KEY: self.dataset_name,\n            self._RESULTS_KEY: dict(self.results),\n        }\n\n    def validate(self):\n        \"\"\"Validate a task after all folds have been recorded.\n\n        There are a few requirements for a task to be validated:\n        - Data types of each predicted sample must match those\n            specified by the validation procedure\n        - All folds must be recorded\n        - There must be no extra or missing required keys from\n            the data, including indices. Every index specified in\n            the validation procedure must be present in its\n            correct fold, and no extras may be present.\n        - Ensure consistency of the supplied uncertainty values.\n            For example, if std is specified and ci is specified\n            for one sample, it must be specified for all samples.\n            If ci is specified but std is not, that must be\n            consistent for all samples.\n        Returns:\n            (NoneType): Errors are thrown if benchmark not valid.\n\n        \"\"\"\n        self._check_all_folds_recorded(\n            f\"Cannot validate task {self.dataset_name} \"\n            f\"unless all folds recorded!\"\n        )\n        task_type = self.metadata.task_type\n\n        # Check for extra fold keys\n        extra_fold_keys = [k for k in self.results if k not in self.folds_keys]\n        if extra_fold_keys:\n            raise KeyError(\n                f\"Extra fold keys {extra_fold_keys} for task \"\n                f\"{self.dataset_name} not allowed.\"\n            )\n\n        for fold_key in self.folds_keys:\n            if fold_key not in self.results:\n                raise KeyError(\n                    f\"Required fold data for fold '{fold_key}' \"\n                    f\"for task {self.dataset_name} not found.\"\n                )\n\n            # Check for extra or missing keys inside each fold:\n            # need params, scores, and data.\n            req_subfold_keys = [self._SCORES_KEY, self._DATA_KEY, self._PARAMS_KEY]\n            extra_subfold_keys = [\n                k for k in self.results[fold_key] if k not in req_subfold_keys\n            ]\n            if self._UNCERTAINTY_KEY in extra_subfold_keys:\n                extra_subfold_keys.remove(self._UNCERTAINTY_KEY)\n            if extra_subfold_keys:\n                raise KeyError(\n                    f\"Extra keys {extra_subfold_keys} for fold results of \"\n                    f\"'{fold_key}' for task {self.dataset_name}  not allowed.\"\n                )\n            req_subfold_keys.append(self._UNCERTAINTY_KEY)\n            for subkey in req_subfold_keys:\n                fold_results = self.results[fold_key]\n                if (\n                    subkey is not self._UNCERTAINTY_KEY\n                    and subkey not in fold_results\n                ):\n                    raise KeyError(\n                        f\"Required key '{subkey}' for task {self.dataset_name} \"\n                        f\"not found for fold '{fold_key}'.\"\n                    )\n                if subkey == self._SCORES_KEY:\n                    scores = self.results[fold_key][subkey]\n                    metrics = REG_METRICS if task_type == REG_KEY else CLF_METRICS\n                    for m in metrics:\n                        if m not in scores:\n                            raise KeyError(\n                                f\"Required score '{m}' for task \"\n                                f\"{self.dataset_name} \"\n                                f\"not found for '{fold_key}'.\"\n                            )\n                        elif not isinstance(scores[m], float):\n                            raise TypeError(\n                                f\"Required score '{m}' for task \"\n                                f\"{self.dataset_name} \"\n                                f\"is not float-type for '{fold_key}'!\"\n                            )\n                    extra_metrics = [k for k in scores if k not in metrics]\n                    if extra_metrics:\n                        raise KeyError(\n                            f\"Extra keys {extra_metrics} for fold scores of \"\n                            f\"'{fold_key}' for task {self.dataset_name} \"\n                            f\"not allowed.\"\n                        )\n\n                # results data indices are cast by json to be strings,\n                # so must be converted to int\n                elif subkey == self._DATA_KEY:\n                    fold_data = self.results[fold_key].data\n\n                    # Ensure all the indices are present with no\n                    # extras for each fold\n                    req_indices = set(self.validation[fold_key].test)\n                    remaining_indices = copy.deepcopy(req_indices)\n                    extra_indices = {}\n                    if self.metadata.task_type == REG_KEY:\n                        allowed_types = (float,)\n                    else:\n                        allowed_types = (bool, float)\n\n                    for ix, datum in fold_data.items():\n                        if ix not in req_indices:\n                            extra_indices[ix] = datum\n                        else:\n                            if not isinstance(datum, allowed_types):\n                                raise TypeError(\n                                    f\"Data point '{ix}: {datum}' has data type \"\n                                    f\"{type(datum)} while required type is \"\n                                    f\"{allowed_types} for task \"\n                                    f\"{self.dataset_name} !\"\n                                )\n                            if self.metadata.task_type == CLF_KEY:\n                                if isinstance(datum, float):\n                                    if datum &lt; 0 or datum &gt; 1:\n                                        raise ValueError(\n                                            f\"Probability estimate '{ix}': {datum}\"\n                                            f\"for task {self.dataset_name} outside \"\n                                            f\"of range [0, 1].\"\n                                        )\n\n                            remaining_indices.remove(ix)\n\n                    if extra_indices and not remaining_indices:\n                        raise ValueError(\n                            f\"{len(extra_indices)} extra indices for problem \"\n                            f\"{self.dataset_name} are not allowed (found in \"\n                            f\"{fold_key}: {remaining_indices}\"\n                        )\n                    elif not extra_indices and remaining_indices:\n                        raise ValueError(\n                            f\"{len(remaining_indices)} required indices \"\n                            f\"for problem {self.dataset_name} not \"\n                            f\"found for {fold_key}: {remaining_indices}\"\n                        )\n                    elif extra_indices and remaining_indices:\n                        raise ValueError(\n                            f\"{len(remaining_indices)} required indices \"\n                            f\"for problem {self.dataset_name} not \"\n                            f\"found and {len(extra_indices)} not \"\n                            f\"allowed indices found for {fold_key}!\"\n                        )\n                    else:\n                        pass\n\n                elif subkey == self._UNCERTAINTY_KEY:\n                    if self._UNCERTAINTY_KEY in self.results[fold_key].keys():\n                        uncertainties = self.results[fold_key][subkey]\n                    else:\n                        uncertainties = None\n                    if uncertainties is not None:\n                        std = uncertainties[\"std\"]\n                        ci = uncertainties[\"ci\"]\n\n                        if all(isinstance(s, float) for s in std):\n                            if any(isinstance(c, float) for c in ci):\n                                if not all(isinstance(c, float) for c in ci):\n                                    raise ValueError(\n                                        \"std specified for all samples \"\n                                        \"but ci not specified for some.\"\n                                    )\n                        else:\n                            if any(isinstance(s, float) for s in std):\n                                raise ValueError(\n                                    \"std is specified for some, but not for all.\"\n                                )\n\n                        if all(isinstance(c, float) for c in ci):\n                            if any(isinstance(s, float) for s in std):\n                                if not all(isinstance(s, float) for s in std):\n                                    raise ValueError(\n                                        \"ci specified for all samples \"\n                                        \"but ci not specified for some.\"\n                                    )\n                        else:\n                            if any(isinstance(c, float) for c in ci):\n                                raise ValueError(\n                                    \"ci is specified for some, but not for all.\"\n                                )\n\n                # Params key has no required form;\n                # it is up to the model to determine it.\n\n        logger.debug(f\"Data for {self.dataset_name} successfully validated.\")\n\n    @property\n    def scores(self):\n        \"\"\"Comprehensive score metrics for this task.\n\n        Gets means, maxes, mins, and more distribution stats (across folds)\n        for all scoring metrics defined for this task.\n\n        There will be different scores for classification problems and\n        regression problems.\n\n        Returns:\n            (dict): A dictionary of all the scores for this task.\n        \"\"\"\n        metric_keys = (\n            REG_METRICS if self.metadata.task_type == REG_KEY else CLF_METRICS\n        )\n        scores = {}\n        self._check_all_folds_recorded(\"Cannot score unless all folds are recorded!\")\n        for mk in metric_keys:\n            metric = {}\n\n            # scores for a metric among all folds\n            raw_metrics_on_folds = [\n                self.results[fk][self._SCORES_KEY][mk]\n                for fk in self.folds_map.values()\n            ]\n            for op in FOLD_DIST_METRICS:\n                metric[op] = getattr(np, op)(raw_metrics_on_folds)\n            scores[mk] = metric\n        return RecursiveDotDict(scores)\n\n    @property\n    def is_recorded(self):\n        \"\"\"Determine what folds in the task are recorded.\n\n        Returns:\n            ({int: bool}): Keys are fold numbers, values are whether the\n                fold is recorded or not.\n        \"\"\"\n        is_recorded = {}\n        for fnum, fkey in self.folds_map.items():\n            if self.results[fkey][self._DATA_KEY]:\n                is_recorded[fnum] = True\n            else:\n                is_recorded[fnum] = False\n        return is_recorded\n\n    @property\n    def all_folds_recorded(self):\n        \"\"\"Determine if all folds are recorded.\n\n        Returns:\n            (bool): True if all folds are recorded, False otherwise.\n        \"\"\"\n        return all([v for v in self.is_recorded.values()])\n\n    @property\n    def has_polymorphs(self):\n        \"\"\"Determine if a task's raw data contains polymorphs.\n\n        Returns:\n            (bool): If true, contains polymorphs.\n        \"\"\"\n        checker_key = \"pmg_composition\"\n        self._check_is_loaded()\n        if self.metadata.input_type == \"composition\":\n            stc = StrToComposition(target_col_id=checker_key, reduce=True)\n            comps = stc.featurize_dataframe(self.df, \"composition\")[\n                checker_key\n            ].values\n        elif self.metadata.input_type == \"structure\":\n            stc = StructureToComposition(target_col_id=checker_key, reduce=True)\n            comps = stc.featurize_dataframe(self.df, \"structure\")[checker_key].values\n        else:\n            raise ValueError(\n                \"Cannot check for polymorphs without input type in \"\n                \"(structure, composition)!\"\n            )\n\n        unique_comps = set(comps)\n        if len(unique_comps) != len(comps):\n            return True\n        else:\n            return False\n</code></pre>"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.all_folds_recorded","title":"<code>all_folds_recorded</code>  <code>property</code>","text":"<p>Determine if all folds are recorded.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if all folds are recorded, False otherwise.</p>"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.has_polymorphs","title":"<code>has_polymorphs</code>  <code>property</code>","text":"<p>Determine if a task's raw data contains polymorphs.</p> <p>Returns:</p> Type Description <code>bool</code> <p>If true, contains polymorphs.</p>"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.is_recorded","title":"<code>is_recorded</code>  <code>property</code>","text":"<p>Determine what folds in the task are recorded.</p> <p>Returns:</p> Type Description <code>{int: bool}</code> <p>Keys are fold numbers, values are whether the fold is recorded or not.</p>"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.scores","title":"<code>scores</code>  <code>property</code>","text":"<p>Comprehensive score metrics for this task.</p> <p>Gets means, maxes, mins, and more distribution stats (across folds) for all scoring metrics defined for this task.</p> <p>There will be different scores for classification problems and regression problems.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary of all the scores for this task.</p>"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.__init__","title":"<code>__init__(dataset_name, autoload=True, benchmark=MBV01_KEY)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>Name of the task. Must belong to the benchmark given in the 'benchmark' argument.</p> required <code>autoload</code> <code>bool</code> <p>If True, will load the benchmark's raw data. This includes deserializing many large structures for some datasets, so loading make take some time. If False, you will need to run .load() before running .get_*_data() methods.</p> <code>True</code> <code>benchmark</code> <code>str</code> <p>Name of the benchmark this task belongs to.</p> <code>MBV01_KEY</code> Source code in <code>matbench/task.py</code> <pre><code>def __init__(self, dataset_name, autoload=True, benchmark=MBV01_KEY):\n    \"\"\"\n    Args:\n        dataset_name (str): Name of the task. Must belong to the benchmark\n            given in the 'benchmark' argument.\n        autoload (bool): If True, will load the benchmark's raw data. This\n            includes deserializing many large structures for some datasets,\n            so loading make take some time. If False, you will need to\n            run .load() before running .get_*_data() methods.\n        benchmark (str): Name of the benchmark this task belongs to.\n    \"\"\"\n    self.dataset_name = dataset_name\n    self.df = load(self.dataset_name) if autoload else None\n    self.info = get_all_dataset_info(dataset_name)\n\n    # define all static data needed for this task\n    # including citations, data size, as well as specific validation splits\n\n    if benchmark == MBV01_KEY:\n        self.benchmark_name = MBV01_KEY\n        self.metadata = mbv01_metadata[dataset_name]\n        self.validation = mbv01_validation.splits[dataset_name]\n    else:\n        raise ValueError(\n            f\"Only {MBV01_KEY} available. No other benchmarks defined!\"\n        )\n\n    # keeping track of folds\n    self.folds_keys = list(self.validation.keys())\n    self.folds_nums = list(range(len(self.folds_keys)))\n    self.folds_map = dict(zip(self.folds_nums, self.folds_keys))\n\n    # Alias for ease of use\n    self.folds = self.folds_nums\n    self.results = RecursiveDotDict({})\n</code></pre>"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.as_dict","title":"<code>as_dict()</code>","text":"<p>Return a MatbenchTask object as a dictionary.</p> <p>Required method from MSONAble.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The object as a serialized dictionary.</p> Source code in <code>matbench/task.py</code> <pre><code>def as_dict(self):\n    \"\"\"Return a MatbenchTask object as a dictionary.\n\n    Required method from MSONAble.\n\n    Returns:\n        (dict): The object as a serialized dictionary.\n    \"\"\"\n    return {\n        \"@module\": self.__class__.__module__,\n        \"@class\": self.__class__.__name__,\n        self._BENCHMARK_KEY: self.benchmark_name,\n        self._DATASET_KEY: self.dataset_name,\n        self._RESULTS_KEY: dict(self.results),\n    }\n</code></pre>"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.from_dict","title":"<code>from_dict(d)</code>  <code>classmethod</code>","text":"<p>Create a MatbenchTask from a dictionary input.</p> <p>Required method from MSONable.</p> <p>Parameters:</p> Name Type Description Default <code>d</code> <code>dict</code> required <p>Returns:</p> Type Description <code>MatbenchTask</code> <p>The MatbenchTask object.</p> Source code in <code>matbench/task.py</code> <pre><code>@classmethod\ndef from_dict(cls, d):\n    \"\"\"Create a MatbenchTask from a dictionary input.\n\n    Required method from MSONable.\n\n    Args:\n        d (dict):\n\n    Returns:\n        (MatbenchTask): The MatbenchTask object.\n\n    \"\"\"\n    req_base_keys = [\n        \"@module\",\n        \"@class\",\n        cls._DATASET_KEY,\n        cls._RESULTS_KEY,\n        cls._BENCHMARK_KEY,\n    ]\n    for k in req_base_keys:\n        if k not in d:\n            raise KeyError(f\"Required key '{k}' not found.\")\n    extra_base_keys = [k for k in d.keys() if k not in req_base_keys]\n    if extra_base_keys:\n        raise KeyError(f\"Extra keys {extra_base_keys} not allowed.\")\n    return cls._from_args(\n        dataset_name=d[cls._DATASET_KEY],\n        benchmark_name=d[cls._BENCHMARK_KEY],\n        results_dict=d[cls._RESULTS_KEY],\n    )\n</code></pre>"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.get_test_data","title":"<code>get_test_data(fold_number, as_type='tuple', include_target=False)</code>","text":"<p>The test data used for recording benchmarks.</p> <p>Parameters:</p> Name Type Description Default <code>fold_number</code> <code>int</code> <p>Index of the fold to retrieve.</p> required <p>Returns:</p> Type Description <code>tuple) or (pd.Dataframe</code> <p>Data for inference. If target is not included (it should not be, usually) then it should be a single column if a df or a 1-tuple if a tuple.</p> Source code in <code>matbench/task.py</code> <pre><code>def get_test_data(self, fold_number, as_type=\"tuple\", include_target=False):\n    \"\"\"\n    The test data used for recording benchmarks.\n\n    Args:\n        fold_number (int): Index of the fold to retrieve.\n\n    Returns:\n        (tuple) or (pd.Dataframe): Data for inference. If target is\n            not included (it should not be, usually) then it should\n            be a single column if a df or a 1-tuple if a tuple.\n    \"\"\"\n    self._check_is_loaded()\n    fold_key = self.folds_map[fold_number]\n    ids = self.validation[fold_key].test\n    if include_target:\n        return self._get_data_from_df(ids, as_type)\n    else:\n        if as_type == \"tuple\":\n            return self._get_data_from_df(ids, as_type)[0]\n        elif as_type == \"df\":\n            return self._get_data_from_df(ids, as_type)[\n                [self.metadata.input_type]\n            ]\n</code></pre>"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.get_train_and_val_data","title":"<code>get_train_and_val_data(fold_number, as_type='tuple')</code>","text":"<p>The training + validation data. All model tuning and hyperparameter selection must be done on this data, NOT test data.</p> <p>Parameters:</p> Name Type Description Default <code>fold_number</code> <code>int</code> <p>Index of the fold to retrieve test data.</p> required <p>Returns:</p> Type Description <code>pd.Dataframe) or (tuple</code> <p>Returns either a dataframe of training data or a 2-tuple of training data.</p> Source code in <code>matbench/task.py</code> <pre><code>def get_train_and_val_data(self, fold_number, as_type=\"tuple\"):\n    \"\"\"\n    The training + validation data. All model tuning and\n    hyperparameter selection must be done on this data, NOT test data.\n\n    Args:\n        fold_number (int): Index of the fold to retrieve test data.\n\n    Returns:\n        (pd.Dataframe) or (tuple): Returns either a dataframe of\n            training data or a 2-tuple of training data.\n\n    \"\"\"\n    self._check_is_loaded()\n    fold_key = self.folds_map[fold_number]\n    ids = self.validation[fold_key].train\n    return self._get_data_from_df(ids, as_type)\n</code></pre>"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.load","title":"<code>load()</code>","text":"<p>Load the dataset for this task into memory.</p> <p>Returns:</p> Type Description <code>NoneType</code> <p>The dataset is stored as an attribute.</p> Source code in <code>matbench/task.py</code> <pre><code>def load(self):\n    \"\"\"Load the dataset for this task into memory.\n\n    Returns:\n        (NoneType):  The dataset is stored as an attribute.\n    \"\"\"\n    if self.df is None:\n        logger.info(f\"Loading dataset '{self.dataset_name}'...\")\n        self.df = load(self.dataset_name)\n        logger.info(f\"Dataset '{self.dataset_name} loaded.\")\n    else:\n        logger.info(\n            f\"Dataset {self.dataset_name} already loaded; \"\n            f\"not reloading dataset.\"\n        )\n</code></pre>"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.record","title":"<code>record(fold_number, predictions, ci=None, std=None, params=None)</code>","text":"<p>Record the test data as well as parameters about the model trained on this fold.</p> <p>Parameters:</p> Name Type Description Default <code>fold_number</code> <code>int</code> <p>The fold number.</p> required <code>predictions</code> <code>[float] or [bool] or ndarray</code> <p>A list of predictions for</p> required <code>fold</code> <code>number (int</code> <p>The index of the fold number to record.</p> required <code>ci</code> <code>[tuple] or [list] or ndarray</code> <p>A list of 95% confidence intervals on predictions for fold number {fold_number}. By default None. Only one of <code>ci</code> or <code>std</code> should be specified, not both.</p> <code>None</code> <code>std</code> <code>[float] or ndarray</code> <p>A list of prediction standard deviations for fold number {fold_number}. By default None. Only one of <code>ci</code> or <code>std</code> should be specified, not both.</p> <code>None</code> <code>params</code> <code>dict</code> <p>Any free-form parameters for information about the algorithm on this fold. For example, hyperparameters determined during validation. Parameters must be a dictionary; dictionary types must adhere to the same requirements as in the MatbenchBenchmark.add_metadata docstring.</p> <code>None</code> <p>Returns:</p> Type Description <code>NoneType</code> <p>Recorded data is stored in attributes.</p> Source code in <code>matbench/task.py</code> <pre><code>def record(self, fold_number, predictions, ci=None, std=None, params=None):\n    \"\"\"Record the test data as well as parameters about the model\n    trained on this fold.\n\n    Args:\n        fold_number (int): The fold number.\n        predictions ([float] or [bool] or np.ndarray): A list of predictions for\n        fold number (int): The index of the fold number to record.\n        ci ([tuple] or [list] or np.ndarray): A list of 95% confidence\n            intervals on predictions for fold number {fold_number}. By default\n            None. Only one of `ci` or `std` should be specified, not both.\n        std ([float] or np.ndarray): A list of prediction standard deviations\n            for fold number {fold_number}. By default None. Only one of\n            `ci` or `std` should be specified, not both.\n        params (dict): Any free-form parameters for information\n            about the algorithm on this fold. For example,\n            hyperparameters determined during validation. Parameters\n            must be a dictionary; dictionary types must adhere to\n            the same requirements as in the MatbenchBenchmark.add_metadata\n            docstring.\n\n    Returns:\n        (NoneType): Recorded data is stored in attributes.\n    \"\"\"\n    if self.is_recorded[fold_number]:\n        logger.error(\n            f\"Fold number {fold_number} already recorded! Aborting record...\"\n        )\n    else:\n        # avoid problems with json serialization\n        if isinstance(predictions, np.ndarray):\n            predictions = predictions.tolist()\n\n        if isinstance(std, np.ndarray):\n            std = std.tolist()\n\n        if isinstance(ci, np.ndarray):\n            ci = ci.tolist()\n\n        if std is not None and ci is not None:\n            raise ValueError(\n                \"\"\"Both standard deviation (`std`) and confidence\n                intervals (`ci`) were specified as kwargs. Only one\n                should be specified, not both.\"\"\"\n            )\n\n        fold_key = self.folds_map[fold_number]\n\n        # create map of original df index to prediction, e.g.,\n        # {ix_of_original_df1: prediction1, ... etc.}\n\n        split_ids = self.validation[fold_key].test\n        if len(predictions) != len(split_ids):\n            raise ValueError(\n                f\"Prediction outputs must be the same length as the \"\n                f\"inputs! {len(predictions)} != {len(split_ids)}\"\n            )\n\n        ids_to_predictions = {split_ids[i]: p for i, p in enumerate(predictions)}\n        self.results[fold_key][self._DATA_KEY] = ids_to_predictions\n\n        if std is not None or ci is not None:\n            if self.metadata[\"task_type\"] == \"classification\":\n                raise ValueError(\n                    \"`std` and `ci` are not valid kwargs for classification \"\n                    + \"tasks. See \"\n                    + \"https://github.com/materialsproject/matbench/pull/99/files#issuecomment-1022662192.\"  # noqa: E501\n                )\n\n            if ci is None:\n                low_p = 0.05\n                high_p = 0.95\n                # convert from two-tail to one-tail probabilities\n                # for compatibility with `ppf`\n                # https://stackoverflow.com/a/29562808/13697228\n                low_p = low_p / 2.0\n                high_p = (1 + high_p) / 2.0\n                # convert std to ci, modified from source:\n                # https://github.com/uncertainty-toolbox/uncertainty-toolbox/blob/b2f342f6606d1d667bf9583919a663adf8643efe/uncertainty_toolbox/metrics_scoring_rule.py#L187 # noqa: E501\n                pred_l = stats.norm.ppf(low_p, loc=predictions, scale=std)\n                pred_u = stats.norm.ppf(high_p, loc=predictions, scale=std)\n                ci = np.vstack((pred_l.ravel(), pred_u.ravel())).T.tolist()\n                ci = [tuple(c) for c in ci]\n\n            if std is None:\n                # std calculated and stored iff ci is symmetric within tol\n                pred_l, pred_u = np.hsplit(np.array(ci), 2)\n                if np.allclose(-pred_l, pred_u):\n                    high_p = 0.95\n                    # convert from two-tail to one-tail probabilities for\n                    # compatibility with `ppf`\n                    # https://stackoverflow.com/a/29562808/13697228\n                    high_p = (1 + high_p) / 2.0\n                    std = (pred_u - pred_l) / (2 * stats.norm.ppf(high_p))\n                else:\n                    std = [None] * len(ci)\n\n            if len(ci) != len(split_ids):\n                raise ValueError(\n                    f\"\"\"Confidence interval outputs (derived from standard\n                     deviations if `std` was supplied) must be the same\n                     length as the inputs! {len(ci)} != {len(split_ids)}\"\"\"\n                )\n\n            ids_to_uncertainties = {\n                split_ids[i]: {\"ci_lower\": p[0], \"ci_upper\": p[1], \"std\": s}\n                for i, (p, s) in enumerate(zip(ci, std))\n            }\n            self.results[fold_key][self._UNCERTAINTY_KEY] = ids_to_uncertainties\n        else:\n            self.results[fold_key][self._UNCERTAINTY_KEY] = None\n\n        if not isinstance(params, (dict, type(None))):\n            raise TypeError(\n                f\"Parameters must be stored as a dictionary, not {type(params)}!\"\n            )\n        params = immutify_dictionary(params) if params else params\n        self.results[fold_key][self._PARAMS_KEY] = params if params else {}\n        self.is_recorded[fold_number] = True\n\n        logger.info(\n            f\"Recorded fold \" f\"{self.dataset_name}-{fold_number} successfully.\"\n        )\n\n        truth = self._get_data_from_df(split_ids, as_type=\"tuple\")[1]\n        self.results[fold_key][self._SCORES_KEY] = score_array(\n            truth, predictions, self.metadata.task_type\n        )\n        logger.debug(\n            f\"Scored fold '\" f\"{self.dataset_name}-{fold_key} successfully.\"\n        )\n</code></pre>"},{"location":"Reference/MatbenchTask/#matbench.task.MatbenchTask.validate","title":"<code>validate()</code>","text":"<p>Validate a task after all folds have been recorded.</p> <p>There are a few requirements for a task to be validated: - Data types of each predicted sample must match those     specified by the validation procedure - All folds must be recorded - There must be no extra or missing required keys from     the data, including indices. Every index specified in     the validation procedure must be present in its     correct fold, and no extras may be present. - Ensure consistency of the supplied uncertainty values.     For example, if std is specified and ci is specified     for one sample, it must be specified for all samples.     If ci is specified but std is not, that must be     consistent for all samples. Returns:     (NoneType): Errors are thrown if benchmark not valid.</p> Source code in <code>matbench/task.py</code> <pre><code>def validate(self):\n    \"\"\"Validate a task after all folds have been recorded.\n\n    There are a few requirements for a task to be validated:\n    - Data types of each predicted sample must match those\n        specified by the validation procedure\n    - All folds must be recorded\n    - There must be no extra or missing required keys from\n        the data, including indices. Every index specified in\n        the validation procedure must be present in its\n        correct fold, and no extras may be present.\n    - Ensure consistency of the supplied uncertainty values.\n        For example, if std is specified and ci is specified\n        for one sample, it must be specified for all samples.\n        If ci is specified but std is not, that must be\n        consistent for all samples.\n    Returns:\n        (NoneType): Errors are thrown if benchmark not valid.\n\n    \"\"\"\n    self._check_all_folds_recorded(\n        f\"Cannot validate task {self.dataset_name} \"\n        f\"unless all folds recorded!\"\n    )\n    task_type = self.metadata.task_type\n\n    # Check for extra fold keys\n    extra_fold_keys = [k for k in self.results if k not in self.folds_keys]\n    if extra_fold_keys:\n        raise KeyError(\n            f\"Extra fold keys {extra_fold_keys} for task \"\n            f\"{self.dataset_name} not allowed.\"\n        )\n\n    for fold_key in self.folds_keys:\n        if fold_key not in self.results:\n            raise KeyError(\n                f\"Required fold data for fold '{fold_key}' \"\n                f\"for task {self.dataset_name} not found.\"\n            )\n\n        # Check for extra or missing keys inside each fold:\n        # need params, scores, and data.\n        req_subfold_keys = [self._SCORES_KEY, self._DATA_KEY, self._PARAMS_KEY]\n        extra_subfold_keys = [\n            k for k in self.results[fold_key] if k not in req_subfold_keys\n        ]\n        if self._UNCERTAINTY_KEY in extra_subfold_keys:\n            extra_subfold_keys.remove(self._UNCERTAINTY_KEY)\n        if extra_subfold_keys:\n            raise KeyError(\n                f\"Extra keys {extra_subfold_keys} for fold results of \"\n                f\"'{fold_key}' for task {self.dataset_name}  not allowed.\"\n            )\n        req_subfold_keys.append(self._UNCERTAINTY_KEY)\n        for subkey in req_subfold_keys:\n            fold_results = self.results[fold_key]\n            if (\n                subkey is not self._UNCERTAINTY_KEY\n                and subkey not in fold_results\n            ):\n                raise KeyError(\n                    f\"Required key '{subkey}' for task {self.dataset_name} \"\n                    f\"not found for fold '{fold_key}'.\"\n                )\n            if subkey == self._SCORES_KEY:\n                scores = self.results[fold_key][subkey]\n                metrics = REG_METRICS if task_type == REG_KEY else CLF_METRICS\n                for m in metrics:\n                    if m not in scores:\n                        raise KeyError(\n                            f\"Required score '{m}' for task \"\n                            f\"{self.dataset_name} \"\n                            f\"not found for '{fold_key}'.\"\n                        )\n                    elif not isinstance(scores[m], float):\n                        raise TypeError(\n                            f\"Required score '{m}' for task \"\n                            f\"{self.dataset_name} \"\n                            f\"is not float-type for '{fold_key}'!\"\n                        )\n                extra_metrics = [k for k in scores if k not in metrics]\n                if extra_metrics:\n                    raise KeyError(\n                        f\"Extra keys {extra_metrics} for fold scores of \"\n                        f\"'{fold_key}' for task {self.dataset_name} \"\n                        f\"not allowed.\"\n                    )\n\n            # results data indices are cast by json to be strings,\n            # so must be converted to int\n            elif subkey == self._DATA_KEY:\n                fold_data = self.results[fold_key].data\n\n                # Ensure all the indices are present with no\n                # extras for each fold\n                req_indices = set(self.validation[fold_key].test)\n                remaining_indices = copy.deepcopy(req_indices)\n                extra_indices = {}\n                if self.metadata.task_type == REG_KEY:\n                    allowed_types = (float,)\n                else:\n                    allowed_types = (bool, float)\n\n                for ix, datum in fold_data.items():\n                    if ix not in req_indices:\n                        extra_indices[ix] = datum\n                    else:\n                        if not isinstance(datum, allowed_types):\n                            raise TypeError(\n                                f\"Data point '{ix}: {datum}' has data type \"\n                                f\"{type(datum)} while required type is \"\n                                f\"{allowed_types} for task \"\n                                f\"{self.dataset_name} !\"\n                            )\n                        if self.metadata.task_type == CLF_KEY:\n                            if isinstance(datum, float):\n                                if datum &lt; 0 or datum &gt; 1:\n                                    raise ValueError(\n                                        f\"Probability estimate '{ix}': {datum}\"\n                                        f\"for task {self.dataset_name} outside \"\n                                        f\"of range [0, 1].\"\n                                    )\n\n                        remaining_indices.remove(ix)\n\n                if extra_indices and not remaining_indices:\n                    raise ValueError(\n                        f\"{len(extra_indices)} extra indices for problem \"\n                        f\"{self.dataset_name} are not allowed (found in \"\n                        f\"{fold_key}: {remaining_indices}\"\n                    )\n                elif not extra_indices and remaining_indices:\n                    raise ValueError(\n                        f\"{len(remaining_indices)} required indices \"\n                        f\"for problem {self.dataset_name} not \"\n                        f\"found for {fold_key}: {remaining_indices}\"\n                    )\n                elif extra_indices and remaining_indices:\n                    raise ValueError(\n                        f\"{len(remaining_indices)} required indices \"\n                        f\"for problem {self.dataset_name} not \"\n                        f\"found and {len(extra_indices)} not \"\n                        f\"allowed indices found for {fold_key}!\"\n                    )\n                else:\n                    pass\n\n            elif subkey == self._UNCERTAINTY_KEY:\n                if self._UNCERTAINTY_KEY in self.results[fold_key].keys():\n                    uncertainties = self.results[fold_key][subkey]\n                else:\n                    uncertainties = None\n                if uncertainties is not None:\n                    std = uncertainties[\"std\"]\n                    ci = uncertainties[\"ci\"]\n\n                    if all(isinstance(s, float) for s in std):\n                        if any(isinstance(c, float) for c in ci):\n                            if not all(isinstance(c, float) for c in ci):\n                                raise ValueError(\n                                    \"std specified for all samples \"\n                                    \"but ci not specified for some.\"\n                                )\n                    else:\n                        if any(isinstance(s, float) for s in std):\n                            raise ValueError(\n                                \"std is specified for some, but not for all.\"\n                            )\n\n                    if all(isinstance(c, float) for c in ci):\n                        if any(isinstance(s, float) for s in std):\n                            if not all(isinstance(s, float) for s in std):\n                                raise ValueError(\n                                    \"ci specified for all samples \"\n                                    \"but ci not specified for some.\"\n                                )\n                    else:\n                        if any(isinstance(c, float) for c in ci):\n                            raise ValueError(\n                                \"ci is specified for some, but not for all.\"\n                            )\n\n            # Params key has no required form;\n            # it is up to the model to determine it.\n\n    logger.debug(f\"Data for {self.dataset_name} successfully validated.\")\n</code></pre>"}]}